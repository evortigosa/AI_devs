{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-AilCEFI9Qu"
   },
   "source": [
    "# Speculative sampling from scratch in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xexOCpENH6ay"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "3020742d0e854644aeaf1391e3833b2e",
      "cf1e18b9db1e424eb66cc4c496f4e084",
      "2fdb7f6eb97643cf92c197b5a19b2df9",
      "183b235c4c614db394697e14fecb1c21",
      "54a1e6f9dc2941d8a5fb528019dd63d3",
      "5bfa0edb629049328e52b871d8ad6ce7",
      "6d42eebcbfb341729717a9583cd26818",
      "42e04b7e0aca4a978cda8097c549c556",
      "58b099388ab34905bc8bad556ff452b4",
      "16738138c8d44c53a41016550e5a7d70",
      "a83c79e027484468b70ec77e8234a258",
      "d6b0eb1c0e1e4399bc5b1b2bc82469d8",
      "56014c3c2adb40d38f1a7520856a26c8",
      "40bb7a0cdbe24598bd18b9c512dd0343",
      "2ef13cfcaba7499ab670bc16628fa8a8",
      "05a62aaee70848f1a82044dd3f262d4f",
      "fb52a4ccc58d4a0bae72b9566f46d211",
      "5494fb5aa080481a86efb0ea0176be06",
      "21c171e8ba7f442498e8c69511233d90",
      "5eefe3d5272b4eaf8fe2dc31b53ed0e2",
      "54b22bfee74143908c9fa9507fbc5256",
      "7f03ba0a78b249019c3b00b744944fff",
      "863d5946526f4545b4873f0b19224bc4",
      "abfac48d91f14d45a0f7eed958dd9217",
      "987135ed403d4a69837c5d0fbbff7eb0",
      "7da456d4a8ec4b14b5644b154f76f241",
      "05ae800c1eb44e9d8807638d0aaaf485",
      "104d1416263b4b1f99596e33e639460c",
      "a94a5c75b0114840b84cf3462d57e7e0",
      "1a6a2aa145224f20a10c1e5b9c550335",
      "f68bf5c91450416891e3958bdbf154a4",
      "3a0a972d2a5b4ed9a2a6097bd367d29c",
      "1b4057206e6c41fea23379878b806419",
      "aac3d7aa03014b4599e697d8b7095945",
      "9fff0949ccfc48179a308cda3133dc71",
      "36fac9e8586145e8a2eadd493df220b8",
      "d7f743e90e6d42a38b89b55fed7588d5",
      "6899f4b09b124a62ab1eb73313fa9cb9",
      "6b63fe8a656b4102bdf34b47b3e5e501",
      "9792c708d187442a92fb6845ba10d925",
      "f51de67d6d054a4683ed4cfd9afc0307",
      "35aed37185f6424599c6eb08f7f67d94",
      "2ef4b01b49e44eefaa4887d58f0e216b",
      "76012a63335b479c880fe00a47851b58",
      "f4342723c96f4750857b3fdd144575bf",
      "3f02decac3ec4a41baccc0ba33b813f4",
      "561c6a9bb021411b9be850cdf64de7e3",
      "de5a94db977b4fa9bb98d008ddb1b5ef",
      "4885737d8bff464fa47a338495f53c11",
      "84cdb83e9b0e4f399af5303996be4acb",
      "3282f61347d749cba85cfccb8e1f8e59",
      "eaffe177974b4619a7b48e07f544690f",
      "ebe1f70df8f24fa78d61af72e8cb320d",
      "e520d6ad90de47baab5ee760c1810deb",
      "39e6f17f28cf4a52aeb644a4c63ec4ce",
      "4f18aea52f3649e1ab833b94ff3c143d",
      "3451810589e945c79107176e1240cda0",
      "6b838771b13b47ec95526859c0ce9818",
      "4bbd707adf6a40c7a1ea8757b0de1484",
      "20425720e68c45f58ed343ae10728f7d",
      "c74d3d75b34747feac13ab87aab8aeb5",
      "d7c85cf671694f7e9722a9ae49d5de03",
      "0447c663d47d40d387287b0686e01044",
      "6d36e67f9b654dadbda365cec2d30fac",
      "af91e54f3f4b44358280822c9dad813f",
      "d5d7650337c94f97ad6e8ca4be423a54",
      "b90e42686ee04121ae2facd56be8c563",
      "9fa5f205f48045fdb0bf1ecb1be5e38d",
      "d6a9fa53f6604e8eabce3ccd450a8c8c",
      "f5f7670f7e174d51a10bbba45c43d899",
      "645c59e5c2054e76ba808ff8fbd08dbd",
      "90beac3f765347fb9f137891557c5947",
      "6d62b02e570a4d628d842d9104f48ffb",
      "74a5523a5d3a4f2b95310935dea109ab",
      "819172e409e6462a8d3dcbe165856fed",
      "6112f5a78ab8406d893b7164f2747fb2",
      "accada9864d442678bac124eb39e2435",
      "added88056aa438883dd10d66df47388",
      "cb8174b508bc4298be4e625b863020a9",
      "307bab61f6b24882b7f9d529728d1108",
      "078550da1cbb44d2b96c441a6f7f7cc9",
      "79ef92b8d8894baabdf691021d1e43e4",
      "145c041fc1814165be15865864f28216",
      "562c8b3eeade4f94a3278ef21e1c3693",
      "e4cc3b4434014c3d8d7da6710a4161dc",
      "4dd091ec8a6b4252933d36d88d6cba7d",
      "eccf9d0633994ec9a9a4df80c4b83681",
      "a5a975e6e83b47319731d60e38ba51be",
      "b1503edecc6241e79ee7794eaca93db7",
      "b9e00a9151124778b84c7fe3c76cced4",
      "f01116d1f4464830ac439b09f3a3bd36",
      "3bf7cf273359413ba914f389594283dd",
      "bbfd59aed72b4fa49421ba3d3128cf71",
      "88f73ec464304738865cfd47e560ae89",
      "3dd9928ae3294969b71fd7e1a18be874",
      "9f5f68ebc9d543b6be655de266d11f32",
      "9a15f3717ace4945bfd53d3865634ae9",
      "021fd47b9e48486d8c6f5506a86678ab",
      "148ee7169b7b4079b56cb9d04988ef32",
      "5c4837241780413eaa3d012e064625e4",
      "b575d00c94124dd0bcd8c701a45c1e6d",
      "49f6652fc57c40acb2c69e9bd479b0e0",
      "ed248ae92adb433c88a992518ccc884b",
      "462c9cdb611a459f9c1f84e997676df3",
      "acb1493f7e614b8789465fdaca1f8140",
      "61428cdf023e4884a02e1d8ec89e72bd",
      "6202ab1a391d4aea9d11316e27656b64",
      "0dd21cb0ac1442e38131255e9ed19967",
      "aec353a3f6694c13867855df11f1838b",
      "f4a64a6c3bc44e189eaf4067c441bbe7",
      "74c9062130de40c594e51af4c2a41a94",
      "0a6f80a36768473988ef80e2bc546a6f",
      "0070b9a46d4b47108fc21e7e6cdd00bb",
      "b8eec3e7538a47f98803ba9d9bfb0384",
      "d8b48edabf0c444494f0f937673fc33d",
      "f7892be36f9f4490a2a62b2081e3b175",
      "3a286ee012b44f0ea05290fa9dc5e1ce",
      "e08d0e3ea732497ba4b371583315e382",
      "4074edba04a443dab6dee97cd1f55a31",
      "b1035d1b1f924f7db475d3b8f787ae7b",
      "1d691bbfc0774d68b203d2c01312a1b1"
     ]
    },
    "id": "bOL1qMQQJBWC",
    "outputId": "2b7a95a9-9a81-486b-a657-00dd7c196cea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3020742d0e854644aeaf1391e3833b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b0eb1c0e1e4399bc5b1b2bc82469d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863d5946526f4545b4873f0b19224bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac3d7aa03014b4599e697d8b7095945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4342723c96f4750857b3fdd144575bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f18aea52f3649e1ab833b94ff3c143d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90e42686ee04121ae2facd56be8c563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "added88056aa438883dd10d66df47388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1503edecc6241e79ee7794eaca93db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4837241780413eaa3d012e064625e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c9062130de40c594e51af4c2a41a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# loading the draft model\n",
    "draft= 'google/flan-t5-large'\n",
    "draft_tokenizer= T5Tokenizer.from_pretrained(draft)\n",
    "draft_model= T5ForConditionalGeneration.from_pretrained(draft)\n",
    "\n",
    "# loading the target model\n",
    "target= 'google/flan-t5-xl'\n",
    "target_tokenizer= T5Tokenizer.from_pretrained(target)\n",
    "target_model= T5ForConditionalGeneration.from_pretrained(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IslT92koJBZG",
    "outputId": "66c365bd-c134-4ed0-ae43-c6de418a25c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ensuring the tokenizers are identical\n",
    "In order for speculative sampling to work, tokenization for both the draft and\n",
    "target model must be identical. This is a sanity check to make sure they are.\n",
    "\"\"\"\n",
    "\n",
    "# tokenizing a sequence\n",
    "prompt= 'this, is, some [text] for 1234comparing, tokenizers adoihayyuz'\n",
    "ex1= target_tokenizer(prompt, return_tensors='pt').input_ids\n",
    "ex2= draft_tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "# zero means all tokenized values are the same, so the tokenizers are more than likely identical\n",
    "print((ex1-ex2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-dJjbkgMaNP"
   },
   "source": [
    "# Building Speculative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KGjxImwcP2GD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSDQDCpNJBce",
    "outputId": "bdac5816-d897-4553-acbb-a5725cd83999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Speculative Sampling Iteration 0 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316, 20256,    15,   311,   181]])\n",
      "generated draft text: <pad>Die Kampfe nicht mit\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([316,   3,  15, 181, 181, 177])\n",
      "generated target text: Die e mit mit den\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([  0, 316,   3])\n",
      "generated target text: <pad>Die\n",
      "========== Speculative Sampling Iteration 1 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,     2, 25231,     3,   547,   289]])\n",
      "generated draft text: <pad> Die <unk>ffentlichkeit hat sich\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([ 316,    3, 9465,   40,    3,  547,  289,    3])\n",
      "generated target text: Die Brul hat sich\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465])\n",
      "generated target text: <pad>Die Bru\n",
      "========== Speculative Sampling Iteration 2 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17, 13680,   229,   311,   181]])\n",
      "generated draft text: <pad>Die Brutalität ist nicht mit\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([ 316,    3, 9465,   17,  235,    3,  311,  181,  177])\n",
      "generated target text: Die Brutto  nicht mit den\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465,   17,  235])\n",
      "generated target text: <pad>Die Brutto\n",
      "========== Speculative Sampling Iteration 3 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,   109,   311,   181, 18117,\n",
      "            35]])\n",
      "generated draft text: <pad>Die Bruttole nicht mit Monsteren\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([ 316,    3, 9465,   17,  235,    7,   49,  181,  177,   29,    6])\n",
      "generated target text: Die Bruttoser mit denn,\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465,   17,  235,    7])\n",
      "generated target text: <pad>Die Bruttos\n",
      "========== Speculative Sampling Iteration 4 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,   311,   181, 18117,\n",
      "            35,     6]])\n",
      "generated draft text: <pad>Die Bruttos nicht mit Monsteren,\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([ 316,    3, 9465,   17,  235,    7,   15,  181,  177,   29,    6,  561])\n",
      "generated target text: Die Bruttose mit denn, um\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465,   17,  235,    7,   15])\n",
      "generated target text: <pad>Die Bruttose\n",
      "========== Speculative Sampling Iteration 5 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   404,   311,\n",
      "           181, 18117,    35]])\n",
      "generated draft text: <pad>Die Bruttose werden nicht mit Monsteren\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([ 316,    3, 9465,   17,  235,    7,   15,  155,  311,  181,  177,   29,\n",
      "           3])\n",
      "generated target text: Die Bruttoseit nicht mit denn\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465,   17,  235,    7,   15,  155])\n",
      "generated target text: <pad>Die Bruttoseit\n",
      "========== Speculative Sampling Iteration 6 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    15,\n",
      "           404,   311,   181, 18117]])\n",
      "generated draft text: <pad>Die Bruttoseite werden nicht mit Monster\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([ 316,    3, 9465,   17,  235,    7,   15,  155,   35,    3,  311,  181,\n",
      "         177,   29])\n",
      "generated target text: Die Bruttoseiten  nicht mit denn\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465,   17,  235,    7,   15,  155,   35])\n",
      "generated target text: <pad>Die Bruttoseiten\n",
      "========== Speculative Sampling Iteration 7 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "           404,   311,   181,   340, 18117]])\n",
      "generated draft text: <pad>Die Bruttoseiten werden nicht mit dem Monster\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "          311,   181,   177, 20256,    29])\n",
      "generated target text: Die Bruttoseiten  nicht mit den Kampfn\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([   0,  316,    3, 9465,   17,  235,    7,   15,  155,   35,    3])\n",
      "generated target text: <pad>Die Bruttoseiten\n",
      "========== Speculative Sampling Iteration 8 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181, 18117]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit Monster\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,    29])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit demn\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem\n",
      "========== Speculative Sampling Iteration 9 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181,   340, 18117,     6,  2889,   292,\n",
      "           311]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit dem Monster, damit Sie nicht\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,   961,    29,   561,   292,   289,\n",
      "          236])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit dem Gen um Sie sich ein\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340,   961])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem Ge\n",
      "========== Speculative Sampling Iteration 10 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181,   340,   961,   860,  3142,     6,\n",
      "          2889,   292]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit dem Geschick, damit Sie\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,   961,    89,    51,     6,   561,\n",
      "          292,   289])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit dem Gefm, um Sie sich\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340,   961,    89])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gef\n",
      "========== Speculative Sampling Iteration 11 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "           159,     6,  2889]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, damit\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,   961,    89,  7423,    29,   159,\n",
      "            6,   561,   292])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um Sie\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "          159,     6,   561])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um\n",
      "========== Speculative Sampling Iteration 12 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "           159,     6,   561,   292,   170,   665,   961,    89]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um Sie zu einem Gef\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,   961,    89,  7423,    29,   159,\n",
      "            6,   561,   289,  2619,   665,   961,    89,  7423])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich selbst einem Gefäng\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "          159,     6,   561,   289])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich\n",
      "========== Speculative Sampling Iteration 13 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "           159,     6,   561,   289,   170,   665,   961,    89,  7423]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich zu einem Gefäng\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,   961,    89,  7423,    29,   159,\n",
      "            6,   561,   289,  2619,   665,   961,    89,  7423,    29])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich selbst einem Gefängn\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "          159,     6,   561,   289,  2619])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich selbst\n",
      "========== Speculative Sampling Iteration 14 ==========\n",
      "=== Draft Generation\n",
      "generated draft tokens: tensor([[    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "             3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "           159,     6,   561,   289,  2619,   236,   961,    89,  7423,    29]])\n",
      "generated draft text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich selbst ein Gefängn\n",
      "=== Target Generation\n",
      "generated target tokens: tensor([  316,     3,  9465,    17,   235,     7,    15,   155,    35,     3,\n",
      "        20854,    29,   311,   181,   340,   961,    89,  7423,    29,   159,\n",
      "            6,   561,   289,  2619,   170,   961,    89,  7423,    29,   159])\n",
      "generated target text: Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich selbst zu Gefängnis\n",
      "=== Validated Generation\n",
      "generated target tokens: tensor([    0,   316,     3,  9465,    17,   235,     7,    15,   155,    35,\n",
      "            3, 20854,    29,   311,   181,   340,   961,    89,  7423,    29,\n",
      "          159,     6,   561,   289,  2619,   170])\n",
      "generated target text: <pad>Die Bruttoseiten kämpfen nicht mit dem Gefängnis, um sich selbst zu\n"
     ]
    }
   ],
   "source": [
    "# performing specculative sampling\n",
    "\n",
    "# initializing an empty input to feed to the decoder. This is updated each loop with valid generations\n",
    "decoder_ids= draft_model._shift_right(draft_tokenizer(\"\", return_tensors=\"pt\").input_ids)\n",
    "\n",
    "# defining input. T5 is an encoder-decoder model, so input and output are handled seperatly\n",
    "input_ids= draft_tokenizer(\"Translate to German \\n Battle not with monsters, lest you become a monster, and if you gaze into the abyss, the abyss gazes also into you.\",\n",
    "                           return_tensors=\"pt\").input_ids\n",
    "\n",
    "# defining the number of draft generations\n",
    "k= 5\n",
    "\n",
    "# keeps track of generation information, for later printouts\n",
    "generated= []\n",
    "\n",
    "# generating Text\n",
    "iter= 0\n",
    "for _ in range(15):\n",
    "    print('========== Speculative Sampling Iteration {} =========='.format(iter))\n",
    "    iter += 1\n",
    "\n",
    "    # creating a holding place for the generated draft\n",
    "    decoder_ids_draft= decoder_ids.clone()\n",
    "\n",
    "    before_text= draft_tokenizer.decode(decoder_ids_draft[0])\n",
    "    initial_length= decoder_ids.shape[1]\n",
    "\n",
    "    # generating draft\n",
    "    for i in range(k):\n",
    "\n",
    "        # predicting the next token with the draft model\n",
    "        with torch.no_grad():\n",
    "            logits= draft_model(input_ids=input_ids, decoder_input_ids=decoder_ids_draft).logits\n",
    "            genid= torch.argmax(logits, dim=2)[0][-1]\n",
    "\n",
    "        # appending the generated id to the draft\n",
    "        genid= genid.expand(1,1)\n",
    "        decoder_ids_draft= torch.cat((decoder_ids_draft,genid),1)\n",
    "\n",
    "    print('=== Draft Generation')\n",
    "    current_draft= draft_tokenizer.decode(decoder_ids_draft[0])\n",
    "    print('Generated draft tokens: {}'.format(decoder_ids_draft))\n",
    "    print('Generated draft text: {}'.format(current_draft))\n",
    "\n",
    "    # generating all next token predictions with the target\n",
    "    logits= target_model(input_ids=input_ids, decoder_input_ids=decoder_ids_draft).logits\n",
    "    genids= torch.argmax(logits, dim=2)[0]\n",
    "    print('=== Target Generation')\n",
    "    current_target= draft_tokenizer.decode(genids)\n",
    "    print('Generated target tokens: {}'.format(genids))\n",
    "    print('Generated target text: {}'.format(current_target))\n",
    "\n",
    "    # checking draft against target\n",
    "    for i, (dv, tv) in enumerate(zip(decoder_ids_draft[0,1:],genids[:-1])):\n",
    "        # target does not agree with the draft\n",
    "        if dv != tv:\n",
    "            # genids is next word, so this is done to preserve the first token\n",
    "            first_token= decoder_ids[0][:1]\n",
    "            decoder_ids= genids[:i+1]\n",
    "            decoder_ids= torch.cat((first_token,decoder_ids),0)\n",
    "            break\n",
    "    else:\n",
    "        # no disagreements\n",
    "        decoder_ids= genids\n",
    "\n",
    "    print('=== Validated Generation')\n",
    "    current_target= draft_tokenizer.decode(decoder_ids)\n",
    "    print('Generated target tokens: {}'.format(decoder_ids))\n",
    "    print('Generated target text: {}'.format(current_target))\n",
    "\n",
    "    # expanding dimensions so that the shape of the tensor is the same\n",
    "    decoder_ids= decoder_ids.expand(1,len(decoder_ids))\n",
    "\n",
    "    # logging\n",
    "    numgen= decoder_ids.shape[1] - initial_length\n",
    "    generated.append({'tokens generated': numgen,\n",
    "                      'text before': before_text,\n",
    "                      'text after': current_target})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDAuEUwHJBgK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J1MY4kuJBkL"
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/speculative-sampling-intuitively-and-exhaustively-explained-2daca347dbb9"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
