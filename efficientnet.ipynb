{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet - Implementation from scratch in PyTorch\n",
        "\n",
        "EfficientNet is a family of convolutional neural networks that were introduced to achieve high accuracy with significantly fewer parameters and lower computational cost. The authors demonstrated the effect of scaling on the ResNet and MobileNet and they also discovered a whole family of networks called EfficientNet through neural architecture search.\n",
        "\n",
        "https://arxiv.org/abs/1905.11946"
      ],
      "metadata": {
        "id": "SANbdWXTGcow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K4WrSniUGCqM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "bBnrVnkhGnVt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many trainable weights the model has\n",
        "def count_parameters(model) -> None:\n",
        "    total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "id": "5Mezx6HsGnZA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Implementation\n",
        "\n",
        "Starting by the fundamental building block of a CNN, represented by a convolutional layer. Notably, the SiLU activation is consistently utilized throughout the entire architecture as mentioned in the original paper.\n",
        "\n",
        "Groups is specified to control how convolution is applied to input. If group=1, then a kernel is applied to all input channels and if group=in_channel (depthwise convolution), then a single convolutional kernel is applied for each input channel."
      ],
      "metadata": {
        "id": "KbDsc3epHrT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements one customizable CNN layer.\n",
        "    EfficientNet-style: Input -> Conv2d -> BatchNorm2d -> SiLU -> Output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups=1,\n",
        "                 bias=False, norm=True, activation=None) -> None:\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.conv= nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=bias\n",
        "        )\n",
        "        # Batch Normalization to stabilize training\n",
        "        self.norm= nn.BatchNorm2d(out_channels) if norm else None\n",
        "        # Activation function -- SiLU is the default in EfficientNet\n",
        "        self.activation= activation\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.conv(x)\n",
        "        if self.norm is not None:\n",
        "            x= self.norm(x)\n",
        "        if self.activation is not None:\n",
        "            x= self.activation(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "meSgQrUdHfX3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Squeeze-and-Excitation module recalibrates channel-wise feature responses by learning global dependencies. It \"squeezes\" global spatial information into a channel descriptor using global average pooling (GAP) and then excites (reweights) each channel through a lightweight network. The primary goal is to enhance feature representation by selectively amplifying important channels.\n",
        "\n",
        "The mechanism applies GAP to condense spatial information into a single descriptor per channel, creating a compact representation of global spatial information. These pooled features are passed to a CNN bottleneck structure and a sigmoid activation is applied on the output features, providing attention weights. The computed attention weights are applied to the original feature maps via channel-wise multiplication, dynamically emphasizing essential channels."
      ],
      "metadata": {
        "id": "VxI74-uEv1HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a Squeeze-and-Excitation module.\n",
        "    It squeezes global spatial information into a channel descriptor and re-scales the channels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, squeezed_dim, activation=None) -> None:\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        # Activation function -- SiLU is the default in EfficientNet\n",
        "        activation= nn.SiLU(inplace=True) if activation is None else activation\n",
        "\n",
        "        # Global average pooling: C x H x W -> C x 1 x 1\n",
        "        self.average_pool= nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        # 1x1 convolution reduces the channel dimension\n",
        "        self.conv1= ConvLayer(\n",
        "            in_channels, squeezed_dim, kernel_size=1, stride=1, padding=0,\n",
        "            bias=True, norm=False, activation=activation\n",
        "        )\n",
        "        # 1x1 convolution restores the channel dimension\n",
        "        # Sigmoid activation to obtain channel-wise weights between 0 and 1\n",
        "        self.conv2= ConvLayer(\n",
        "            squeezed_dim, in_channels, kernel_size=1, stride=1, padding=0,\n",
        "            bias=True, norm=False, activation=nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        se= self.average_pool(x)\n",
        "        se= self.conv1(se)\n",
        "        se= self.conv2(se)\n",
        "\n",
        "        return x * se\n"
      ],
      "metadata": {
        "id": "Uk-Ul6e-HffJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MBConv consists of inverted residual connections and depthwise separable convolutions, which improve computational efficiency while maintaining high representational power.\n",
        "\n",
        "The MBConv block includes:\n",
        "\n",
        "- Expansion Convolution: Expands the input channels using a pointwise (1x1) convolution.\n",
        "- Depthwise Separable Convolution: A depthwise convolution (operates per channel) followed by a pointwise (1x1) convolution, reducing computational cost.\n",
        "- Squeeze-and-Excitation: This component applies GAP followed by a lightweight network to generate channel-wise attention weights, which are then applied to the feature maps.\n",
        "- Stochastic Depth Regularization: Used to improve generalization and training efficiency. It randomly drops entire residual blocks during training, reducing computational load and acting as regularization to prevent overfitting.\n",
        "- Residual Connection (if input/output dimensions match): Helps with gradient flow and prevents information loss.\n",
        "\n",
        "**NOTE:** The inverted bottleneck as in MBConv does the reverse as in ResNets -- instead of reducing the number of channels, the first 1x1 conv layer increases the number of channels to 3 times the initial."
      ],
      "metadata": {
        "id": "Sh4_MogV0puR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StochasticDepth(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements stochastic depth regularization.\n",
        "    During training, randomly drops the output of the block with probability survival_prob\n",
        "    scaling the remaining output to maintain the expected value.\n",
        "    - mode: 'row' to drop per-sample, 'batch' to drop entire batch together.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, survival_prob, mode='row') -> None:\n",
        "        super(StochasticDepth, self).__init__()\n",
        "        assert 0.0 <= survival_prob <= 1.0, \"survival_prob must be in [0, 1]\"\n",
        "        assert mode in ('row', 'batch'), \"mode must be 'row' or 'batch'\"\n",
        "        self.survival_prob= survival_prob\n",
        "        self.mode= mode\n",
        "\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f\"p={self.survival_prob}, mode={self.mode}\"\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if (not self.training) or self.survival_prob in (0.0, 1.0):\n",
        "            return x\n",
        "\n",
        "        if self.mode== 'row':\n",
        "            # Mask with the same batch size and shape (broadcasted over spatial dimensions)\n",
        "            mask_shape= (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "        else:  # 'batch'\n",
        "            # Mask for the whole batch\n",
        "            mask_shape= (1,) * x.ndim\n",
        "\n",
        "        keep_mask= (torch.rand(mask_shape, device=x.device) < self.survival_prob).type_as(x)\n",
        "        # Scale the output to maintain expected value and apply the mask\n",
        "        return torch.div(x, self.survival_prob) * keep_mask\n"
      ],
      "metadata": {
        "id": "4eZ0xifhJlcg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MBConv(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a Mobile Inverted Residual Block (inspired by MobileNetV3).\n",
        "    Residual (skip) connection is used if stride==1 and input/output channels match.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio, reduction=4,\n",
        "                 drop_path=0.1, bias=False, activation=None) -> None:\n",
        "        super(MBConv, self).__init__()\n",
        "        assert stride in [1, 2], \"Stride must be 1 or 2.\"\n",
        "        # Activation function -- SiLU is the default in EfficientNet\n",
        "        activation= nn.SiLU(inplace=True) if activation is None else activation\n",
        "        # Define dimensions for intermediate layers\n",
        "        hidden_dim= int(round(in_channels * expand_ratio))\n",
        "        # For squeeze and excitation module\n",
        "        reduced_dim= max(1, in_channels // reduction)\n",
        "        # Calculate padding to maintain spatial dimensions\n",
        "        padding= kernel_size // 2\n",
        "\n",
        "        # The inverted bottleneck block\n",
        "        self.mb_conv= nn.Sequential(\n",
        "            # Optional expansion phase (1x1 conv + BN + Activation)\n",
        "            ConvLayer(\n",
        "                in_channels, hidden_dim, kernel_size=1, stride=1, padding=0,\n",
        "                bias=bias, activation=activation\n",
        "            ) if (in_channels != hidden_dim) else nn.Identity(),\n",
        "            # Depthwise convolution\n",
        "            ConvLayer(\n",
        "                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,\n",
        "                bias=bias, activation=activation\n",
        "            ),\n",
        "            # Squeeze-and-Excitation\n",
        "            SqueezeExcitation(hidden_dim, reduced_dim, activation=activation),\n",
        "            # Projection phase (1x1 conv + BN) -- reduce channels to out_channels\n",
        "            ConvLayer(\n",
        "                hidden_dim, out_channels, kernel_size=1, stride=1, padding=0,\n",
        "                bias=bias, activation=None\n",
        "            )\n",
        "        )\n",
        "        # When dim(x) == dim(F) and no spatial downsampling is applied -> use residual connection\n",
        "        self.use_residual= (in_channels == out_channels and stride == 1)\n",
        "        # For stochastic depth\n",
        "        self.drop_path= StochasticDepth(drop_path) if drop_path > 0.0 else nn.Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Save the original input for the residual connection\n",
        "        identity= x\n",
        "        # Compute the inverted bottleneck block convolutions\n",
        "        out= self.mb_conv(x)\n",
        "        if self.use_residual:\n",
        "            out= identity + self.drop_path(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "2RRnDqy6HfcP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Stochastic depth drops entire paths (like shortcut + block output). It is usually applied to deep residual blocks (globally).\n",
        "- Dropout drops individual activations within a layer. It is usually applied to fully connected layers or inside convolutions (locally).\n",
        "\n",
        "Thus, they regularize different levels of the model. But using both inside the same convolutional blocks might cause over-regularization, especially if survival probability is low and dropout rate is high.\n",
        "\n",
        "# Define configs for different EfficientNet versions\n",
        "\n",
        "The motivation behind introducing $\\phi$ lies in the understanding that increasing the depth of the model linearly impacts the FLOPS, while changing the width or resolution has a quadratic impact. These constants were derived through neural architecture search, drawing inspiration from MnasNet."
      ],
      "metadata": {
        "id": "oQoPH7TdHgXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model= [\n",
        "    # expand_ratio, out_channels, repeats, stride, kernel_size\n",
        "    [1, 16,  1, 1, 3],\n",
        "    [6, 24,  2, 2, 3],\n",
        "    [6, 40,  2, 2, 5],\n",
        "    [6, 80,  3, 2, 3],\n",
        "    [6, 112, 3, 1, 5],\n",
        "    [6, 192, 4, 2, 5],\n",
        "    [6, 320, 1, 1, 3],\n",
        "]\n",
        "\n",
        "model_hparameters= {}                # base_model, alpha, beta, resolution, dropout\n",
        "model_hparameters['efficientnet-b0']= (base_model, 1.0, 1.0, 224, 0.2)\n",
        "model_hparameters['efficientnet-b1']= (base_model, 1.1, 1.0, 240, 0.2)\n",
        "model_hparameters['efficientnet-b2']= (base_model, 1.2, 1.1, 260, 0.3)\n",
        "model_hparameters['efficientnet-b3']= (base_model, 1.4, 1.2, 300, 0.3)\n",
        "model_hparameters['efficientnet-b4']= (base_model, 1.8, 1.4, 380, 0.4)\n",
        "model_hparameters['efficientnet-b5']= (base_model, 2.2, 1.6, 456, 0.4)\n",
        "model_hparameters['efficientnet-b6']= (base_model, 2.6, 1.8, 528, 0.5)\n",
        "model_hparameters['efficientnet-b7']= (base_model, 3.1, 2.0, 600, 0.5)"
      ],
      "metadata": {
        "id": "ZDdk1tsxHfUN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the EfficientNet\n",
        "\n",
        "**Stem and Head**\n",
        "\n",
        "- Stem: The network begins with a standard convolutional layer (with stride 2) to reduce spatial resolution.\n",
        "- Head: After the MBConv blocks, a final 1x1 convolution, GAP, and a fully connected layer (classifier) are applied to produce the final predictions.\n",
        "\n",
        "Scaling up any dimension of network width, depth, or resolution improves accuracy, but the accuracy gain diminishes for bigger models. In order to pursue better accuracy and efficiency, it is critical to balance all dimensions of network width, depth, and resolution during ConvNet scaling.\n",
        "\n",
        "- Depth Scaling: Increases the number of layers (blocks) in the network.\n",
        "- Width Scaling: Increases the number of channels (filters) in each layer.\n",
        "- Resolution Scaling: Increases the input image size.\n",
        "\n",
        "**Compound Scaling**: One of the major contributions of EfficientNet is its compound scaling method. Instead of scaling only one dimension (e.g., depth or width), EfficientNet scales all three dimensions (depth, width, and resolution) in a principled manner using a compound coefficient $\\phi$."
      ],
      "metadata": {
        "id": "6Zc2Zm66HWWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNet(nn.Module):\n",
        "    \"\"\"\n",
        "    EfficientNet implementation using MBConv blocks with compound scaling.\n",
        "    The compound scaling coefficients (alpha and beta) are based on the model_version.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_version, in_channels, num_classes, stem_channels=32,\n",
        "                 last_channels=None, reduction=4, bias=False, activation=None) -> None:\n",
        "        super(EfficientNet, self).__init__()\n",
        "        # Configs from model_version\n",
        "        base_model, alpha, beta, resolution, drop_path= model_version\n",
        "        # Base channels scaled by width_factor\n",
        "        stem_channels= self.round_channels(stem_channels, beta)\n",
        "        # Activation function -- SiLU is the default in EfficientNet\n",
        "        activation= nn.SiLU(inplace=True) if activation is None else activation\n",
        "\n",
        "        # Build the backbone feature extractor\n",
        "        self.backbone= nn.ModuleList([\n",
        "            # Stem: Initial 3x3 conv with stride 2\n",
        "            ConvLayer(\n",
        "                in_channels, stem_channels, kernel_size=3, stride=2, padding=1,\n",
        "                bias=bias, activation=activation\n",
        "            )\n",
        "        ])\n",
        "        # Update in_channels for subsequent layers\n",
        "        in_channels= stem_channels\n",
        "\n",
        "        # MBConv layers\n",
        "        # For each layer in the base_model, scale the number of channels and number of repeats\n",
        "        total_blocks= sum(self.adjust_depth(base_model[i][2], alpha) for i in range(len(base_model)))\n",
        "        block_id= 0\n",
        "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
        "            # Scale the out_channels using width_factor and round up to a multiple of the reduction\n",
        "            out_channels = self.round_channels(channels, beta)\n",
        "            layer_repeats= self.adjust_depth(repeats, alpha)\n",
        "\n",
        "            for layer in range(layer_repeats):\n",
        "                # The first layer in a block uses the specified stride; for others, use stride 1\n",
        "                stride= stride if layer== 0 else 1\n",
        "                # Stochastic depth probability based on the depth of the layer\n",
        "                sd_prob= drop_path * float(block_id) / total_blocks\n",
        "\n",
        "                self.backbone.append(\n",
        "                    MBConv(\n",
        "                        in_channels, out_channels, kernel_size, stride, expand_ratio, reduction,\n",
        "                        sd_prob, bias, activation\n",
        "                    )\n",
        "                )\n",
        "                # Update in_channels for subsequent layers\n",
        "                in_channels= out_channels\n",
        "                block_id += 1\n",
        "\n",
        "\n",
        "        # Final channel dimension, scaled up to a multiple of the reduction factor\n",
        "        last_channels= last_channels if last_channels is not None else reduction * in_channels\n",
        "\n",
        "        self.backbone.append(\n",
        "            # Final 1x1 conv to adjust channel dimension before classification\n",
        "            ConvLayer(\n",
        "                in_channels, last_channels, kernel_size=1, stride=1, padding=0,\n",
        "                bias=bias, activation=activation\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Pooling and classification head to produce the class logits\n",
        "        self.pool= nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.head= nn.Sequential(\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Dropout(p=drop_path),\n",
        "            nn.Linear(last_channels, num_classes),\n",
        "        )\n",
        "\n",
        "        # initialize parameters with Xavier initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def round_channels(channels, width_mult, divisor=8, min_value=None):\n",
        "        \"\"\"\n",
        "        Round number of channels based on width multiplier (beta).\n",
        "        Ensure that all layers have a channel number that is divisible by 'divisor'.\n",
        "        - This helps with efficient hardware utilization.\n",
        "        \"\"\"\n",
        "        if min_value is None:\n",
        "            min_value= divisor\n",
        "\n",
        "        new_channels= channels * width_mult\n",
        "        new_channels= max(min_value, int(new_channels + divisor / 2) // divisor * divisor)\n",
        "        # Prevent rounding down by more than 10%\n",
        "        if new_channels < 0.9 * channels:\n",
        "            new_channels += divisor\n",
        "\n",
        "        return int(new_channels)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def adjust_depth(num_layers, depth_mult):\n",
        "        \"\"\"\n",
        "        Adjust the number of layers based on depth multiplier (alpha).\n",
        "        \"\"\"\n",
        "        return int(math.ceil(num_layers * depth_mult))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.backbone:\n",
        "            x= layer(x)\n",
        "        x= self.pool(x)\n",
        "        x= self.head(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ZwzrxsDYGncE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchvision.models import EfficientNet_B0_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iCXZVBNw10q",
        "outputId": "69ae24b4-b160-4606-c929-5e8ee8abec0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 220MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 5288548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img= torch.randn(1, 3, 224, 224).to(device)  # a single image batch\n",
        "model= EfficientNet(model_hparameters['efficientnet-b0'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "eeJ2eiH9IMk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e33810-2888-4221-ad6e-b23e5a5ebb95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 5288548\n",
            "torch.Size([1, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (backbone): ModuleList(\n",
              "    (0): ConvLayer(\n",
              "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.0125, mode=row)\n",
              "    )\n",
              "    (3): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.025, mode=row)\n",
              "    )\n",
              "    (4): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "    )\n",
              "    (5): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.05, mode=row)\n",
              "    )\n",
              "    (6): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.0625, mode=row)\n",
              "    )\n",
              "    (7): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "    )\n",
              "    (8): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "    )\n",
              "    (9): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.1, mode=row)\n",
              "    )\n",
              "    (10): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.1125, mode=row)\n",
              "    )\n",
              "    (11): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.125, mode=row)\n",
              "    )\n",
              "    (12): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.1375, mode=row)\n",
              "    )\n",
              "    (13): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "    )\n",
              "    (14): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.1625, mode=row)\n",
              "    )\n",
              "    (15): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "    )\n",
              "    (16): MBConv(\n",
              "      (mb_conv): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (norm): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "          (conv1): ConvLayer(\n",
              "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): ConvLayer(\n",
              "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (3): ConvLayer(\n",
              "          (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (drop_path): StochasticDepth(p=0.1875, mode=row)\n",
              "    )\n",
              "    (17): ConvLayer(\n",
              "      (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (head): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "    (2): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B1_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYW9xlutHXjl",
        "outputId": "bb4260ad-443d-4fd2-85f3-5ea574b902de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n",
            "100%|██████████| 30.1M/30.1M [00:00<00:00, 152MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 7794184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b1'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHVhwDJvHXnC",
        "outputId": "08ffd876-269f-47f3-fba8-970f99853300"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 7794184\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B2_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IsBIKioHXri",
        "outputId": "ad783c9a-7c3a-4ffe-b918-a8c28754c750"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 260MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 9109994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b2'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNzV_aa7HXwE",
        "outputId": "8369ad09-4d3c-40f7-8080-f94b723e1cea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 9109994\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B3_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvbQEf3HHXz0",
        "outputId": "16b7e7be-56a7-433d-c346-5bb05c26afd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
            "100%|██████████| 47.2M/47.2M [00:00<00:00, 179MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 12233232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b3'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg7ApxRuHX4A",
        "outputId": "43877c4d-2bf1-4b74-f195-c5f06ba3ce10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 12227212\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B4_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOmJyY6NHX6l",
        "outputId": "bf6ba17a-11ab-43aa-f10a-449465682d68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth\n",
            "100%|██████████| 74.5M/74.5M [00:00<00:00, 218MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 19341616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b4'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRoHWGqWHf-9",
        "outputId": "dfcf5ac1-0984-4f0f-f1d6-a9bc5a1b418f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 19341616\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B5_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b5(weights=EfficientNet_B5_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ0Ssmw-HgCY",
        "outputId": "b2fadda7-45f2-4054-c6ba-309ca27d0d03"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b5_lukemelas-1a07897c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b5_lukemelas-1a07897c.pth\n",
            "100%|██████████| 117M/117M [00:02<00:00, 45.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 30389784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b5'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvnGVQ3WHgFg",
        "outputId": "f2a0bb29-c563-4650-8d80-79a5a599186e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 30389784\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B6_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b6(weights=EfficientNet_B6_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-7pylOWHgJT",
        "outputId": "cfe7cdb8-9a02-4337-af22-fee50f771f7a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b6_lukemelas-24a108a5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b6_lukemelas-24a108a5.pth\n",
            "100%|██████████| 165M/165M [00:03<00:00, 45.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 43040704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b6'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2eRFKukHqvN",
        "outputId": "5c8f7e37-924b-4bdb-bc3d-c0c6c94db103"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 43040704\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import EfficientNet_B7_Weights\n",
        "\n",
        "tvis_model= models.efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz14slTJHqzL",
        "outputId": "aef09572-0c62-48b8-d40a-b87ae3638835"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b7_lukemelas-c5b4e57e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b7_lukemelas-c5b4e57e.pth\n",
            "100%|██████████| 255M/255M [00:00<00:00, 342MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 66347960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= EfficientNet(model_hparameters['efficientnet-b7'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzGxQoqBH5wS",
        "outputId": "6e680e6d-d0cb-48d8-d6d4-9acd7185acc4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 66347960\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a EfficientNet model from scratch"
      ],
      "metadata": {
        "id": "vLd8fcA4HRDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "6xZhJyB-Gnfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation -- define transformations for the dataset\n",
        "transform= transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std= [0.2023, 0.1994, 0.2010]), # CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# load the CIFAR-10 dataset\n",
        "train_dataset= datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "train_size= int(0.9 * len(train_dataset))\n",
        "val_size  = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset= random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size= 128\n",
        "train_loader= DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "lhiMtAjRIVRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d0c76a-2ad4-4df5-9519-a14b4844de43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(val_loader)"
      ],
      "metadata": {
        "id": "x2upZwRFIVU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb56ffb-7926-4033-9bad-794ba98dc95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Function\n",
        "\n",
        "TODO:\n",
        "\n",
        "- Data augmentation for training.\n",
        "- Play with different learning rate values.\n",
        "- Play with other EfficientNet versions."
      ],
      "metadata": {
        "id": "QR0fYm-gHNuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs,\n",
        "            device, eval_interval=1, verbose=False):\n",
        "\n",
        "    tr_loss_hist= []\n",
        "    vl_loss_hist= []\n",
        "\n",
        "    # --- training loop ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_loss= []\n",
        "        start= time.time()\n",
        "\n",
        "        # --- training steps ---\n",
        "        # iterating over all batches\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            # --- minibatch construction ---\n",
        "            images= images.to(device, non_blocking=True)\n",
        "            labels= labels.to(device, non_blocking=True)\n",
        "\n",
        "            # --- forward pass and get loss ---\n",
        "            logits= model(images)\n",
        "            loss= criterion(logits, labels)\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            # --- backward pass to calculate the gradients ---\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # --- update the parameters using the gradient ---\n",
        "            optimizer.step()\n",
        "\n",
        "        # --- evaluation and track stats ---\n",
        "        tr_loss_hist.append(np.mean(batch_loss))\n",
        "\n",
        "        if epoch% eval_interval== 0 or epoch== epochs-1:\n",
        "            model.eval()\n",
        "            val_loss= []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels= images.to(device), labels.to(device)\n",
        "                    logits= model(images)\n",
        "                    loss_v= criterion(logits, labels)\n",
        "                    val_loss.append(loss_v.item())\n",
        "\n",
        "            val_loss= np.mean(val_loss)\n",
        "            end= time.time()\n",
        "            dt= end - start\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch: {epoch} | Train Loss: {tr_loss_hist[-1]:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f} | dt/epoch: {dt*1000:.2f}ms\")\n",
        "\n",
        "            # for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        vl_loss_hist.append(val_loss)\n",
        "\n",
        "    return tr_loss_hist, vl_loss_hist\n"
      ],
      "metadata": {
        "id": "qntwlcedGnjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device, verbose=False):\n",
        "    model.eval()\n",
        "    correct= 0\n",
        "    total= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels= images.to(device), labels.to(device)\n",
        "            logits= model(images)\n",
        "            y_pred= torch.argmax(logits, dim=1)\n",
        "            correct += (y_pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc= correct / total\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {(acc * 100):.2f}%\")\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "IbrOlZeFH8NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(train_loss, valid_loss):\n",
        "    # plot training and validation losses\n",
        "    plt.plot(train_loss, label='Train Loss')\n",
        "    plt.plot(valid_loss, label='Validation Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "Rxm606euH8RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup using TF32 and Fused AdamW"
      ],
      "metadata": {
        "id": "nXVDS6aEHJ74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_fused= False\n",
        "\n",
        "if device== 'cuda': # TF32 computationally more efficient (slightly the same precision of FP32)\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    # create AdamW optimizer and use the fused version of it is available\n",
        "    fused_available= 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "    # fused is a lot faster when it is available and when running on cuda\n",
        "    use_fused= fused_available\n",
        "\n",
        "# --- EfficientNet-B0 ---\n",
        "in_channels= 3\n",
        "num_classes= 10\n",
        "\n",
        "model= EfficientNet(model_hparameters['efficientnet-b0'], in_channels, num_classes).to(device)\n",
        "count_parameters(model)\n",
        "\n",
        "\n",
        "# train_loader has size 352, so 20 epochs have 7,040 steps\n",
        "epochs= 20\n",
        "learning_rate= 5e-4\n",
        "\n",
        "optimizer= torch.optim.AdamW(\n",
        "    model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-4,\n",
        "    fused=use_fused\n",
        ")\n",
        "print(f\"Using fused AdamW: {use_fused}\")\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "# for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "scheduler= ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "8Kh7NAWPGnn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87068992-c453-46dd-dff5-fcd7476b1976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 4020358\n",
            "Using fused AdamW: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss, vl_loss= trainer(model, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                          epochs, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-xsd1hMrGnq",
        "outputId": "bc670be8-5cb4-4ad0-f877-b99a8f5b4069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 1.6780 | Val Loss: 1.2487 | dt/epoch: 90548.99ms\n",
            "Epoch: 1 | Train Loss: 1.0799 | Val Loss: 0.8454 | dt/epoch: 89586.77ms\n",
            "Epoch: 2 | Train Loss: 0.8028 | Val Loss: 0.7028 | dt/epoch: 89959.65ms\n",
            "Epoch: 3 | Train Loss: 0.6298 | Val Loss: 0.5728 | dt/epoch: 89646.99ms\n",
            "Epoch: 4 | Train Loss: 0.5299 | Val Loss: 0.5115 | dt/epoch: 89695.04ms\n",
            "Epoch: 5 | Train Loss: 0.4559 | Val Loss: 0.4582 | dt/epoch: 89671.36ms\n",
            "Epoch: 6 | Train Loss: 0.3984 | Val Loss: 0.4455 | dt/epoch: 89691.36ms\n",
            "Epoch: 7 | Train Loss: 0.3507 | Val Loss: 0.4175 | dt/epoch: 89754.94ms\n",
            "Epoch: 8 | Train Loss: 0.3082 | Val Loss: 0.4394 | dt/epoch: 90310.51ms\n",
            "Epoch: 9 | Train Loss: 0.2758 | Val Loss: 0.4174 | dt/epoch: 89850.34ms\n",
            "Epoch: 10 | Train Loss: 0.2419 | Val Loss: 0.4129 | dt/epoch: 89511.35ms\n",
            "Epoch: 11 | Train Loss: 0.2177 | Val Loss: 0.3817 | dt/epoch: 89862.18ms\n",
            "Epoch: 12 | Train Loss: 0.1987 | Val Loss: 0.4116 | dt/epoch: 89570.01ms\n",
            "Epoch: 13 | Train Loss: 0.1712 | Val Loss: 0.4080 | dt/epoch: 89561.52ms\n",
            "Epoch: 14 | Train Loss: 0.1523 | Val Loss: 0.3985 | dt/epoch: 89863.33ms\n",
            "Epoch: 15 | Train Loss: 0.1440 | Val Loss: 0.4100 | dt/epoch: 89912.87ms\n",
            "Epoch: 16 | Train Loss: 0.1317 | Val Loss: 0.4070 | dt/epoch: 89896.20ms\n",
            "Epoch: 17 | Train Loss: 0.1138 | Val Loss: 0.4197 | dt/epoch: 89828.20ms\n",
            "Epoch: 18 | Train Loss: 0.0554 | Val Loss: 0.3671 | dt/epoch: 89587.39ms\n",
            "Epoch: 19 | Train Loss: 0.0368 | Val Loss: 0.3477 | dt/epoch: 89662.70ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "plot_losses(tr_loss, vl_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RkJjhrmprG11",
        "outputId": "06592a7e-6252-4570-ea03-d629f9708530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnet_acc= evaluate_model(model, test_loader, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RniNK6scrHA_",
        "outputId": "b7b52b1a-77e4-468b-85cc-d98ef7dde4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/@aniketthomas27/efficientnet-implementation-from-scratch-in-pytorch-a-step-by-step-guide-a7bb96f2bdaa\n",
        "# https://amaarora.github.io/posts/2020-08-13-efficientnet.html\n",
        "# https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/CNN_architectures/pytorch_efficientnet.py\n",
        "# https://medium.com/technological-singularity/efficientnet-revolutionizing-deep-learning-through-model-efficiency-0ed5485f9a6f"
      ],
      "metadata": {
        "id": "--FLwsEqGnrC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}