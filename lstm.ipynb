{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7UeKRnpObBC"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "mH5RCdleidUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesData:\n",
        "    \"\"\"\n",
        "    Dataset class for time series data.\n",
        "    Parameters:\n",
        "        ticker (str): stock ticker symbol\n",
        "        start_date (str): start date for data retrieval\n",
        "        end_date (str): end date for data retrieval\n",
        "        look_back (int): number of previous time steps to include in each sample\n",
        "        train_size (float): proportion of data to use for training\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date, end_date, look_back=1, train_size=0.67) -> None:\n",
        "        self.start_date= start_date\n",
        "        self.end_date= end_date\n",
        "        self.look_back= look_back\n",
        "        self.train_size= train_size\n",
        "\n",
        "\n",
        "    def minmax_scaler(self, train, test, eps=1e-7):\n",
        "        \"\"\"\n",
        "        Min-max scaling of the data.\n",
        "        Parameters:\n",
        "            train (np.ndarray): training data\n",
        "            test (np.ndarray): testing data\n",
        "        \"\"\"\n",
        "\n",
        "        tr_min= np.min(train, 0)\n",
        "        tr_max= np.max(train, 0)\n",
        "\n",
        "        # normalizing the training data\n",
        "        scaled_train= (train - tr_min) / (tr_max - tr_min)\n",
        "        # normalizing the test data based on statistics from training data\n",
        "        scaled_test= (test - tr_min) / (tr_max - tr_min)\n",
        "\n",
        "        return scaled_train, scaled_test\n",
        "\n",
        "\n",
        "    def load_data(self, path):\n",
        "        \"\"\"\n",
        "        Load stock data.\n",
        "        Returns:\n",
        "            np.ndarray, training data\n",
        "            np.ndarray, testing data\n",
        "        \"\"\"\n",
        "\n",
        "        df= pd.read_csv(path)\n",
        "        df= df[(df['Date']>= self.start_date) & (df['Date'] <= self.end_date)]\n",
        "        df= df.set_index('Date')\n",
        "        df= df.sort_index()\n",
        "        df= df.loc[self.start_date:self.end_date]\n",
        "        df= df[['Close']].astype(float) # use closing price\n",
        "        df= df.values                   # convert DataFrame to np.array\n",
        "\n",
        "        train_size= int(len(df) * self.train_size)\n",
        "        train, test= self.minmax_scaler(df[0:train_size,:], df[train_size:len(df),:])\n",
        "\n",
        "        return train, test\n",
        "\n",
        "\n",
        "    def create_dataset(self, data):\n",
        "        \"\"\"\n",
        "        Create the dataset for time series prediction.\n",
        "        Parameters:\n",
        "            data (np.ndarray) input data\n",
        "        Returns:\n",
        "            np.ndarray, input data\n",
        "            np.ndarray, output data\n",
        "        \"\"\"\n",
        "\n",
        "        Xds, Yds= [], []\n",
        "        for i in range(len(data)-self.look_back):\n",
        "            feature= data[i : i+self.look_back]\n",
        "            target= data[i+1 : i+self.look_back+1]\n",
        "            Xds.append(feature)\n",
        "            Yds.append(target)\n",
        "\n",
        "        return np.array(Xds), np.array(Yds)\n",
        "\n",
        "\n",
        "    def split_train_test(self, path):\n",
        "        \"\"\"\n",
        "        Get the training and testing data.\n",
        "        Returns:\n",
        "            np.ndarray, training input\n",
        "            np.ndarray, training output\n",
        "            np.ndarray, testing input\n",
        "            np.ndarray, testing output\n",
        "        \"\"\"\n",
        "\n",
        "        train, test= self.load_data(path)\n",
        "        Xtr, Ytr= self.create_dataset(train)\n",
        "        Xte, Yte= self.create_dataset(test)\n",
        "\n",
        "        return Xtr, Ytr, Xte, Yte\n"
      ],
      "metadata": {
        "id": "42iao3fGKVA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "PATH= '/content/drive/My Drive/Colab Notebooks/data/Google_Stock_Train_2010_2022.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhzivqaUxWzm",
        "outputId": "435613db-f634-484f-c1f5-7fe5f37f6f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the dataset\n",
        "data= TimeSeriesData('2010-1-1', '2020-12-31', look_back=1)\n",
        "Xtr, Ytr, Xte, Yte= data.split_train_test(PATH)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "Xtr= np.reshape(Xtr, (Xtr.shape[0], Xtr.shape[1], 1))\n",
        "Xte= np.reshape(Xte, (Xte.shape[0], Xte.shape[1], 1))"
      ],
      "metadata": {
        "id": "ITzfBhLl3-Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This reshaping step adjusts the data format to what the LSTM expects. LSTMs require input to be in the shape of [samples, time steps, features]. Here:\n",
        "\n",
        "- samples - the number of data points.\n",
        "- time steps - the number of time steps per sample (look_back).\n",
        "- features - the number of features per time step (in this case, 1, because we are probably looking at one dimension of data like closing price).\n",
        "\n",
        "With look_back=1, it is quite surely that the accuracy would not be good for too little clues to predict. But this is a good example to demonstrate the structure of the LSTM model."
      ],
      "metadata": {
        "id": "aXQZyzTnGXM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility classes"
      ],
      "metadata": {
        "id": "PFqTaHYkYYP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightInitializer:\n",
        "    \"\"\"\n",
        "    WeightInitializer is a class that handles the initialization of weights. This is crucial as\n",
        "    different initialization methods can significantly affect the convergence behavior of an NN.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, method='random') -> None:\n",
        "        self.method= method\n",
        "\n",
        "\n",
        "    def initialize(self, shape):\n",
        "        if self.method== 'random':\n",
        "            return np.random.randn(*shape)\n",
        "        elif self.method== 'xavier':\n",
        "            return np.random.randn(*shape) / np.sqrt(shape[0])\n",
        "        elif self.method== 'he':\n",
        "            return np.random.randn(*shape) * np.sqrt(2 / shape[0])\n",
        "        elif self.method== 'uniform':\n",
        "            return np.random.uniform(-1, 1, shape)\n",
        "        else:\n",
        "            raise ValueError(f'Unknown initialization method: {self.method}')\n"
      ],
      "metadata": {
        "id": "ijmszYBKPMZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlotManager:\n",
        "    \"\"\"\n",
        "    Utility class for managing plots.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.fig, self.ax= plt.subplots(figsize=(6, 4))\n",
        "\n",
        "\n",
        "    def plot_losses(self, train_losses, val_losses):\n",
        "        self.ax.plot(train_losses, label='Training Loss')\n",
        "        self.ax.plot(val_losses, label='Validation Loss')\n",
        "        self.ax.set_title('Training and Validation Losses')\n",
        "        self.ax.set_xlabel('Epoch')\n",
        "        self.ax.set_ylabel('Loss')\n",
        "        self.ax.legend()\n",
        "\n",
        "\n",
        "    def show_plots(self):\n",
        "        plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "olb7xmz_PMcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Early stopping to stop the training when the loss does not improve.\n",
        "    Args:\n",
        "        patience (int): Number of epochs to wait before stopping the training.\n",
        "        verbose (bool): If true, prints a message for each epoch where the loss does not improve.\n",
        "        delta (float): Minimum change in the mentioned quantity to quantify as an improvement.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, delta=0, verbose=False) -> None:\n",
        "        self.patience= patience\n",
        "        self.delta= delta\n",
        "        self.verbose= verbose\n",
        "        self.counter= 0\n",
        "        self.best_score= None\n",
        "        self.early_stop= False\n",
        "\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        \"\"\"\n",
        "        Determines if the model should stop training.\n",
        "        Args:\n",
        "            val_loss (float): The loss of the model on the validation set.\n",
        "        \"\"\"\n",
        "\n",
        "        score= -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score= score\n",
        "        elif score< self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop= True\n",
        "        else:\n",
        "            self.best_score= score\n",
        "            self.counter= 0\n"
      ],
      "metadata": {
        "id": "-CbratQIPMf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The LSTM Class\n",
        "\n",
        "An LSTM cell contains four main components that work together to update and maintain the cell state: the forget gate $f_t$, input gate $i_t$, cell state $C_t$, and output gate $o_t$. Here's how each component is calculated at time step t:\n",
        "\n",
        "**Forget Gate $f_t$**, this gate decides which parts of the previous cell state $C_{(t-1)}$ are to be forgotten\n",
        "$$ f_t=\\sigma(W_f ⋅ [h_{t-1}, x_t] + b_f)$$\n",
        "Where:\n",
        "- $\\sigma$ is the sigmoid function, which outputs a value between 0 and 1. This value multiplies the previous cell state $C_(t-1)$, effectively deciding the extent to which each component of the cell state is remembered or forgotten. A value close to 0 means \"forget it almost completely,\" while a value close to 1 means \"retain it entirely.\"\n",
        "- $W_f$ is the weight matrix for the forget gate.\n",
        "- $h_{(t-1)}$ is the output from the previous time step.\n",
        "- $x_t$ is the current input.\n",
        "- $b_f$ is the bias term for the forget gate.\n",
        "\n",
        "**Input Gate $i_t$ and Candidate Cell State $C_t$**, the input gate determines which values will be updated in the cell state, while the candidate cell state $C_t$ represents a filtered version of the input data, prepared to be potentially added to the actual cell state.\n",
        "$$ i_t=\\sigma(W_i ⋅ [h_{t-1}, x_t] + b_i$$\n",
        "$$ \\tilde{C}_t = tanh(W_C \\cdot [h_{t-1}, x_t] + b_C $$\n",
        "\n",
        "Where:\n",
        "- $\\sigma$ again represents the sigmoid function, controlling the input gate.\n",
        "- tanh is the hyperbolic tangent function, which outputs values between -1 and 1. It helps regulate the network's non-linear characteristics.\n",
        "- $W_i$ and $W_C$ are the weight matrices for the input gate and the candidate cell state, respectively.\n",
        "- $b_i$ and $b_C$ are the biases for the input gate and the candidate cell state.\n",
        "\n",
        "**Cell State Update $C_t$**, the cell state is an element-wise addition of the old state multiplied by the forget gate and the candidate state multiplied by the input gate.\n",
        "$$C_t=f_t * C_{t-1} + i_t * \\tilde{C}_t$$\n",
        "\n",
        "The previous cell state $C_(t-1)$ multiplied by the forget gate output $f_t$ determines how much the old state can retain. The candidate cell state $C_t$ multiplied by the input gate output $i_t$ determines how much of the new state to add.\n",
        "\n",
        "**Output Gate $o_t$ and Output $h_t$**, finally, the output gate controls the parts of the cell state that are output to the next layer or used in the final prediction.\n",
        "$$ o_t=\\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o) $$\n",
        "$$ h_t=o_t * tanh(C_t) $$\n",
        "\n",
        "Where:\n",
        "- $\\sigma$ is the sigmoid function used for the output gate.\n",
        "- tanh applied to $C_t$ scales the cell state values to be between -1 and 1.\n",
        "- $W_o$ is the weight matrix for the output gate, and $b_o$ is the bias."
      ],
      "metadata": {
        "id": "WmHBYBSAYkks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM:\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory (LSTM) network.\n",
        "    Parameters:\n",
        "        input_size (int): dimensionality of input space\n",
        "        hidden_size (int): number of LSTM units\n",
        "        output_size (int): dimensionality of output space\n",
        "        init_method (str): weight initialization method (default: 'xavier')\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, init_method='xavier') -> None:\n",
        "        self.input_size= input_size\n",
        "        self.hidden_size= hidden_size\n",
        "        self.output_size= output_size\n",
        "        self.init= WeightInitializer(method=init_method)\n",
        "\n",
        "        # initialize weights\n",
        "        self.wf= self.init.initialize((hidden_size, hidden_size + input_size))\n",
        "        self.wi= self.init.initialize((hidden_size, hidden_size + input_size))\n",
        "        self.wo= self.init.initialize((hidden_size, hidden_size + input_size))\n",
        "        self.wc= self.init.initialize((hidden_size, hidden_size + input_size))\n",
        "        \"\"\"\n",
        "        The weights are initialized for the gates (forget wf, input wi, output wo, and cell wc) and\n",
        "        for connecting the last hidden state to the output (why).\n",
        "        Xavier initialization is often chosen as it's a good default for maintaining the variance\n",
        "        of activations across layers.\n",
        "        \"\"\"\n",
        "\n",
        "        # initialize biases\n",
        "        self.bf= np.zeros((hidden_size, 1))\n",
        "        self.bi= np.zeros((hidden_size, 1))\n",
        "        self.bo= np.zeros((hidden_size, 1))\n",
        "        self.bc= np.zeros((hidden_size, 1))\n",
        "        \"\"\"\n",
        "        Biases for all gates and the output layer are initialized to zero. This is a common\n",
        "        practice, although sometimes small constants are added to avoid dead neurons at the start.\n",
        "        \"\"\"\n",
        "\n",
        "        # initialize output layer weights and biases\n",
        "        self.why= self.init.initialize((output_size, hidden_size))\n",
        "        self.by= np.zeros((output_size, 1))\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        \"\"\"\n",
        "        Sigmoid activation function.\n",
        "        Parameters:\n",
        "            x (np.ndarray): input to the activation function\n",
        "        Returns:\n",
        "            np.ndarray: output of the activation function\n",
        "        \"\"\"\n",
        "\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def dsigmoid(x):\n",
        "        \"\"\"\n",
        "        Derivative of the sigmoid activation function.\n",
        "        Parameters:\n",
        "            x (np.ndarray): output of the sigmoid activation function\n",
        "        Returns:\n",
        "            np.ndarray: derivative of the sigmoid function\n",
        "        \"\"\"\n",
        "\n",
        "        return x * (1 - x)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def dtanh(x):\n",
        "        \"\"\"\n",
        "        Derivative of the hyperbolic tangent activation function.\n",
        "        Parameters:\n",
        "            x (np.ndarray): output of the hyperbolic tangent activation function\n",
        "        Returns:\n",
        "            np.ndarray: derivative of the hyperbolic tangent function\n",
        "        \"\"\"\n",
        "\n",
        "        return 1 - x * x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the LSTM network.\n",
        "        Parameters:\n",
        "            x (np.ndarray): input to the network\n",
        "        Returns:\n",
        "            np.ndarray: output of the network\n",
        "            list: caches containing intermediate values for backpropagation\n",
        "        \"\"\"\n",
        "\n",
        "        caches= []\n",
        "        h_prev= np.zeros((self.hidden_size, 1))\n",
        "        c_prev= np.zeros((self.hidden_size, 1))\n",
        "        h= h_prev\n",
        "        c= c_prev\n",
        "\n",
        "        \"\"\"\n",
        "        The input x is processed timestep by timestep, where each timestep updates the gates'\n",
        "        activations, the cell state, and the hidden state.\n",
        "        \"\"\"\n",
        "        for t in range(x.shape[0]):\n",
        "            x_t= x[t].reshape(-1, 1)\n",
        "            combined= np.vstack((h_prev, x_t))\n",
        "\n",
        "            \"\"\"\n",
        "            At each time step, the input and the previous hidden state are stacked vertically to\n",
        "            form a single combined input for matrix operations. This is crucial for performing the\n",
        "            linear transformations efficiently in one go.\n",
        "            \"\"\"\n",
        "            f= self.sigmoid(np.dot(self.wf, combined) + self.bf)\n",
        "            i= self.sigmoid(np.dot(self.wi, combined) + self.bi)\n",
        "            o= self.sigmoid(np.dot(self.wo, combined) + self.bo)\n",
        "            c_= np.tanh(np.dot(self.wc, combined) + self.bc)\n",
        "            \"\"\"\n",
        "            Here, the forget gate (f) determines the amount of the previous cell state to retain.\n",
        "            The input gate (i) decides how much of the new candidate cell state (c_) to add.\n",
        "            Finally, the output gate (o) calculates what portion of the cell state to output as the\n",
        "            hidden state.\n",
        "            \"\"\"\n",
        "\n",
        "            \"\"\"\n",
        "            The cell state is updated as a weighted sum of the previous state and the new candidate\n",
        "            state. The hidden state is derived by passing the updated cell state through a tanh\n",
        "            function and then gating it with the output gate.\n",
        "            \"\"\"\n",
        "            c= f * c_prev + i * c_\n",
        "            h= o * np.tanh(c)\n",
        "\n",
        "            \"\"\"\n",
        "            We store relevant values needed for backpropagation in cache. This includes states,\n",
        "            gate activations, and inputs.\n",
        "            \"\"\"\n",
        "            cache= (h_prev, c_prev, f, i, o, c_, x_t, combined, c, h)\n",
        "            caches.append(cache)\n",
        "\n",
        "            h_prev, c_prev= h, c\n",
        "\n",
        "        \"\"\"\n",
        "        Finally, the output y is computed as a linear transformation of the last hidden state.\n",
        "        The method returns both the output and the cached values for use during backpropagation.\n",
        "        \"\"\"\n",
        "        y= np.dot(self.why, h) + self.by\n",
        "\n",
        "        return y, caches\n",
        "\n",
        "\n",
        "    def backward(self, dy, caches, clip_value=1.0):\n",
        "        \"\"\"\n",
        "        Backward pass through the LSTM network.\n",
        "        Parameters:\n",
        "            dy (np.ndarray): gradient of the loss with respect to the output\n",
        "            caches (list): caches from the forward pass\n",
        "            clip_value (float): value to clip gradients to (default: 1.0)\n",
        "        Returns:\n",
        "            tuple: gradients of the loss with respect to the parameters\n",
        "        \"\"\"\n",
        "        # zero_grad\n",
        "        dWf, dWi, dWo, dWc= [np.zeros_like(w) for w in (self.wf, self.wi, self.wo, self.wc)]\n",
        "        dbf, dbi, dbo, dbc= [np.zeros_like(b) for b in (self.bf, self.bi, self.bo, self.bc)]\n",
        "        dWhy= np.zeros_like(self.why)\n",
        "        dby= np.zeros_like(self.by)\n",
        "\n",
        "        # ensure dy is reshaped to match output size\n",
        "        dy= dy.reshape(self.output_size, -1)\n",
        "        # dh_next and dc_next store gradients are flowing back from later timesteps\n",
        "        dh_next= np.zeros((self.hidden_size, 1)) # shape must match hidden_size\n",
        "        dc_next= np.zeros_like(dh_next)\n",
        "\n",
        "        \"\"\"\n",
        "        The LSTM state and gate activations for each timestep are retrieved from cache. Processing\n",
        "        starts from the last timestep and moves backward (reversed(caches)), which is essential for\n",
        "        correctly applying the chain rule in recurrent neural networks.\n",
        "        \"\"\"\n",
        "        for cache in reversed(caches):\n",
        "            h_prev, c_prev, f, i, o, c_, x_t, combined, c, h= cache\n",
        "\n",
        "            # add gradient from next step to current output gradient\n",
        "            dh= np.dot(self.why.T, dy) + dh_next\n",
        "            dc= dc_next + (dh * o * self.dtanh(np.tanh(c)))\n",
        "            \"\"\"\n",
        "            Gradients for each gate (df, di, do) and the candidate cell state (dc_) are calculated\n",
        "            using the chain rule, involving derivatives of the sigmoid (dsigmoid) and tanh (dtanh)\n",
        "            functions, which were discussed in the gating mechanisms.\n",
        "            \"\"\"\n",
        "            df= dc * c_prev * self.dsigmoid(f)\n",
        "            di= dc * c_ * self.dsigmoid(i)\n",
        "            do= dh * self.dtanh(np.tanh(c))\n",
        "            dc_= dc * i * self.dtanh(c_)\n",
        "\n",
        "            dcombined_f= np.dot(self.wf.T, df)\n",
        "            dcombined_i= np.dot(self.wi.T, di)\n",
        "            dcombined_o= np.dot(self.wo.T, do)\n",
        "            dcombined_c= np.dot(self.wc.T, dc_)\n",
        "\n",
        "            dcombined= dcombined_f + dcombined_i + dcombined_o + dcombined_c\n",
        "            dh_next= dcombined[:self.hidden_size]\n",
        "            dc_next= f * dc\n",
        "\n",
        "            # The following lines accumulate the gradients over all timesteps for each weight and bias\n",
        "            dWf += np.dot(df, combined.T)\n",
        "            dWi += np.dot(di, combined.T)\n",
        "            dWo += np.dot(do, combined.T)\n",
        "            dWc += np.dot(dc_, combined.T)\n",
        "\n",
        "            dbf += df.sum(axis=1, keepdims=True)\n",
        "            dbi += di.sum(axis=1, keepdims=True)\n",
        "            dbo += do.sum(axis=1, keepdims=True)\n",
        "            dbc += dc_.sum(axis=1, keepdims=True)\n",
        "\n",
        "        dWhy += np.dot(dy, h.T)\n",
        "        dby += dy\n",
        "\n",
        "        gradients= (dWf, dWi, dWo, dWc, dbf, dbi, dbo, dbc, dWhy, dby)\n",
        "\n",
        "        # gradient clipping -- prevent exploding gradients\n",
        "        for i in range(len(gradients)):\n",
        "            np.clip(gradients[i], -clip_value, clip_value, out=gradients[i])\n",
        "\n",
        "        return gradients\n",
        "\n",
        "\n",
        "    def update_params(self, grads, learning_rate):\n",
        "        \"\"\"\n",
        "        Update the parameters of the network using the gradients.\n",
        "        Parameters:\n",
        "            grads (tuple): gradients of the loss with respect to the parameters\n",
        "            learning_rate (float): learning rate\n",
        "        \"\"\"\n",
        "\n",
        "        dWf, dWi, dWo, dWc, dbf, dbi, dbo, dbc, dWhy, dby= grads\n",
        "\n",
        "        self.wf -= learning_rate * dWf\n",
        "        self.wi -= learning_rate * dWi\n",
        "        self.wo -= learning_rate * dWo\n",
        "        self.wc -= learning_rate * dWc\n",
        "\n",
        "        self.bf -= learning_rate * dbf\n",
        "        self.bi -= learning_rate * dbi\n",
        "        self.bo -= learning_rate * dbo\n",
        "        self.bc -= learning_rate * dbc\n",
        "\n",
        "        self.why -= learning_rate * dWhy\n",
        "        self.by -= learning_rate * dby\n"
      ],
      "metadata": {
        "id": "PbPulcUXPMjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gating mechanisms of LSTMs are designed to combat the vanishing gradient problem by controlling the flow of gradients during backpropagation. The gates use two primary functions to manage this flow: the sigmoid function and the hyperbolic tangent function (tanh). These functions are not just chosen arbitrarily; their mathematical properties are ideally suited to the tasks of gating and updating neural network cell states.\n",
        "\n",
        "The sigmoid function outputs values between 0 and 1. This characteristic is ideal for gating because a value close to 0 can block the component (acting like a gate is closed), and a value close to 1 can allow the component to pass through (acting like a gate is open). In the context of LSTMs, the sigmoid function is used in the forget gate to decide which parts of the previous cell state to keep or discard, and in the input and output gates to regulate the contribution of new input data and the outputting of cell state information respectively.\n",
        "\n",
        "The tanh function outputs values between -1 and 1. This range is beneficial for neural network activations because it centers the output, helping to maintain the mean of the activations throughout the network close to zero, which in turn aids in faster convergence during training. The tanh function is primarily used in two places within the LSTM cell. First, it helps to create a candidate cell state, which is a filtered version of the input data, potentially added to the cell state if the input gate allows it. Second, it transforms the final cell state output to be within the range of -1 to 1 before being modulated by the output gate."
      ],
      "metadata": {
        "id": "WKH_aalwDWWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation\n",
        "\n",
        "Each batch of data is fed through the model. The forward pass generates predictions and caches intermediate values for backpropagation. After calculating the loss, the gradient with respect to the prediction error (dy) is used to perform backpropagation. The resulting gradients are used to update the model parameters. Training progress is logged to help monitor the model's performance over time."
      ],
      "metadata": {
        "id": "MyWuZh-AiMNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTrainer:\n",
        "    \"\"\"\n",
        "    Trainer for the LSTM network.\n",
        "    Parameters:\n",
        "        model (LSTM): the LSTM network to train\n",
        "        learning_rate (float): learning rate for the optimizer\n",
        "        patience (int): number of epochs to wait before early stopping\n",
        "        delta (float): minimum change in validation loss to qualify as an improvement\n",
        "        verbose (bool): whether to print training information\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, learning_rate=1e-3, patience=7, delta=0, verbose=True) -> None:\n",
        "        self.model= model\n",
        "        self.learning_rate= learning_rate\n",
        "        self.train_losses= []\n",
        "        self.eval_losses= []\n",
        "        self.early_stopping= EarlyStopping(patience, delta, verbose)\n",
        "\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute MSE loss.\n",
        "        \"\"\"\n",
        "\n",
        "        return np.mean((y_pred - y_true)**2)\n",
        "\n",
        "\n",
        "    def validate(self, x_val, y_val):\n",
        "        \"\"\"\n",
        "        Validate the model on a separate set of data.\n",
        "        \"\"\"\n",
        "\n",
        "        val_losses= []\n",
        "        for x, y_true in zip(x_val, y_val):\n",
        "            y_pred, _= self.model.forward(x)\n",
        "            loss_val= self.compute_loss(y_pred, y_true.reshape(-1, 1))\n",
        "            val_losses.append(loss_val)\n",
        "\n",
        "        return np.mean(val_losses)\n",
        "\n",
        "\n",
        "    def train(self, x_train, y_train, x_val=None, y_val=None, epochs=10, batch_size=1,\n",
        "              clip_value=1.0, shuffle=True):\n",
        "        \"\"\"\n",
        "        Train the LSTM network.\n",
        "        Parameters:\n",
        "            x_train (np.ndarray): training data\n",
        "            y_train (np.ndarray): training labels\n",
        "            x_val (np.ndarray): validation data\n",
        "            y_val (np.ndarray): validation labels\n",
        "            epochs (int): number of training epochs\n",
        "            batch_size (int): size of mini-batches\n",
        "            clip_value (float): value to clip gradients to\n",
        "            shuffle (bool): whether to shuffle the training data in each epoch\n",
        "        \"\"\"\n",
        "        # training data indexes\n",
        "        ix= np.arange(0, x_train.shape[0])\n",
        "\n",
        "        # --- training loop ---\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            epoch_loss= []\n",
        "\n",
        "            # iterating over all batches\n",
        "            if shuffle:\n",
        "                ix= np.random.permutation(x_train.shape[0])[:x_train.shape[0]]\n",
        "\n",
        "            for i in range(0, len(x_train), batch_size):\n",
        "                batch_loss= []\n",
        "\n",
        "                # --- minibatch construction ---\n",
        "                Xmb= x_train[ix[i : i + batch_size]]\n",
        "                Ymb= y_train[ix[i : i + batch_size]]\n",
        "\n",
        "                for x, y_true in zip(Xmb, Ymb):\n",
        "                    # --- forward pass and get loss ---\n",
        "                    y_pred, caches= self.model.forward(x)\n",
        "                    loss_tr= self.compute_loss(y_pred, y_true.reshape(-1, 1))\n",
        "                    batch_loss.append(loss_tr)\n",
        "\n",
        "                    # --- backward pass to calculate the gradients ---\n",
        "                    dy= y_pred - y_true.reshape(-1, 1)\n",
        "                    grads= self.model.backward(dy, caches, clip_value=clip_value)\n",
        "\n",
        "                    # --- update the parameters using the gradient ---\n",
        "                    self.model.update_params(grads, self.learning_rate)\n",
        "\n",
        "                epoch_loss.append(np.mean(batch_loss))\n",
        "\n",
        "\n",
        "            # --- evaluation and track stats ---\n",
        "            self.train_losses.append(np.mean(epoch_loss))\n",
        "\n",
        "            if x_val is not None and y_val is not None:\n",
        "                val_loss= self.validate(x_val, y_val)\n",
        "                self.eval_losses.append(val_loss)\n",
        "                if epoch % 10== 0:\n",
        "                    print(f'Epoch {epoch+1}/{epochs} - Loss: {self.train_losses[-1]:.4}, Val Loss: {val_loss:.4}')\n",
        "\n",
        "                # --- early stopping checking ---\n",
        "                self.early_stopping(val_loss)\n",
        "                if self.early_stopping.early_stop:\n",
        "                    print('Early stopping...')\n",
        "                    break\n",
        "            elif epoch % 10== 0:\n",
        "                print(f'Epoch {epoch+1}/{epochs} - Loss: {self.train_losses[-1]:.4}')\n"
      ],
      "metadata": {
        "id": "Dvie_nHNPMlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back= 1     # Number of previous time steps to include in each sample\n",
        "hidden_size= 256 # Number of LSTM units\n",
        "output_size= 1   # Dimensionality of the output space\n",
        "\n",
        "lstm= LSTM(input_size=1, hidden_size=hidden_size, output_size=output_size)\n",
        "\n",
        "trainer= LSTMTrainer(lstm, learning_rate=1e-3, patience=50, delta=0.001, verbose=True)\n",
        "trainer.train(Xtr, Ytr, Xte, Yte, epochs=1000, batch_size=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kpopsFlKVEF",
        "outputId": "367dafbf-4ec3-4bb8-dc6d-7830d48faeb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000 - Loss: 0.01344, Val Loss: 0.01367\n",
            "Epoch 11/1000 - Loss: 0.0001035, Val Loss: 0.0008996\n",
            "Epoch 21/1000 - Loss: 0.0001041, Val Loss: 0.0009014\n",
            "Epoch 31/1000 - Loss: 0.0001043, Val Loss: 0.0009012\n",
            "Epoch 41/1000 - Loss: 0.0001047, Val Loss: 0.0008975\n",
            "Epoch 51/1000 - Loss: 0.0001042, Val Loss: 0.0008974\n",
            "Early stopping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_manager= PlotManager()\n",
        "\n",
        "# Inside your training loop\n",
        "plot_manager.plot_losses(trainer.train_losses, trainer.eval_losses)\n",
        "\n",
        "# After your training loop\n",
        "plot_manager.show_plots()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "D3KXnrz4KVGz",
        "outputId": "69a89115-2275-42a4-8b8d-be8dc30ae9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/the-math-behind-lstm-9069b835289d"
      ],
      "metadata": {
        "id": "qNvb_wpYPMrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch version"
      ],
      "metadata": {
        "id": "vTa7wAzUPlXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "rrhdWhiFKVJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With look_back=1, it is quite surely that the accuracy would not be good for too little clues to predict. But this is a good example to demonstrate the structure of the LSTM model."
      ],
      "metadata": {
        "id": "ppd4XSjuSK4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the dataset\n",
        "data= TimeSeriesData('2010-1-1', '2020-12-31', look_back=1)\n",
        "Xtr, Ytr, Xte, Yte= data.split_train_test(PATH)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "Xtr= np.reshape(Xtr, (Xtr.shape[0], Xtr.shape[1], 1))\n",
        "Xte= np.reshape(Xte, (Xte.shape[0], Xte.shape[1], 1))\n",
        "\n",
        "Xtr= torch.tensor(Xtr, requires_grad=True).type(torch.float32)\n",
        "Ytr= torch.tensor(Ytr.squeeze(axis=-1)).type(torch.float32)\n",
        "Xte= torch.tensor(Xte, requires_grad=True).type(torch.float32)\n",
        "Yte= torch.tensor(Yte.squeeze(axis=-1)).type(torch.float32)\n",
        "\n",
        "print(f'Shape of training: Xtr - {Xtr.shape}, Ytr - {Ytr.shape}')\n",
        "print(f'Shape of test data: Xte - {Xte.shape}, Yte - {Yte.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODeiIv3PPxOx",
        "outputId": "9dcd6829-1cd0-4eaf-fefc-c951e13ec136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training: Xtr - torch.Size([1728, 1, 1]), Ytr - torch.Size([1728, 1])\n",
            "Shape of test data: Xte - torch.Size([851, 1, 1]), Yte - torch.Size([851, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Py_LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_lstm_layers=1) -> None:\n",
        "        super(Py_LSTM, self).__init__()\n",
        "        self.hidden_size= hidden_size\n",
        "        self.num_lstm_layers= num_lstm_layers\n",
        "\n",
        "        self.lstm= nn.LSTM(input_size, hidden_size, num_lstm_layers, batch_first=True)\n",
        "        self.activ1= nn.ReLU()\n",
        "        self.fc_in = nn.Linear(hidden_size, int(hidden_size / 2))\n",
        "        self.activ2= nn.ReLU()\n",
        "        self.fc_out= nn.Linear(int(hidden_size / 2), output_size)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim()> 1:\n",
        "                nn.init.xavier_normal_(p)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0= torch.zeros((self.num_lstm_layers, x.shape[0], self.hidden_size), requires_grad=True)\n",
        "        c_0= torch.zeros((self.num_lstm_layers, x.shape[0], self.hidden_size), requires_grad=True)\n",
        "        # propagate input through LSTM\n",
        "        out, (h_n, c_n)= self.lstm(x, (h_0, c_0))\n",
        "        h_n= h_n.view(-1, self.hidden_size) # reshaping the data for Dense layer next\n",
        "        x= self.activ1(h_n)\n",
        "        x= self.fc_in(x)\n",
        "        x= self.activ2(x)\n",
        "        x= self.fc_out(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "PGNnpIBuPMob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size= 1    # number of features\n",
        "hidden_size= 256 # number of LSTM units\n",
        "output_size= 1   # dimensionality of the output space (classes)\n",
        "num_layers= 1    # number of stacked lstm layers\n",
        "\n",
        "model= Py_LSTM(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of parameters: {total_params}')\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOoqFvsjPxLV",
        "outputId": "c914c2c4-a935-4b8a-bc9b-cb04bab04eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 298241\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Py_LSTM(\n",
              "  (lstm): LSTM(1, 256, batch_first=True)\n",
              "  (activ1): ReLU()\n",
              "  (fc_in): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (activ2): ReLU()\n",
              "  (fc_out): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_training(model, learning_rate=1e-3, epochs=500, eval_interval=5, batches:bool=True,\n",
        "                        batch_size=64, shuffle:bool=True, early_stop:bool=True, patience=5, cutoff=1e-9):\n",
        "\n",
        "    # defining key hyperparamaters explicitly (instead of hyperparamater search)\n",
        "    if batches:\n",
        "        epoch_size= math.floor(Xtr.shape[0]/ batch_size)\n",
        "    else:\n",
        "        batch_size= Xtr.shape[0]\n",
        "        epoch_size= 1\n",
        "\n",
        "    weight_decay=5e-4\n",
        "\n",
        "    # create a PyTorch optimizer\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # loss function\n",
        "    loss_fn= nn.MSELoss()\n",
        "\n",
        "    # for early stoping\n",
        "    patience_count= 0\n",
        "    previous_loss= 1e10\n",
        "\n",
        "    # tracking statistics\n",
        "    train_hist= []\n",
        "    test_hist= []\n",
        "\n",
        "    # training data indexes\n",
        "    ix= torch.arange(0, Xtr.shape[0])\n",
        "\n",
        "    # --- training loop ---\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        batch_loss= []\n",
        "\n",
        "        # iterating over all batches\n",
        "        if shuffle:\n",
        "            ix= torch.randperm(Xtr.shape[0])[:Xtr.shape[0]]\n",
        "\n",
        "        for i in range(epoch_size):\n",
        "\n",
        "            # --- minibatch construction ---\n",
        "            Xmb= Xtr[ix[(i * batch_size) : ((i+1) * batch_size)]]\n",
        "            Ymb= Ytr[ix[(i * batch_size) : ((i+1) * batch_size)]]\n",
        "\n",
        "            # --- forward pass and get loss ---\n",
        "            model.train(True)\n",
        "            y_pred= model(Xmb)\n",
        "            loss_tr= loss_fn(y_pred, Ymb)\n",
        "            batch_loss.append(loss_tr.item())\n",
        "\n",
        "            # --- backward pass to calculate the gradients ---\n",
        "            optimizer.zero_grad()\n",
        "            loss_tr.backward()\n",
        "\n",
        "            # --- update the parameters using the gradient ---\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        # --- evaluation and track stats ---\n",
        "        train_hist.append(np.mean(batch_loss))\n",
        "\n",
        "        if epoch% eval_interval== 0:\n",
        "            model.train(False)\n",
        "            with torch.no_grad():\n",
        "                y_pred= model(Xte)\n",
        "                loss_te= loss_fn(y_pred, Yte)\n",
        "\n",
        "        test_hist.append(loss_te.item())\n",
        "\n",
        "\n",
        "        # --- early stopping -- calculating loss change ---\n",
        "        loss_change= np.abs(previous_loss - train_hist[-1])\n",
        "        # deciding to stop if loss is not decreasing fast enough\n",
        "        if (early_stop and loss_change< cutoff):\n",
        "            patience_count += 1\n",
        "\n",
        "            if patience_count> patience:\n",
        "                print('\\nEarly stopping at epoch {}'.format(epoch))\n",
        "                model.train(False)\n",
        "                break\n",
        "        else:\n",
        "            patience_count= 0\n",
        "        # setting current train loss as previous loss\n",
        "        previous_loss= train_hist[-1]\n",
        "\n",
        "\n",
        "    return train_hist, test_hist\n"
      ],
      "metadata": {
        "id": "4yEueQECPxRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size= 1    # number of features\n",
        "hidden_size= 256 # number of LSTM units\n",
        "output_size= 1   # dimensionality of the output space (classes)\n",
        "num_layers= 1    # number of stacked lstm layers\n",
        "\n",
        "model= Py_LSTM(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "train_hist, test_hist= supervised_training(model, learning_rate=1e-3, epochs=500,\n",
        "                                           eval_interval=5, batch_size=250, cutoff=1e-6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP7rq-0IPxU-",
        "outputId": "6955bc53-d44a-4258-be59-c5e2085e7f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [11:33<00:00,  1.39s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_manager= PlotManager()\n",
        "# Inside your training loop\n",
        "plot_manager.plot_losses(train_hist, test_hist)\n",
        "# After your training loop\n",
        "plot_manager.show_plots()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "9xRzf1UENDp9",
        "outputId": "3b6941d7-b9cf-4510-bc94-1a6d35023e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can plot the predictions on the data set, to check out how the model is performing. But before performing predictions on the whole dataset, we'll need to bring the original dataset into the model suitable format, which can be done by using similar code as above.\n",
        "\n",
        "We can simply perform predictions on the whole dataset via a forward pass, and then to plot them, converting them to numpy, reversing transform them (remember that we scaled the data, and we'll need to reverse transform it) and then plot it."
      ],
      "metadata": {
        "id": "mtyu7-HBVMNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/\n",
        "# https://cnvrg.io/pytorch-lstm/"
      ],
      "metadata": {
        "id": "NEkQSDfXYgyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}