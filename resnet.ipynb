{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Network (ResNet)\n",
        "\n",
        "Adding more layers to a deep learning model should intuitively improve its performance but the practical observations are not aligned to this notion. One of the issues with deeper models can be Vanishing/exploding gradients which hampers the convergence. This can be addressed by normalized initialisation and intermediate normalization layers (BatchNorm) which enables the network to start converging for SGD with backprop. Even with using normalization, the increase in network depth leads to saturation of accuracy which eventually degrades rapidly. Unexpectedly this is not due to overfitting.\n",
        "\n",
        "This is referred to as degradation problem. The authors solve this problem using deep residual learning framework. With skip connections, weights of multiple non-linear layers can be driven to zero to approach identity mappings.\n",
        "\n",
        "https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html"
      ],
      "metadata": {
        "id": "b2vK1An5ohR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AZw2qKEwoeeC"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "nk-VFXJFo106"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many trainable weights the model has\n",
        "def count_parameters(model) -> None:\n",
        "    total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "id": "sENSxtG2o13x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define configs for different ResNet versions\n",
        "\n",
        "Here, model_hparameters['resnet50'] = ([64,128,256,512], [3,4,6,3], 4, True) represents the hyperparameters for building a ResNet-50, where\n",
        "- [64,128,256,512] -> channels in each intermediate block\n",
        "- [3,4,6,3] -> number of repetition for Bottlenecks in each block\n",
        "- 4 -> expansion_factor. Note that 64 turns to 256, 128 to 512. All the ResNet layers use the same expansion factor\n",
        "- True -> create Bottleneck layer status. True only for ResNet-50+"
      ],
      "metadata": {
        "id": "W_w0y3XWFHjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet_= (num channels, repetition, bottleneck expansion, bottleneck layer)\n",
        "model_hparameters= {}\n",
        "model_hparameters['resnet18'] = ([64,128,256,512], [2,2,2,2], 1, False)\n",
        "model_hparameters['resnet34'] = ([64,128,256,512], [3,4,6,3], 1, False)\n",
        "model_hparameters['resnet50'] = ([64,128,256,512], [3,4,6,3], 4, True)\n",
        "model_hparameters['resnet101']= ([64,128,256,512], [3,4,23,3],4, True)\n",
        "model_hparameters['resnet152']= ([64,128,256,512], [3,8,36,3],4, True)"
      ],
      "metadata": {
        "id": "jjseXo3Uo16T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Bottleneck and Basic Blocks\n",
        "\n",
        "Bottlenecks are the bulding units of ResNet architecture. A bottleneck layer is a layer that contains few nodes compared to the previous layers. It can be used to obtain a representation of the input with reduced dimensionality.\n",
        "\n",
        "- A bottleneck consists of (conv1x1->BN->activation) -> (conv3x3->BN->activation) -> (conv1x1->BN) -> activation. Bottleneck is used to reduce the computation cost while increasing depth for layers-50, 101, and 152.\n",
        "- For ResNet-18/34, Basic blocks are used instead of bottlenecks. Basic blocks are simple and effective for shallower networks but become inefficient as network depth increases.\n",
        "\n",
        "**NOTE:** The original ResNet uses ReLU as activation function, I replaced by GELU as it is a more modern approach and suitable to avoid dead neurons (but the activation function of the network can be defined in the hyperparameters)."
      ],
      "metadata": {
        "id": "XCQ1mEvyHa6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleneckBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Creates a bottleneck layer for ResNet. It uses 1x1 convolution before the 3x3 convolution\n",
        "    (i.e., reduces the number of channels before applying the 3x3 convolution). The final 1x1\n",
        "    convolution restores the original dimensions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, mid_channels, expansion, stride=1, activation=None) -> None:\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        # define the activation function -- ReLU is default in the original ResNet\n",
        "        activation= nn.GELU() if activation is None else activation\n",
        "        # for all ResNet-50+\n",
        "        self.bottleneck= nn.Sequential(\n",
        "            # conv1x1 -> BN -> activation (dimensionality reduction)\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            activation,\n",
        "            # conv3x3 -> BN -> activation (feature extraction)\n",
        "            nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            activation,\n",
        "            # conv1x1 -> BN (restoring dimensions)\n",
        "            nn.Conv2d(mid_channels, mid_channels*expansion, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels*expansion),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.bottleneck(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Z2BFe_2XFCIS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Creates a basic block layer for ResNet. It uses 3x3 convolutions in both layers (maintains the\n",
        "    same number of channels throughout the block).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, mid_channels, stride=1, activation=None) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # define the activation function -- ReLU is default in the original ResNet\n",
        "        activation= nn.GELU() if activation is None else activation\n",
        "        # for ResNet-18/34 (no dimensionality reduction)\n",
        "        self.basic_block= nn.Sequential(\n",
        "            # conv3x3 -> BN -> activation\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            activation,\n",
        "            # conv3x3 -> BN\n",
        "            nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.basic_block(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "WsqjIJDr0neV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identity vs Downsample mapping\n",
        "\n",
        "Skip connections, which are housed in residual blocks, allow you to take the activation value from an earlier layer and pass it to a deeper layer in a network. Skip connections enable deep networks to learn the identity function. Learning the identity function allows a deeper layer to perform as well as an earlier layer, or at the very least it won't perform any worse. The result is smoother gradient flow, ensuring important features are preserved in the training process.\n",
        "\n",
        "If **x** and the feature map size (including the number of channels) are the same, **x** can add to the feature map directly. If **x** and the feature map do not match, we apply downsample mapping (aka shortcut connection) using 1x1 convolutions where **x** and the feature map are projected to the required dimensions.\n",
        "\n",
        "Increasing the number of filters in the ResidualBlock by a factor of 2 also comes with reducing the feature map dimensions to half. Decreasing the feature map dimensions occurs with stride=2 instead of maxpool in conv3x3 of the ResidualBlock."
      ],
      "metadata": {
        "id": "lRJEx4UQ1Ksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Creates a residual layer for ResNet.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, mid_channels, expansion=4, is_bottleneck=True, stride=1,\n",
        "                 activation=None, dropout=0.1) -> None:\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        # is_bottleneck=True for all ResNet-50+\n",
        "        if is_bottleneck:\n",
        "            self.block= BottleneckBlock(in_channels, mid_channels, expansion, stride, activation)\n",
        "        else:\n",
        "            self.block= BasicBlock(in_channels, mid_channels, stride, activation)\n",
        "        # dropout layer for regularization\n",
        "        self.dropout= nn.Dropout2d(p=dropout) if dropout> 0.0 else None\n",
        "        # if dim(x)== dim(F) -> Identity function\n",
        "        if in_channels== mid_channels * expansion:\n",
        "            self.identity= True\n",
        "        else:\n",
        "            self.identity= False\n",
        "            self.downsample= nn.Sequential(\n",
        "                # only conv -> BN and no activation (aka shortcut connection)\n",
        "                nn.Conv2d(\n",
        "                    in_channels, mid_channels*expansion,\n",
        "                    kernel_size=1, stride=stride, padding=0, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(mid_channels*expansion),\n",
        "            )\n",
        "        # define the activation function -- ReLU is default in the original ResNet\n",
        "        self.activation= nn.GELU() if activation is None else activation\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out= self.block(x)\n",
        "        if self.dropout is not None:\n",
        "            out= self.dropout(out)\n",
        "        # skip connection -- identity or projected map\n",
        "        if self.identity:\n",
        "            x= x + out\n",
        "        else:\n",
        "            x= self.downsample(x) + out\n",
        "\n",
        "        return self.activation(x)\n"
      ],
      "metadata": {
        "id": "K47_Z3wM1s25"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of the previous layers output being passed directly onto the next block, a copy of that output is made, then that copy is passed through a residual block. This residual block will process the copied output matrix, **x** — with a 3x3 convolution, followed by BatchNorm and activation to yield a matrix **out**.\n",
        "\n",
        "Then, **x** and **out** would be added together, element by element, to yield the output to the next layer/block. Doing this helps us ensure that any added layers in a neural network are useful for learning."
      ],
      "metadata": {
        "id": "KjuAERGldn1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img= torch.randn(1, 64, 112, 112).to(device)\n",
        "model= ResidualBlock(64, 64, 4, True, 2).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6o4hhvTFCLJ",
        "outputId": "8276277a-71ec-488d-c1c5-26582164a511"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 75008\n",
            "torch.Size([1, 256, 56, 56])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the ResNet\n",
        "\n",
        "The input RGB image is passed through a 7x7 Conv2d with stride=2, number of filters=64, and padding=3, followed by max pooling to reduce the feature map size by half. In the remaining architecture, only 3x3 filters are used with stride=2 in cases of reducing feature map size. Max pooling is not used.\n",
        "\n",
        "According to the ResNet variant, create 4 Sequential ResidualBlocks, either BottleneckBlocks or BasicBlocks. All the four blocks have feature map size reduction using stride=2 except for block 1, where stride=1. This exception is because the 56x56 input remains the same throughout block 1.\n",
        "\n",
        "After the four blocks, Average Pooling reduces the feature map to 1x1, followed by a Fully Connected Layer connecting the flattened feature map with the output classes."
      ],
      "metadata": {
        "id": "uhru6tIzeSOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Initializes the ResNet architecture based on the provided variant.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, resnet_type, in_channels, num_classes, activation=None, dropout=0.1) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        # define the channels and repeatition lists along with expansion factor and stride\n",
        "        channels= resnet_type[0]\n",
        "        repetitions= resnet_type[1]\n",
        "        expansion= resnet_type[2]\n",
        "        is_bottleneck= resnet_type[3]\n",
        "        # define the activation function -- ReLU is default in the original ResNet\n",
        "        activation= nn.GELU() if activation is None else activation\n",
        "\n",
        "        self.conv_in= nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            activation,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "        self.block1= self.residual_stack(\n",
        "            64, channels[0], repetitions[0], expansion, is_bottleneck, stride=1,\n",
        "            activation=activation, dropout=dropout\n",
        "        )\n",
        "        self.block2= self.residual_stack(\n",
        "            channels[0]*expansion, channels[1], repetitions[1], expansion, is_bottleneck, stride=2,\n",
        "            activation=activation, dropout=dropout\n",
        "        )\n",
        "        self.block3= self.residual_stack(\n",
        "            channels[1]*expansion, channels[2], repetitions[2], expansion, is_bottleneck, stride=2,\n",
        "            activation=activation, dropout=dropout\n",
        "        )\n",
        "        self.block4= self.residual_stack(\n",
        "            channels[2]*expansion, channels[3], repetitions[3], expansion, is_bottleneck, stride=2,\n",
        "            activation=activation, dropout=dropout\n",
        "        )\n",
        "        self.average_pool= nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.fc_out= nn.Linear(channels[3]*expansion, num_classes)\n",
        "\n",
        "        # initialize parameters -- Xavier is more suitable for GELU\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "    def residual_stack(\n",
        "        self, in_channels, mid_channels, repetitions, expansion, is_bottleneck, stride,\n",
        "        activation, dropout\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create a sequential stack of residual blocks.\n",
        "        \"\"\"\n",
        "        layers= nn.Sequential(\n",
        "            ResidualBlock(\n",
        "                in_channels, mid_channels, expansion, is_bottleneck, stride, activation, dropout\n",
        "            ),\n",
        "            *[ResidualBlock(\n",
        "                mid_channels*expansion, mid_channels, expansion, is_bottleneck, stride=1,\n",
        "                activation=activation, dropout=dropout\n",
        "            ) for _ in range(1, repetitions)],\n",
        "        )\n",
        "        return layers\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.conv_in(x)\n",
        "        x= self.block1(x)\n",
        "        x= self.block2(x)\n",
        "        x= self.block3(x)\n",
        "        x= self.block4(x)\n",
        "        x= torch.flatten(self.average_pool(x), start_dim=1)\n",
        "\n",
        "        # softmax (if needed) is applied externally\n",
        "        return self.fc_out(x)\n"
      ],
      "metadata": {
        "id": "o6z_oBsfFCN6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet with GELU Recommendation:** Use nn.init.xavier_uniform_. Uniform initialization often provides more stable training in practice, especially for networks with batch normalization like ResNet. Uniform initialization avoids rare large values that may occur with normal initialization and provides consistent variance across layers."
      ],
      "metadata": {
        "id": "DHDNsGx7Hv9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img= torch.randn(1, 3, 224, 224).to(device)\n",
        "model= ResNet(model_hparameters['resnet50'], in_channels=3, num_classes=1000, dropout=0.1).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "crtMCTXdFCQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258cae84-4a15-4f8e-b5dd-8ea52c4ed1c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 25557032\n",
            "torch.Size([1, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv_in): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block1): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (5): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (block): BottleneckBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): GELU(approximate='none')\n",
              "          (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "      (activation): GELU(approximate='none')\n",
              "    )\n",
              "  )\n",
              "  (average_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc_out): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "tvis_model= models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)\n",
        "img= torch.randn(1, 3, 224, 224).to(device)\n",
        "print(tvis_model(img).shape)"
      ],
      "metadata": {
        "id": "e987wP0AFCag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef344a47-3d6d-43f4-9864-5310a7aa9c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 143MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 25557032\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the ResNet model from scratch"
      ],
      "metadata": {
        "id": "Gczu4NsrMHtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "uPMWaTEMFCeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation -- define transformations for the dataset\n",
        "transform= transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]), # CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# load the CIFAR-10 dataset\n",
        "train_dataset= datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "train_size= int(0.9 * len(train_dataset))\n",
        "val_size  = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset= random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size= 128\n",
        "train_loader= DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNpAGo2oRBsV",
        "outputId": "f0b64140-ff32-4a39-a335-7d96a03c5c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lHNeKmxRvKB",
        "outputId": "9010fd31-5bd1-4cbc-9885-740a23046977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Function\n",
        "\n",
        "TODO:\n",
        "- Data augmentation for training.\n",
        "- Logging Learning Rate.\n",
        "- Early Stopping: based on validation loss to prevent overfitting."
      ],
      "metadata": {
        "id": "ixLNlWLqNAQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs,\n",
        "            device, eval_interval=1, verbose=False):\n",
        "\n",
        "    tr_loss_hist= []\n",
        "    vl_loss_hist= []\n",
        "\n",
        "    # --- training loop ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_loss= []\n",
        "        start= time.time()\n",
        "\n",
        "        # --- training steps ---\n",
        "        # iterating over all batches\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            # --- minibatch construction ---\n",
        "            images= images.to(device, non_blocking=True)\n",
        "            labels= labels.to(device, non_blocking=True)\n",
        "\n",
        "            # --- forward pass and get loss ---\n",
        "            logits= model(images)\n",
        "            loss= criterion(logits, labels)\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            # --- backward pass to calculate the gradients ---\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # --- update the parameters using the gradient ---\n",
        "            optimizer.step()\n",
        "\n",
        "        # --- evaluation and track stats ---\n",
        "        tr_loss_hist.append(np.mean(batch_loss))\n",
        "\n",
        "        if epoch% eval_interval== 0 or epoch== epochs-1:\n",
        "            model.eval()\n",
        "            val_loss= []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels= images.to(device), labels.to(device)\n",
        "                    logits= model(images)\n",
        "                    loss_v= criterion(logits, labels)\n",
        "                    val_loss.append(loss_v.item())\n",
        "\n",
        "            val_loss= np.mean(val_loss)\n",
        "            end= time.time()\n",
        "            dt= end - start\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch: {epoch} | Train Loss: {tr_loss_hist[-1]:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f} | dt/epoch: {dt*1000:.2f}ms\")\n",
        "\n",
        "            # for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        vl_loss_hist.append(val_loss)\n",
        "\n",
        "    return tr_loss_hist, vl_loss_hist\n"
      ],
      "metadata": {
        "id": "IzvJS9_io1-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device, verbose=False):\n",
        "    model.eval()\n",
        "    correct= 0\n",
        "    total= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels= images.to(device), labels.to(device)\n",
        "            logits= model(images)\n",
        "            y_pred= torch.argmax(logits, dim=1)\n",
        "            correct += (y_pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc= correct / total\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {(acc * 100):.2f}%\")\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "tCT5MRyB4E25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(train_loss, valid_loss):\n",
        "    # plot training and validation losses\n",
        "    plt.plot(train_loss, label='Train Loss')\n",
        "    plt.plot(valid_loss, label='Validation Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "GxsLtu7G4E5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup using TF32 and Fused AdamW"
      ],
      "metadata": {
        "id": "rFZj54hgNvp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_fused= False\n",
        "\n",
        "if device== 'cuda': # TF32 computationally more efficient (slightly the same precision of FP32)\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    # create AdamW optimizer and use the fused version of it is available\n",
        "    fused_available= 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "    # fused is a lot faster when it is available and when running on cuda\n",
        "    use_fused= fused_available\n",
        "\n",
        "# --- ResNet-50 ---\n",
        "in_channels= 3\n",
        "num_classes= 10\n",
        "\n",
        "model= ResNet(model_hparameters['resnet50'], in_channels, num_classes, dropout=0.1).to(device)\n",
        "count_parameters(model)\n",
        "\n",
        "\n",
        "# train_loader has size 352, so 20 epochs have 7,040 steps\n",
        "epochs= 20\n",
        "learning_rate= 1e-3\n",
        "\n",
        "optimizer= torch.optim.AdamW(\n",
        "    model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-4,\n",
        "    fused=use_fused\n",
        ")\n",
        "print(f\"Using fused AdamW: {use_fused}\")\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "# for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "scheduler= ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "lZR31h_54E73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27645082-9a07-4a56-d4b5-4f196177179e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 23528522\n",
            "Using fused AdamW: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss, vl_loss= trainer(model, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                          epochs, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNz4R8TMQhb6",
        "outputId": "f2f7055e-a951-4149-b70e-3c220b2fab8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 1.6132 | Val Loss: 1.6342 | dt/epoch: 90975.75ms\n",
            "Epoch: 1 | Train Loss: 1.1005 | Val Loss: 1.2328 | dt/epoch: 91044.69ms\n",
            "Epoch: 2 | Train Loss: 0.8910 | Val Loss: 1.2778 | dt/epoch: 90954.17ms\n",
            "Epoch: 3 | Train Loss: 0.7475 | Val Loss: 0.8094 | dt/epoch: 90959.45ms\n",
            "Epoch: 4 | Train Loss: 0.6300 | Val Loss: 0.7262 | dt/epoch: 91404.87ms\n",
            "Epoch: 5 | Train Loss: 0.5440 | Val Loss: 0.6547 | dt/epoch: 90927.57ms\n",
            "Epoch: 6 | Train Loss: 0.4887 | Val Loss: 0.7015 | dt/epoch: 91108.82ms\n",
            "Epoch: 7 | Train Loss: 0.4459 | Val Loss: 0.5306 | dt/epoch: 91176.32ms\n",
            "Epoch: 8 | Train Loss: 0.3914 | Val Loss: 0.5016 | dt/epoch: 91467.60ms\n",
            "Epoch: 9 | Train Loss: 0.3507 | Val Loss: 0.4961 | dt/epoch: 91552.12ms\n",
            "Epoch: 10 | Train Loss: 0.3101 | Val Loss: 0.5003 | dt/epoch: 91378.08ms\n",
            "Epoch: 11 | Train Loss: 0.2891 | Val Loss: 0.4955 | dt/epoch: 90732.95ms\n",
            "Epoch: 12 | Train Loss: 0.2589 | Val Loss: 0.4757 | dt/epoch: 90976.78ms\n",
            "Epoch: 13 | Train Loss: 0.2261 | Val Loss: 0.4714 | dt/epoch: 91262.70ms\n",
            "Epoch: 14 | Train Loss: 0.2079 | Val Loss: 0.5560 | dt/epoch: 91372.59ms\n",
            "Epoch: 15 | Train Loss: 0.1889 | Val Loss: 0.5795 | dt/epoch: 90873.51ms\n",
            "Epoch: 16 | Train Loss: 0.1657 | Val Loss: 0.5057 | dt/epoch: 90892.64ms\n",
            "Epoch: 17 | Train Loss: 0.1480 | Val Loss: 0.4988 | dt/epoch: 91267.59ms\n",
            "Epoch: 18 | Train Loss: 0.1403 | Val Loss: 0.4971 | dt/epoch: 91248.28ms\n",
            "Epoch: 19 | Train Loss: 0.1217 | Val Loss: 0.5473 | dt/epoch: 91198.19ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "plot_losses(tr_loss, vl_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "P3aESMaLN8DN",
        "outputId": "39aa7e61-f7e1-4c64-82a1-785bf4c38d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** In this case, the x-axis accounts for epochs, not steps."
      ],
      "metadata": {
        "id": "N_nOLfDKkBuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit_acc= evaluate_model(model, test_loader, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "799CVXoMZjyb",
        "outputId": "3a6a529d-6dbf-4474-cc5e-1140d1bf6c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://heartbeat.comet.ml/resnet-how-one-paper-changed-deep-learning-forever-2256cf09fa9a\n",
        "# https://medium.com/@karuneshu21/resnet-paper-walkthrough-b7f3bdba55f0\n",
        "# https://medium.com/@karuneshu21/how-to-resnet-in-pytorch-9acb01f36cf5"
      ],
      "metadata": {
        "id": "sksBDAPjo2AX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}