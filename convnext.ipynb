{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNeXt from Scratch in PyTorch\n",
        "\n",
        "The authors of ConvNeXt did their best to revive ResNet by improving it following new practices and discoveries made in the last decade to perform better and to be more similar to a transformer, without actually turning it into a transformer or adding attention into the mix. The authors focused on Swin-Transformer and follows closely its design choices.\n",
        "\n",
        "https://arxiv.org/abs/2201.03545"
      ],
      "metadata": {
        "id": "Yqc4ZHaR4PpQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTttaB-A4O_Y"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "3unqYKnd4Rgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many trainable weights the model has\n",
        "def count_parameters(model) -> None:\n",
        "    total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "id": "IJiEokwa4Rke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define configs for different ConvNeXt versions\n",
        "\n",
        "ResNet-50 has four stages, where stages one and four have three blocks, stage two has four blocks and stage three has six blocks (3, 4, 6, 3). Swin-T also consists of four stages with a ratio of 1:1:3:1 Swin-Transformer Blocks in each stage. Therefore, ConvNeXt adjusts ResNet-50 stages to be more similar to that of the Swin-Transformer, i.e., (3, 3, 9, 3)."
      ],
      "metadata": {
        "id": "LRUyDqvQ4evJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convnext_= dims (channels), depths (number of blocks at each stage)\n",
        "model_hparameters= {}\n",
        "model_hparameters['convnext_tiny']  = ([ 96,192, 384, 768], [3,3, 9,3])  # similar size to resnet50\n",
        "model_hparameters['convnext_small'] = ([ 96,192, 384, 768], [3,3,27,3])\n",
        "model_hparameters['convnext_base']  = ([128,256, 512,1024], [3,3,27,3])\n",
        "model_hparameters['convnext_large'] = ([192,384, 768,1536], [3,3,27,3])\n",
        "model_hparameters['convnext_xlarge']= ([256,512,1024,2048], [3,3,27,3])"
      ],
      "metadata": {
        "id": "NBK4VF_C4Rn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Implementation\n",
        "\n",
        "Starting by the fundamental building block of a CNN, represented by a convolutional layer. ConvNeXt replaces all the Rectified Linear Units (ReLU) in the activation layers with Gaussian Error Linear Units (GELU) as they are smoother and used by Swin Transformers, and replace Batch Normalisation (BN) with Layer Normalisation (LN).\n",
        "\n",
        "Groups is specified to control how convolution is applied to input. If group=1, then a kernel is applied to all input channels and if group=in_channel (depthwise convolution), then a single convolutional kernel is applied for each input channel."
      ],
      "metadata": {
        "id": "1rA4qMZP4kOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements one customizable CNN layer.\n",
        "    ConvNeXt-style: Input -> (pre Norm) -> Conv2d -> (pos Norm) -> Activation -> Output\n",
        "    - pre_norm only when downsampling (so that the LN sees \"old\" activations),\n",
        "    - post_norm -- GroupNorm(1, C, eps) -- everywhere else.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, groups=1,\n",
        "                 bias=False, pre_norm=False, post_norm=True, activation=None, eps=1e-6) -> None:\n",
        "        super(ConvLayer, self).__init__()\n",
        "        # Pre normalization for the downsample layers (LayerNorm over channels)\n",
        "        self.pre_norm= nn.GroupNorm(\n",
        "            num_groups=1, num_channels=in_channels, eps=eps\n",
        "        ) if pre_norm else None\n",
        "        # Convolutional module\n",
        "        self.conv= nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=bias\n",
        "        )\n",
        "        # GroupNorm with num_groups=1 is the same as LayerNorm but works for 2D data\n",
        "        self.post_norm= nn.GroupNorm(\n",
        "            num_groups=1, num_channels=out_channels, eps=eps\n",
        "        ) if post_norm else None\n",
        "        # Activation function -- GELU is the default in ConvNeXt\n",
        "        self.activation= activation\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pre_norm is not None:\n",
        "            x= self.pre_norm(x)\n",
        "        x= self.conv(x)\n",
        "        if self.post_norm is not None:\n",
        "            x= self.post_norm(x)\n",
        "        if self.activation is not None:\n",
        "            x= self.activation(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "U_0FaR0i4RrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.LayerNorm by default expects inputs of shape $[*, D]$ (or more generally it normalizes over the last len(normalized_shape) dimensions). When we do nn.LayerNorm(normalized_shape=$D$) on a tensor of shape $[B, D]$ it computes mean/var over each vector of length $D$. LayerNorm2d (as used in torchvision's ConvNeXt) is really just a version of LayerNorm that works on 4D tensors $[B,C,H,W]$, normalizing across the $C \\times H \\times W$ dimensions per sample. Under the hood it is implemented using a GroupNorm with G=1 that computes mean/var over all channels and spatial positions — exactly matches what we want for a \"2D LayerNorm.\"\n",
        "\n",
        "Therefore, by using GroupNorm(num_groups=1, num_channels=C) in our feature extractor, we are doing exactly the same normalization that torchvision calls \"LayerNorm2d after the stem and before each pointwise 1x1 conv.\""
      ],
      "metadata": {
        "id": "S44Ji7VJ6Bqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StochasticDepth(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements stochastic depth regularization.\n",
        "    During training, randomly drops the output of the block with probability survival_prob\n",
        "    scaling the remaining output to maintain the expected value.\n",
        "    - mode: 'row' to drop per-sample, 'batch' to drop entire batch together.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, survival_prob, mode='row') -> None:\n",
        "        super(StochasticDepth, self).__init__()\n",
        "        assert 0.0 <= survival_prob <= 1.0, \"survival_prob must be in [0, 1]\"\n",
        "        assert mode in ('row', 'batch'), \"mode must be 'row' or 'batch'\"\n",
        "        self.survival_prob= survival_prob\n",
        "        self.mode= mode\n",
        "\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f\"p={self.survival_prob}, mode={self.mode}\"\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if (not self.training) or self.survival_prob in (0.0, 1.0):\n",
        "            return x\n",
        "\n",
        "        if self.mode== 'row':\n",
        "            # Mask with the same batch size and shape (broadcasted over spatial dimensions)\n",
        "            mask_shape= (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "        else:  # 'batch'\n",
        "            # Mask for the whole batch\n",
        "            mask_shape= (1,) * x.ndim\n",
        "\n",
        "        keep_mask= (torch.rand(mask_shape, device=x.device) < self.survival_prob).type_as(x)\n",
        "        # Scale the output to maintain expected value and apply the mask\n",
        "        return torch.div(x, self.survival_prob) * keep_mask\n"
      ],
      "metadata": {
        "id": "glbh157386kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvNext uses depthwise convolutions (like in MobileNet and later in EfficientNet). This operation reduces FLOPS and is similar to taking the weighted sum in self-attention, which mixes information only in the spatial dimension.\n",
        "\n",
        "One important design in every Transformer block is that it creates an **inverted bottleneck**, i.e., the hidden dimension of the FFN block is four times wider than the input dimension. Interestingly, this Transformer design is connected to the inverted bottleneck design with an expansion ratio of 4 used in 1x1 convs. So we go from **wide -> narrow -> wide** to **narrow -> wide -> narrow**. The idea was popularized by MobileNetV2 (InvertedBottleneckBlock), and has subsequently gained traction in several advanced CNN architectures.\n",
        "\n",
        "However, the depthwise convolutional layer was moved from the center to the first layer in the block, and its kernel size was increased to 7x7.\n",
        "\n",
        "In Transformer blocks, there is only one activation function, the one inside the MLP block. ConvNeXt reduces the number of activation functions and keeps only the one after the middle conv layer of the inverted bottleneck. Similar to activations, the authors reduced the number of normalization layers, keeping only the one before the middle conv."
      ],
      "metadata": {
        "id": "3AynWUrckX8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the ConvNeXt Inverted Bottleneck Block with layer scale and stochastic depth.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, expansion_ratio=4, bias=True, activation=None, drop_path=0.0,\n",
        "                 layer_scale_init=1e-6) -> None:\n",
        "        super(CNBlock, self).__init__()\n",
        "        # Activation function -- GELU is the default in ConvNeXt\n",
        "        activation= nn.GELU() if activation is None else activation\n",
        "\n",
        "        # The inverted bottleneck block\n",
        "        self.bottleneck= nn.Sequential(\n",
        "            # narrow -> wide (with depthwise conv and bigger kernel)\n",
        "            ConvLayer(\n",
        "                channels, channels, kernel_size=7, stride=1, padding=3, groups=channels,\n",
        "                bias=bias, pre_norm=False, post_norm=True, activation=None\n",
        "            ),\n",
        "            # wide -> wide (pointwise -- 1x1 conv)\n",
        "            ConvLayer(\n",
        "                channels, channels * expansion_ratio, kernel_size=1, stride=1, padding=0,\n",
        "                bias=bias, pre_norm=False, post_norm=False, activation=activation\n",
        "            ),\n",
        "            # wide -> narrow (projection phase -- 1x1 conv to restore channels)\n",
        "            ConvLayer(\n",
        "                channels * expansion_ratio, channels, kernel_size=1, stride=1, padding=0,\n",
        "                bias=bias, pre_norm=False, post_norm=False, activation=None\n",
        "            )\n",
        "        )\n",
        "        # (optional) layer‐scale (one learnable parameter per channel)\n",
        "        if layer_scale_init > 0.0:\n",
        "            self.layer_scaler= nn.Parameter(\n",
        "                layer_scale_init * torch.ones((channels)), requires_grad=True\n",
        "            )\n",
        "        else:\n",
        "            self.layer_scaler= None\n",
        "        # For stochastic depth\n",
        "        self.drop_path= StochasticDepth(drop_path) if drop_path > 0.0 else nn.Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Save the original input for the residual connection\n",
        "        identity= x\n",
        "        # Compute the inverted bottleneck block convolutions\n",
        "        out= self.bottleneck(x)\n",
        "\n",
        "        if self.layer_scaler is not None:\n",
        "            # Reshape to [1, C, 1, 1] for broadcasting\n",
        "            out= self.layer_scaler[None, :, None, None] * out\n",
        "\n",
        "        out= identity + self.drop_path(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "g7YxhqPJ4Rt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the ConvNeXt\n",
        "\n",
        "ResNet **stem** uses a very aggressive 7x7 conv and a maxpool to heavily downsample the input images. But the Swin-Transformer uses non-overlapping patches with a 4x4 kernel size. Therefore, the **ConvNeXt** stem is now a 4x4 convolutional layer with a stride of four, so that the patches don't overlap.\n",
        "\n",
        "In ResNet, downsampling is done using stride=2 convs in the Bottleneck Blocks. Transformers have separate downsampling blocks. Therefore, ConvNeXt removes the stride=2 convs from Bottlenecks and adds **separate downsampling layers between stages** that consist of a layer normalization and a 2x2 conv layer with stride=2.\n",
        "\n",
        "Finally, ConvNeXt adds a layer normalisation after the average pooling after the fourth stage (before the classification head)."
      ],
      "metadata": {
        "id": "foshnQh84muo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNeXt(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the ConvNeXt architecture.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, configs, in_channels, num_classes=None, bias=True, activation=None,\n",
        "                 drop_path=0.1, layer_scale_init=1e-6) -> None:\n",
        "        super(ConvNeXt, self).__init__()\n",
        "        # dims (channels) and depths (number of blocks at each stage)\n",
        "        dims=   configs[0]\n",
        "        depths= configs[1]\n",
        "        # Activation function -- GELU is the default in ConvNeXt\n",
        "        activation= nn.GELU() if activation is None else activation\n",
        "\n",
        "        # Stem + 3 downsampling layers\n",
        "        downsample_layers= nn.ModuleList()\n",
        "        # Stem\n",
        "        downsample_layers.append(ConvLayer(\n",
        "            in_channels, dims[0], kernel_size=4, stride=4, padding=0, bias=bias,\n",
        "            pre_norm=False, post_norm=True, activation=None\n",
        "        ))\n",
        "        # and 3 intermediate downsampling ConvLayers\n",
        "        for i in range(3):\n",
        "            downsample_layers.append(ConvLayer(\n",
        "                dims[i], dims[i+1], kernel_size=2, stride=2, padding=0, bias=bias,\n",
        "                pre_norm=True, post_norm=False, activation=None\n",
        "            ))\n",
        "\n",
        "        # 4 feature resolution stages, each consisting of multiple Bottleneck (CN)Blocks\n",
        "        stages= nn.ModuleList()\n",
        "        # Create drop path probabilities (one for each stage)\n",
        "        total_blocks= sum(depths)\n",
        "        drop_rates= [x.item() for x in torch.linspace(0, drop_path, total_blocks)]\n",
        "        cur= 0  # current stage (to track how many blocks we've already assigned a drop‑path prob)\n",
        "\n",
        "        for i in range(4):\n",
        "            residual_blocks= nn.Sequential(\n",
        "                *[CNBlock(\n",
        "                    dims[i], expansion_ratio=4, bias=bias, activation=activation,\n",
        "                    drop_path=drop_rates[cur + j], layer_scale_init=layer_scale_init\n",
        "                ) for j in range(depths[i])]\n",
        "            )\n",
        "            stages.append(residual_blocks)\n",
        "            cur += depths[i]  # advance the offset by the number of blocks in this stage\n",
        "\n",
        "        # The feature extractor is a sequence of downsample_layers and resolution stages\n",
        "        features= nn.ModuleList()\n",
        "        for i in range(4):\n",
        "            features.append(downsample_layers[i])\n",
        "            features.append(stages[i])\n",
        "\n",
        "        self.features= nn.Sequential(*features)\n",
        "\n",
        "        # Pooling and classification head to produce the class logits\n",
        "        self.average_pool= nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.fc_out= nn.Sequential(\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.LayerNorm(dims[-1], eps=1e-6),\n",
        "            nn.Dropout(p=drop_path),\n",
        "            nn.Linear(dims[-1], num_classes)\n",
        "        ) if num_classes is not None else None\n",
        "\n",
        "        # initialize parameters with Xavier\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            if isinstance(m, (nn.GroupNorm, nn.LayerNorm)):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.features(x)\n",
        "        x= self.average_pool(x)\n",
        "        if self.fc_out is not None:\n",
        "            x= self.fc_out(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "o60drr3L4R4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchvision.models import (\n",
        "    convnext_tiny,   ConvNeXt_Tiny_Weights,\n",
        "    convnext_small,  ConvNeXt_Small_Weights,\n",
        "    convnext_base,   ConvNeXt_Base_Weights,\n",
        "    convnext_large,  ConvNeXt_Large_Weights,\n",
        ")\n",
        "\n",
        "tvis_model= convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4trv_gYhz5q",
        "outputId": "be376649-9d60-48e9-c5c4-f1bdabf15cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n",
            "100%|██████████| 109M/109M [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 28589128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img= torch.randn(1, 3, 224, 224).to(device)\n",
        "model= ConvNeXt(model_hparameters['convnext_tiny'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVt4Sh716Usg",
        "outputId": "104e7881-49da-4e92-a50b-915b6c733637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 28589128\n",
            "torch.Size([1, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNeXt(\n",
              "  (features): Sequential(\n",
              "    (0): ConvLayer(\n",
              "      (conv): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (post_norm): GroupNorm(1, 96, eps=1e-06, affine=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "            (post_norm): GroupNorm(1, 96, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "            (post_norm): GroupNorm(1, 96, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.0058823530562222, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "            (post_norm): GroupNorm(1, 96, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.0117647061124444, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): ConvLayer(\n",
              "      (pre_norm): GroupNorm(1, 96, eps=1e-06, affine=True)\n",
              "      (conv): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "            (post_norm): GroupNorm(1, 192, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.01764705963432789, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "            (post_norm): GroupNorm(1, 192, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.0235294122248888, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "            (post_norm): GroupNorm(1, 192, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.029411764815449715, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): ConvLayer(\n",
              "      (pre_norm): GroupNorm(1, 192, eps=1e-06, affine=True)\n",
              "      (conv): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.03529411926865578, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.04117647185921669, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.0470588244497776, mode=row)\n",
              "      )\n",
              "      (3): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.052941177040338516, mode=row)\n",
              "      )\n",
              "      (4): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.05882352963089943, mode=row)\n",
              "      )\n",
              "      (5): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.06470588594675064, mode=row)\n",
              "      )\n",
              "      (6): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.07058823853731155, mode=row)\n",
              "      )\n",
              "      (7): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.07647059112787247, mode=row)\n",
              "      )\n",
              "      (8): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "            (post_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.08235294371843338, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): ConvLayer(\n",
              "      (pre_norm): GroupNorm(1, 384, eps=1e-06, affine=True)\n",
              "      (conv): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "            (post_norm): GroupNorm(1, 768, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.0882352963089943, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "            (post_norm): GroupNorm(1, 768, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.0941176488995552, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (bottleneck): Sequential(\n",
              "          (0): ConvLayer(\n",
              "            (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "            (post_norm): GroupNorm(1, 768, eps=1e-06, affine=True)\n",
              "          )\n",
              "          (1): ConvLayer(\n",
              "            (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (2): ConvLayer(\n",
              "            (conv): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (drop_path): StochasticDepth(p=0.10000000149011612, mode=row)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (average_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc_out): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tvis_model= convnext_small(weights=ConvNeXt_Small_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCLgxwxoLAzY",
        "outputId": "6286b638-2287-4a3e-edeb-b6b774a04122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_small-0c510722.pth\" to /root/.cache/torch/hub/checkpoints/convnext_small-0c510722.pth\n",
            "100%|██████████| 192M/192M [00:00<00:00, 237MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 50223688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= ConvNeXt(model_hparameters['convnext_small'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ5cv9TmLZkM",
        "outputId": "0b55533e-4dff-4b0c-bafb-688adf0bf5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 50223688\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tvis_model= convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut7epmCQLBEf",
        "outputId": "3814bf77-9967-41d1-b285-a8a88d8dbd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
            "100%|██████████| 338M/338M [00:01<00:00, 235MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 88591464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= ConvNeXt(model_hparameters['convnext_base'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwkcRzycLaVJ",
        "outputId": "a55a5fdc-eda4-481a-8325-dff63571fa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 88591464\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tvis_model= convnext_large(weights=ConvNeXt_Large_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufUiglQpLBUN",
        "outputId": "d3e4f39e-4c1d-49cf-9839-2e8c08a59d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_large-ea097f82.pth\" to /root/.cache/torch/hub/checkpoints/convnext_large-ea097f82.pth\n",
            "100%|██████████| 755M/755M [00:03<00:00, 234MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 197767336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= ConvNeXt(model_hparameters['convnext_large'], in_channels=3, num_classes=1000).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1E4symsLbHw",
        "outputId": "470a218f-aff6-4e8e-9be3-1d7ee9b1f6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 197767336\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a ConvNeXt model from scratch"
      ],
      "metadata": {
        "id": "lAkIhlzt4u2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "Jacl19u24SB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation -- define transformations for the dataset\n",
        "transform= transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std= [0.2023, 0.1994, 0.2010]), # CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# load the CIFAR-10 dataset\n",
        "train_dataset= datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "train_size= int(0.9 * len(train_dataset))\n",
        "val_size  = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset= random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size= 128\n",
        "train_loader= DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "PDkm8nig4SFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d339b833-82c1-4ed7-d02b-51f6789f48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(val_loader)"
      ],
      "metadata": {
        "id": "N4ac5px24SJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f648ac-0e8e-4f4e-e1f2-1ee41c5be205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Function\n",
        "\n",
        "TODO:\n",
        "\n",
        "- Strong data augmentation for training.\n",
        "- Early Stopping: based on validation loss to prevent overfitting.\n",
        "- Play with different learning rate values.\n",
        "- More training epochs.\n",
        "- Larger batch sizes.\n",
        "- Use label smoothing."
      ],
      "metadata": {
        "id": "a8XPm86h45b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineLRDecay:\n",
        "    \"\"\"\n",
        "    Modulates learning rate (LR) based on the iteration (step) number which LR there should be.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, min_lr, max_lr=3e-4, warmup_steps=10, max_steps=50) -> None:\n",
        "        assert warmup_steps < max_steps, \"warmup_steps must be less than max_steps\"\n",
        "        self.optimizer= optimizer\n",
        "        self.min_lr= min_lr\n",
        "        self.max_lr= max_lr\n",
        "        self.warmup_steps= warmup_steps\n",
        "        self.max_steps= max_steps\n",
        "        self.last_step= 0\n",
        "        self.last_lr= None\n",
        "\n",
        "\n",
        "    def get_last_lr(self):\n",
        "        \"\"\" Returns the last computed learning rate. \"\"\"\n",
        "        return self.last_lr\n",
        "\n",
        "\n",
        "    def get_lr(self, it):\n",
        "        \"\"\" Computes the learning rate at a given iteration 'step'. \"\"\"\n",
        "        # 1) linear warmup for warmup_iters steps iterations\n",
        "        if it< self.warmup_steps:\n",
        "            return self.max_lr * (it + 1) / self.warmup_steps\n",
        "        # 2) beyond max_steps, use the minimum learning rate\n",
        "        if it>= self.max_steps:\n",
        "            return self.min_lr\n",
        "        # 3) in between, use cosine decay down to min learning rate\n",
        "        decay_ratio= (it - self.warmup_steps) / (self.max_steps - self.warmup_steps)\n",
        "        assert 0 <= decay_ratio <= 1\n",
        "        # coeff starts at 1 and goes to 0\n",
        "        coeff= 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "\n",
        "        return self.min_lr + coeff * (self.max_lr - self.min_lr)\n",
        "\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\" Updates the learning rate for all parameter groups in the optimizer. \"\"\"\n",
        "        self.last_lr= self.get_lr(self.last_step)\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr']= self.last_lr\n",
        "\n",
        "        self.last_step += 1\n"
      ],
      "metadata": {
        "id": "jDORjbXeg8uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs,\n",
        "            device, eval_interval=1, verbose=False):\n",
        "\n",
        "    tr_loss_hist= []\n",
        "    vl_loss_hist= []\n",
        "\n",
        "    # --- training loop ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_loss= []\n",
        "        start= time.time()\n",
        "\n",
        "        # --- training steps ---\n",
        "        # iterating over all batches\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # --- minibatch construction ---\n",
        "            images= images.to(device, non_blocking=True)\n",
        "            labels= labels.to(device, non_blocking=True)\n",
        "\n",
        "            # --- forward pass and get loss ---\n",
        "            logits= model(images)\n",
        "            loss= criterion(logits, labels)\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            # --- backward pass to calculate the gradients ---\n",
        "            loss.backward()\n",
        "\n",
        "            # --- update the parameters using the gradient ---\n",
        "            optimizer.step()\n",
        "            # for decreasing learning rate -- CosineLRDecay is designed to be used per step\n",
        "            scheduler.step()\n",
        "\n",
        "        # --- evaluation and track stats ---\n",
        "        tr_loss_hist.append(np.mean(batch_loss))\n",
        "\n",
        "        if epoch% eval_interval== 0 or epoch== epochs-1:\n",
        "            model.eval()\n",
        "            val_loss= []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels= images.to(device), labels.to(device)\n",
        "                    logits= model(images)\n",
        "                    loss_v= criterion(logits, labels)\n",
        "                    val_loss.append(loss_v.item())\n",
        "\n",
        "            val_loss= np.mean(val_loss)\n",
        "            end= time.time()\n",
        "            dt= end - start\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch: {epoch} | Train Loss: {tr_loss_hist[-1]:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f} | dt/epoch: {dt*1000:.2f}ms\")\n",
        "\n",
        "        vl_loss_hist.append(val_loss)\n",
        "\n",
        "    return tr_loss_hist, vl_loss_hist\n"
      ],
      "metadata": {
        "id": "PO2vdiyg4SNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device, verbose=False):\n",
        "    model.eval()\n",
        "    correct= 0\n",
        "    total= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels= images.to(device), labels.to(device)\n",
        "            logits= model(images)\n",
        "            y_pred= torch.argmax(logits, dim=1)\n",
        "            correct += (y_pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc= correct / total\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {(acc * 100):.2f}%\")\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "hwjGaJWl4SQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(train_loss, valid_loss):\n",
        "    # plot training and validation losses\n",
        "    plt.plot(train_loss, label='Train Loss')\n",
        "    plt.plot(valid_loss, label='Validation Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "iFU08T9o4STV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup using TF32 and Fused AdamW"
      ],
      "metadata": {
        "id": "E4Icu2rJ5FfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_fused= False\n",
        "\n",
        "if device== 'cuda': # TF32 computationally more efficient (slightly the same precision of FP32)\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    # create AdamW optimizer and use the fused version of it is available\n",
        "    fused_available= 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "    # fused is a lot faster when it is available and when running on cuda\n",
        "    use_fused= fused_available\n",
        "\n",
        "# --- ConvNeXt ---\n",
        "in_channels= 3\n",
        "num_classes= 10\n",
        "\n",
        "model= ConvNeXt(model_hparameters['convnext_tiny'], in_channels, num_classes, dropout=0.1).to(device)\n",
        "count_parameters(model)\n",
        "\n",
        "\n",
        "# train_loader has size 352, so 40 epochs have 14,080 steps\n",
        "epochs= 40\n",
        "steps= len(train_loader) * epochs\n",
        "learning_rate= 4e-3\n",
        "\n",
        "max_lr= learning_rate\n",
        "min_lr= 1e-4\n",
        "warmup_steps= 704  # 2 epochs of warmup\n",
        "max_steps= steps\n",
        "\n",
        "optimizer= torch.optim.AdamW(\n",
        "    model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=0.05,\n",
        "    fused=use_fused\n",
        ")\n",
        "print(f\"Using fused AdamW: {use_fused}\")\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "# for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "scheduler= CosineLRDecay(optimizer, min_lr, max_lr, warmup_steps, max_steps)\n"
      ],
      "metadata": {
        "id": "pLyhrxg-4SWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72e4e9b-ad8e-4bb3-ba6e-1649151c40f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 27827818\n",
            "Using fused AdamW: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss, vl_loss= trainer(model, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                          epochs, device, verbose=True)"
      ],
      "metadata": {
        "id": "I-hInO_r4Sbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9a613f-7eeb-4584-8578-46789cd5ce02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 2.7643 | Val Loss: 2.0921 | dt/epoch: 94634.02ms\n",
            "Epoch: 1 | Train Loss: 1.9494 | Val Loss: 1.8085 | dt/epoch: 93918.41ms\n",
            "Epoch: 2 | Train Loss: 1.7120 | Val Loss: 1.6304 | dt/epoch: 93957.97ms\n",
            "Epoch: 3 | Train Loss: 1.6281 | Val Loss: 1.5654 | dt/epoch: 93968.15ms\n",
            "Epoch: 4 | Train Loss: 1.5670 | Val Loss: 1.5303 | dt/epoch: 93811.53ms\n",
            "Epoch: 5 | Train Loss: 1.5108 | Val Loss: 1.4614 | dt/epoch: 93924.32ms\n",
            "Epoch: 6 | Train Loss: 1.4679 | Val Loss: 1.4640 | dt/epoch: 94401.53ms\n",
            "Epoch: 7 | Train Loss: 1.4229 | Val Loss: 1.4019 | dt/epoch: 94294.41ms\n",
            "Epoch: 8 | Train Loss: 1.3578 | Val Loss: 1.3850 | dt/epoch: 94223.36ms\n",
            "Epoch: 9 | Train Loss: 1.3068 | Val Loss: 1.2581 | dt/epoch: 93935.12ms\n",
            "Epoch: 10 | Train Loss: 1.2546 | Val Loss: 1.2731 | dt/epoch: 93771.58ms\n",
            "Epoch: 11 | Train Loss: 1.2161 | Val Loss: 1.1955 | dt/epoch: 94157.91ms\n",
            "Epoch: 12 | Train Loss: 1.1768 | Val Loss: 1.1798 | dt/epoch: 94014.19ms\n",
            "Epoch: 13 | Train Loss: 1.1458 | Val Loss: 1.1484 | dt/epoch: 94279.59ms\n",
            "Epoch: 14 | Train Loss: 1.1257 | Val Loss: 1.1279 | dt/epoch: 93808.26ms\n",
            "Epoch: 15 | Train Loss: 1.0970 | Val Loss: 1.1980 | dt/epoch: 93874.32ms\n",
            "Epoch: 16 | Train Loss: 1.0810 | Val Loss: 1.0551 | dt/epoch: 94008.95ms\n",
            "Epoch: 17 | Train Loss: 1.0618 | Val Loss: 1.0531 | dt/epoch: 94335.02ms\n",
            "Epoch: 18 | Train Loss: 1.0415 | Val Loss: 1.0690 | dt/epoch: 94139.34ms\n",
            "Epoch: 19 | Train Loss: 1.0198 | Val Loss: 0.9996 | dt/epoch: 93948.50ms\n",
            "Epoch: 20 | Train Loss: 1.0015 | Val Loss: 1.0207 | dt/epoch: 94068.84ms\n",
            "Epoch: 21 | Train Loss: 0.9780 | Val Loss: 1.0439 | dt/epoch: 94020.39ms\n",
            "Epoch: 22 | Train Loss: 0.9681 | Val Loss: 1.0399 | dt/epoch: 93733.68ms\n",
            "Epoch: 23 | Train Loss: 0.9475 | Val Loss: 1.0418 | dt/epoch: 93790.35ms\n",
            "Epoch: 24 | Train Loss: 0.9266 | Val Loss: 0.9875 | dt/epoch: 93922.28ms\n",
            "Epoch: 25 | Train Loss: 0.9054 | Val Loss: 0.9319 | dt/epoch: 93508.79ms\n",
            "Epoch: 26 | Train Loss: 0.8852 | Val Loss: 0.9035 | dt/epoch: 93278.04ms\n",
            "Epoch: 27 | Train Loss: 0.8679 | Val Loss: 0.9176 | dt/epoch: 93848.85ms\n",
            "Epoch: 28 | Train Loss: 0.8422 | Val Loss: 0.8937 | dt/epoch: 93953.60ms\n",
            "Epoch: 29 | Train Loss: 0.8248 | Val Loss: 0.8900 | dt/epoch: 93557.81ms\n",
            "Epoch: 30 | Train Loss: 0.8116 | Val Loss: 0.8660 | dt/epoch: 93529.12ms\n",
            "Epoch: 31 | Train Loss: 0.7952 | Val Loss: 0.8335 | dt/epoch: 93763.24ms\n",
            "Epoch: 32 | Train Loss: 0.7751 | Val Loss: 0.8498 | dt/epoch: 93862.63ms\n",
            "Epoch: 33 | Train Loss: 0.7607 | Val Loss: 0.8055 | dt/epoch: 93894.79ms\n",
            "Epoch: 34 | Train Loss: 0.7504 | Val Loss: 0.8037 | dt/epoch: 93691.09ms\n",
            "Epoch: 35 | Train Loss: 0.7362 | Val Loss: 0.7925 | dt/epoch: 93430.16ms\n",
            "Epoch: 36 | Train Loss: 0.7240 | Val Loss: 0.7636 | dt/epoch: 93495.36ms\n",
            "Epoch: 37 | Train Loss: 0.7169 | Val Loss: 0.7747 | dt/epoch: 93858.24ms\n",
            "Epoch: 38 | Train Loss: 0.7078 | Val Loss: 0.7734 | dt/epoch: 93980.25ms\n",
            "Epoch: 39 | Train Loss: 0.7059 | Val Loss: 0.7689 | dt/epoch: 93631.16ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "plot_losses(tr_loss, vl_loss)"
      ],
      "metadata": {
        "id": "EGqvHC8a4Se7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "098d0497-5b9e-4bc1-9307-15bea87abd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAapxJREFUeJzt3Xd4VFX+x/H3THqvpNBbgNA7UgXpIoLYRQXrTwVXdNVd1wb23ldWV4W1IJYVdQGB0EF676ETSkISSK+TzP39MWQwUgOTmWTyeT3PfZK5c+fO98ywm4/nnnuOyTAMAxERERE3YXZ1ASIiIiKOpHAjIiIibkXhRkRERNyKwo2IiIi4FYUbERERcSsKNyIiIuJWFG5ERETErSjciIiIiFtRuBERERG3onAjIiIibkXhRkScYurUqZhMJtatW+fqUkTEzSnciIiIiFtRuBERERG3onAjIlXGxo0bGTp0KMHBwQQGBtK/f39WrVpV7hiLxcKkSZOIi4vD19eXiIgIevXqRUJCgv2YlJQU7rrrLurWrYuPjw+xsbGMGDGCgwcPljvXb7/9Ru/evQkICCAoKIhhw4axffv2csdc7LlEpOrwdHUBIiIA27dvp3fv3gQHB/Pkk0/i5eXFJ598Qt++fVmyZAndunUDYOLEibz66qvce++9dO3alezsbNatW8eGDRsYOHAgANdffz3bt2/n4YcfpmHDhqSmppKQkEBSUhINGzYE4KuvvmLMmDEMHjyY119/nfz8fCZPnkyvXr3YuHGj/biLOZeIVDGGiIgTTJkyxQCMtWvXnvX5kSNHGt7e3sa+ffvs+44dO2YEBQUZffr0se9r166dMWzYsHO+T0ZGhgEYb7755jmPycnJMUJDQ4377ruv3P6UlBQjJCTEvv9iziUiVY8uS4mIy5WWljJv3jxGjhxJ48aN7ftjY2O57bbbWL58OdnZ2QCEhoayfft29uzZc9Zz+fn54e3tzeLFi8nIyDjrMQkJCWRmZnLrrbeSnp5u3zw8POjWrRuLFi266HOJSNWjcCMiLpeWlkZ+fj7Nmzc/47n4+HisViuHDx8G4IUXXiAzM5NmzZrRpk0bnnjiCbZs2WI/3sfHh9dff53ffvuN6Oho+vTpwxtvvEFKSor9mLJgdNVVV1GrVq1y27x580hNTb3oc4lI1aNwIyLVSp8+fdi3bx9ffPEFrVu35rPPPqNjx4589tln9mMmTJjA7t27efXVV/H19eXZZ58lPj6ejRs3AmC1WgHbuJuEhIQztl9++eWizyUiVZCrr4uJSM1wvjE3JSUlhr+/v3HTTTed8dwDDzxgmM1mIysr66znzcnJMTp06GDUqVPnnO+9e/duw9/f3xg9erRhGIbx/fffG4Axd+7cCrfjz+cSkapHPTci4nIeHh4MGjSIX375pdwt1sePH2fatGn06tWL4OBgAE6cOFHutYGBgTRt2pSioiIA8vPzKSwsLHdMkyZNCAoKsh8zePBggoODeeWVV7BYLGfUk5aWdtHnEpGqR7eCi4hTffHFF8yZM+eM/RMnTiQhIYFevXrx0EMP4enpySeffEJRURFvvPGG/biWLVvSt29fOnXqRHh4OOvWrePHH39k/PjxAOzevZv+/ftz00030bJlSzw9PZkxYwbHjx/nlltuASA4OJjJkydzxx130LFjR2655RZq1apFUlISs2bNomfPnnz00UcXdS4RqYJc3XUkIjVD2WWpc22HDx82NmzYYAwePNgIDAw0/P39jX79+hkrVqwod56XXnrJ6Nq1qxEaGmr4+fkZLVq0MF5++WWjuLjYMAzDSE9PN8aNG2e0aNHCCAgIMEJCQoxu3boZ33///Rk1LVq0yBg8eLAREhJi+Pr6Gk2aNDHGjh1rrFu3rsLnEpGqw2QYhuHCbCUiIiLiUBpzIyIiIm5F4UZERETcisKNiIiIuBWFGxEREXErCjciIiLiVhRuRERExK3UuEn8rFYrx44dIygoCJPJ5OpyRERE5CIYhkFOTg61a9fGbD5/30yNCzfHjh2jXr16ri5DRERELsHhw4epW7fueY+pceEmKCgIsH04ZWvVOIrFYmHevHkMGjQILy8vh567KqkJ7awJbQS1092one6jJrQRKtbO7Oxs6tWrZ/87fj41LtyUXYoKDg6ulHDj7+9PcHCw2/9jdPd21oQ2gtrpbtRO91ET2giX1s6LGVKiAcUiIiLiVhRuRERExK0o3IiIiIhbqXFjbkRE5PKVlpZisVhc8t4WiwVPT08KCwspLS11SQ2VrSa0Ec5sp7e39wVv874YCjciInLRDMMgJSWFzMxMl9YQExPD4cOH3Xa+sprQRjiznWazmUaNGuHt7X1Z51W4ERGRi1YWbKKiovD393fJH16r1Upubi6BgYEO+a/8qqgmtBHKtxNsc9ElJydTv379y/q3pXAjIiIXpbS01B5sIiIiXFaH1WqluLgYX19ft/3DXxPaCGe2s1atWhw7doySkpLLugXefT8xERFxqLIxNv7+/i6uRNxV2eWoyx1npHAjIiIV4s5jQMS1HPVvS+FGRERE3IrCjYiISAU1bNiQ9957z9VlyDko3IiIiNsymUzn3SZOnHhJ5127di3333//ZdXWt29fJkyYcFnnkLPT3VIOUmo1SM0pIr3Q1ZWIiEiZ5ORk++/fffcdzz33HImJifZ9Zbcgg23OldLSUjw9L/ynsVatWo4tVBxKPTcOsmr/CXq+sYR/7/JwdSkiInJKTEyMfQsJCcFkMtkf79q1i6CgIH777Tc6deqEj48Py5cvZ9++fYwYMYLo6GgCAwPp0qUL8+fPL3feP1+WMplMfPbZZ1x33XX4+/sTFxfHr7/+elm1//rrr7Rp0wYfHx8aNmzI22+/Xe75jz/+mLi4OHx9fYmOjuaGG26wP/fjjz/Spk0b/Pz8iIiIYMCAAeTl5V1WPdWJem4cJCLQdvtajmtmIxcRcTrDMCiwOH9pAKvVimEYDjvf3//+d9566y0aN25MWFgYhw8f5uqrr+bll1/Gx8eHL7/8kuHDh5OYmEj9+vXPeZ5Jkybxxhtv8Oabb/Lhhx8yevRoDh06RHh4eIVrWr9+PXfddRfPP/88t9xyCytWrOChhx4iIiKCsWPHsm7dOv7yl7/w1Vdf0aNHD06ePMmyZcsAW2/VrbfeyhtvvMF1111HTk4Oy5Ytc+hnVtUp3DhIZKAPAPklUFJq5TLmHhIRqRYKLKW0fG6uS9575WNXEOKgc73wwgsMHDjQ/jg8PJx27drZH7/44ovMmDGDX3/9lfHjx5/zPGPHjuXWW28F4JVXXuGDDz5gzZo1DBkypMI1vfvuu1x55ZU888wzmM1mmjVrxo4dO3jzzTcZO3YsSUlJBAQEcM011xAUFESDBg3o0KEDYAs3JSUljBo1igYNGgDQpk2bCtdQnemylIOE+XtjMoGBicwCdd+IiFQXnTt3Lvc4NzeXxx9/nPj4eEJDQwkMDGTnzp0kJSWd9zxt27a1/x4QEEBwcDCpqamXVNOuXbvo1q1buX09e/Zkz549lJaWMnDgQBo0aEDjxo254447+Oabb8jPzwegXbt29O/fnzZt2nDjjTfy73//m4yMjEuqo7pSz42DeJhNhPl7cTLPwoncYmLDXF2RiEjl8vPyYMcLg53+vlarFUuB48aPBAQElHv8+OOPk5CQwFtvvUXTpk3x8/PjhhtuoLi4+Lzn+fNyASaTCavV6rA6/ygoKIgNGzawePFi5s2bx3PPPcfEiRNZu3YtoaGhJCQksGLFCubNm8eHH37I008/zerVq2nUqFGl1FPVqOfGgSICbONu0vPO/z8AERF3YDKZ8Pf2dMlWmbMk//7774wdO5brrruONm3aEBMTw8GDByvt/c6mRYsWrF69+oy6mjVrhoeH7cYVT09PBgwYwBtvvMGWLVs4ePAgCxcuBGzfTc+ePZk0aRIbN27E29ubGTNmOLUNrqSeGweKDPRhT2oeJ3IVbkREqqu4uDh++uknhg8fjslk4tlnn620Hpi0tDQ2bdpUbl9sbCyPPfYY3bp146WXXuKWW25h5cqVfPTRR3z88ccAzJw5k/3799OnTx/CwsKYPXs2VquV5s2bs3r1ahYsWMCgQYOIiopi9erVpKWlER8fXyltqIoUbhwo/FTPzQn13IiIVFvvvPMOd999Nz169CAyMpK//e1vZGdnV8p7TZs2jWnTppXb9+KLL/KPf/yDKVOm8Prrr/PSSy8RGxvLCy+8wNixYwEIDQ3lp59+YuLEiRQWFhIXF8e3335Lq1at2LlzJ0uXLuW9994jOzubBg0a8PbbbzN06NBKaUNVpHDjQGWXpU4q3IiIVDljx461hwOwzRB8ttujGzZsaL+8U2bcuHHlHv/5MtXZzpOZmXneehYvXnzO56xWK9deey233347ZvOZI0h69ep1ztfHx8czZ86c8763u9OYGweyj7nRZSkRERGXUbhxoMjAsstSRS6uREREpOZSuHGgCI25ERERcTmFGwcKP9Vzc1KXpURERFxG4caB/jjPTU1aw0NERKQqUbhxoLIxN4UWK/nFzl9MTkRERBRuHMrf2xNvs63HRhP5iYiIuIbCjYMFnlpaJF13TImIiLiEwo2DBZWFmxyFGxEREVdQuHGwIK9Tl6V0O7iIiNvo27cvEyZMsD9u2LAh77333nlfYzKZ+Pnnny/7vR11nppE4cbByi5LnchVz42IiKsNHz6cIUOGnPW5ZcuWYTKZ2LJlS4XPu3btWu6///7LLa+ciRMn0r59+zP2JycnV/q6UFOnTiU0NLRS38OZFG4czD7mRgOKRURc7p577iEhIYEjR46c8dyUKVPo3Lkzbdu2rfB5a9Wqhb+/vyNKvKCYmBh8fHyc8l7uQuHGwcouS6Wr50ZExOWuueYaatWqxdSpU8vtz83N5YcffuCee+7hxIkT3HrrrdSpUwd/f3/atGnDt99+e97z/vmy1J49e+jTpw++vr60bNmShISEM17zt7/9jWbNmuHv70/jxo159tlnsVgsgK3nZNKkSWzevBmTyYSHh4d9tfA/X5baunUrV111FX5+fkRERHD//feTm5trf37s2LGMHDmSt956i9jYWCIiIhg3bpz9vS5FUlISI0aMIDAwkODgYG666SaOHz9uf37z5s3069ePoKAggoOD6dSpE+vWrQPg0KFDDB8+nLCwMAICAmjVqhWzZ8++5FouhlYFd7Ag+2Up9dyIiJszDLDkO/99rVbbe18ET09P7rzzTqZOncrTTz+NyWQC4IcffqC0tJRbb72V3NxcOnXqxN/+9jeCg4OZNWsWd9xxB02aNKFr164XUY6VUaNGER0dzerVq8nKyio3PqdMUFAQU6dOpXbt2mzdupX77ruPoKAgnnzySW6++Wa2bdvGnDlzmD9/Plar1V7rH+Xl5TF48GC6d+/O2rVrSU1N5d5772X8+PHlAtyiRYuIjY1l0aJF7N27l5tvvpn27dtz3333XdTn9uf2lQWbJUuWUFJSwrhx47j55pvtK5OPHj2aDh06MHnyZDw8PNi0aRNeXrY/iOPGjaO4uJilS5cSEBDAjh07CAwMrHAdFaFw42D2MTe6FVxE3J0lH16p7fS3NQOM2wmEXNTxd999N2+++SZLliyhb9++gO2S1PXXX09ISAghISE8/vjj9uMffvhh5s6dy/fff39R4Wb+/Pns2rWLuXPnUru27fN45ZVXzhgn88wzz9h/b9iwIY8//jjTp0/nySefxM/Pj8DAQDw9PYmJicFqtZKdnX3Ge02bNo3CwkK+/PJLAgICAPjoo48YPnw4r7/+OtHR0QCEhYXx0Ucf4eHhQYsWLRg2bBgLFiy4pHCzYMECtm7dyoEDB6hXrx4AX375Ja1atWLt2rV06dKFpKQknnjiCVq0aAFAXFyc/fVJSUlcf/31tGnTBoDGjRtXuIaK0mUpBwvy1CR+IiJVSYsWLejRowdffPEFAHv37mXZsmXcc889AJSWlvLiiy/Spk0bwsPDCQwMZO7cuSQlJV3U+Xfu3Em9evXswQage/fuZxz33Xff0bNnT2JiYggMDOSZZ5656Pf443u1a9fOHmwAevbsidVqJTEx0b6vVatWeHh42B/HxsaSmppaoff643vWq1fPHmwAWrZsSWhoKDt37gTgscce495772XAgAG89tpr7Nu3z37sX/7yF1566SV69uzJ888/f0kDuCtKPTcOVtZzczK/mJJSK54eyo8i4qa8/OEfx5z+tlarFQpKKvSae+65h4cffph//vOfTJkyhSZNmnDllVcC8Oabb/L+++/z3nvv0aZNGwICApgwYQLFxY77j9SVK1cyevRoJk2axODBgwkJCWH69Om8/fbbDnuPPyq7JFTGZDLZPrdKMnHiRG677TZmzZrFb7/9xvPPP8/06dO57rrruPfeexk8eDCzZs1i3rx5vPrqq7z99ts8/PDDlVaP/vI6WKAXmEy2y8EZ+Zc+eEtEpMozmcA7wDXbWcajnM9NN92E2Wxm2rRpfPnll9x99932MS2///47I0aM4Pbbb6ddu3Y0btyY3bt3X/S54+PjOXz4MMnJyfZ9q1atKnfMihUraNCgAU8//TSdO3cmLi6OQ4cOlTvG29ub0tLzr0sYHx/P5s2bycvLs+/7/fffMZvNNG/e/KJrroiy9h0+fNi+b8eOHWRmZtKyZUv7vmbNmvHoo48yb948Ro0axZQpU+zP1atXjwceeICffvqJv/71r/z73/+ulFrLKNw4mNkEYf62xKxxNyIiVUNgYCA333wzTz31FMnJyYwdO9b+XFxcHAkJCaxYsYKdO3fyf//3f+XuBLqQAQMG0KxZM8aMGcPmzZtZtmwZTz/9dLlj4uLiSEpKYvr06ezbt48PPviAGTNmlDumYcOGHDhwgE2bNpGenk5R0Zl/Q0aPHo2vry9jxoxh27ZtLFq0iIcffpg77rjDPt7mUpWWlrJp06Zy286dOxkwYABt2rRh9OjRbNiwgTVr1nDnnXdy5ZVX0rlzZwoKChg/fjyLFy/m0KFD/P7776xdu5b4+HgAJkyYwNy5czlw4AAbNmxg0aJF9ucqi8JNJYgIsK0OrnE3IiJVxz333ENGRgaDBw8uNz7mmWeeoWPHjgwePJi+ffsSExPDyJEjL/q8ZrOZGTNmUFBQQNeuXbn33nt5+eWXyx1z7bXX8uijjzJ+/Hjat2/PihUrePbZZ8sdc/311zNkyBD69etHdHQ0//3vf894L39/f+bOncvJkyfp0qULN9xwA/379+ejjz6q2IdxFrm5uXTo0KHcNnz4cEwmE7/88gthYWH06dOHAQMG0LhxY7777jsAPDw8OHHiBHfeeSfNmjXjpptuYujQoUyaNAmwhaZx48YRHx/PkCFDaNasGR9//PFl13s+JsO4yPvp3ER2djYhISFkZWURHBzs0HNbLBZmz57Ntym1WHUgg/dvac+I9nUc+h5VQVk7r7766jOu67qLmtBGUDvdTWW3s7CwkAMHDtCoUSN8fX0dfv6LVXYnUXBwMGaze/43ek1oI5zZzvP9G6vI32/3/cRcKCLQNpOkZikWERFxPoWbSnD6spTG3IiIiDibwk0l0JgbERER11G4qQQRgbZwo/WlREREnE/hphJEnuq5Sc9Tz42IuJ8adh+KOJGj/m0p3FSC8ECNuRER91N2B1Z+vgsWy5QaoWxW6D8uHXEptPxCJSgbc5OeW4RhGGdd2VVEpLrx8PAgNDTUvkaRv7+/S/7/zWq1UlxcTGFhodveJl0T2gjl2wmQlpaGv78/np6XF08UbipBWbgptFjJLy4lwEcfs4i4h5iYGIBLXoTREQzDoKCgAD8/P7f9j8ea0EY4s51ms5n69etfdpv1V7cSBPh44uflQYGllBO5xQo3IuI2TCYTsbGxREVFYbG4Zv08i8XC0qVL6dOnj9tOylgT2ghnttPb29shPVX6q1tJIgK9OZJRQHpeEfUj/F1djoiIQ3l4eFz2uIjLee+SkhJ8fX3d9g9/TWgjVF47XXoh79VXX6VLly4EBQURFRXFyJEjSUxMPO9rpk6dislkKre5chrwc7HPUpyjQcUiIiLO5NJws2TJEsaNG8eqVatISEjAYrEwaNCgcku5n01wcDDJycn27c/LxlcFZbeDn9Dt4CIiIk7l0stSc+bMKfd46tSpREVFsX79evr06XPO15lMJvugtqoq8lTPjW4HFxERca4qNeYmKysLgPDw8PMel5ubS4MGDbBarXTs2JFXXnmFVq1anfXYoqIiiopOB4zs7GzANojJ0YPhys5nsVgI87d9tKnZhS4bdFdZ/thOd1UT2ghqp7tRO91HTWgjVKydFfksTEYVmWrSarVy7bXXkpmZyfLly8953MqVK9mzZw9t27YlKyuLt956i6VLl7J9+3bq1q17xvETJ05k0qRJZ+yfNm0a/v6VN9B3cbKJGQc96BBhZWwza6W9j4iISE2Qn5/PbbfdRlZWFsHBwec9tsqEmwcffJDffvuN5cuXnzWknIvFYiE+Pp5bb72VF1988Yznz9ZzU69ePdLT0y/44VSUxWIhISGBgQMH8tuOdP7641auaBTGV3d3cej7uNof2+muo/hrQhtB7XQ3aqf7qAlthIq1Mzs7m8jIyIsKN1XistT48eOZOXMmS5curVCwAdt04B06dGDv3r1nfd7HxwcfH5+zvq6y/sF4eXkRE2rrFTqZb3Hbf5iV+RlWFTWhjaB2uhu1033UhDbCxbWzIp+DS++WMgyD8ePHM2PGDBYuXEijRo0qfI7S0lK2bt1KbGxsJVR46SLs60vpbikRERFncmnPzbhx45g2bRq//PILQUFBpKSkABASEoKfnx8Ad955J3Xq1OHVV18F4IUXXuCKK66gadOmZGZm8uabb3Lo0CHuvfdel7XjbCICbL1FJ/OLKSm14unhvmuDiIiIVCUuDTeTJ08GoG/fvuX2T5kyhbFjxwKQlJRUbirmjIwM7rvvPlJSUggLC6NTp06sWLGCli1bOqvsixLm74XJBIYBGfkWagWdeWlMREREHM+l4eZixjIvXry43ON3332Xd999t5IqchxPDzPh/t6cyCvmRF6Rwo2IiIiT6FpJJdK4GxEREedTuKlEZeNu0jVLsYiIiNMo3FSisp6bdPXciIiIOI3CTSXS+lIiIiLOp3BTiSI15kZERMTpFG4qUUSgxtyIiIg4m8JNJYoIODXmJk89NyIiIs6icFOJIoM05kZERMTZFG4qUWRAWbhRz42IiIizKNxUorJbwQsspeQVlbi4GhERkZpB4aYS+Xt74Otl+4jVeyMiIuIcCjeVyGQy2ee6Sc/TuBsRERFnULipZBGBGncjIiLiTAo3lSyy7HZw3TElIiLiFAo3lez0yuAKNyIiIs6gcFPJ7GNudFlKRETEKRRuKpl9zI1mKRYREXEKhZtKVrZ4ZnqOLkuJiIg4g8JNJYsom6VYt4KLiIg4hcJNJYsMKhtQrMtSIiIizqBwU8nKem5O5hdTajVcXI2IiIj7U7ipZGH+XphMYBhwUoOKRUREKp3CTSXz9DAT5n/q0pTG3YiIiFQ6hRsniAzUuBsRERFnUbhxgrJxN1qCQUREpPIp3DhB2RIMmqVYRESk8incOEGkfWVw9dyIiIhUNoUbJ9CYGxEREedRuHGC0+tLqedGRESksincOEFEgK3nJk09NyIiIpVO4cYJIjTmRkRExGkUbpyglj3cqOdGRESksincOEHZreAFllLyi0tcXI2IiIh7U7hxAn9vD3y9bB91eo56b0RERCqTwo0TmEym07MU644pERGRSqVw4ySRQRp3IyIi4gwKN04SGVA2kZ96bkRERCqTwo2TnF5fSuFGRESkMincOEnZXDdaPFNERKRyKdw4iX3xzDyFGxERkcqkcOMkpxfP1GUpERGRyqRw4yT2W8EVbkRERCqVwo2TRNh7bnRZSkREpDIp3DhJ2Zibk/nFlFoNF1cjIiLivhRunCTM3wuTCQwDMvLVeyMiIlJZFG6cxNPDTJi/5roRERGpbAo3ThQRoHE3IiIilU3hxokiA3XHlIiISGVTuHGi00swqOdGRESksijcOJF9lmL13IiIiFQahRsn0pgbERGRyqdw40SRQWXrS6nnRkREpLIo3DhRWc9NmnpuREREKo3CjRNFaMyNiIhIpVO4caJIrS8lIiJS6RRunKjsbqkCSyn5xSUurkZERMQ9Kdw4kb+3B75eto88PUe9NyIiIpVB4caJTCYTEQGnZinWHVMiIiKVQuHGUfJOYNr2A/VOLD/vYfbbwTXuRkREpFIo3DjK0fV4/vIgzVJ+Pu9hkfaJ/NRzIyIiUhkUbhyl/hUYJjOBxamQffSch51eX0rhRkREpDIo3DiKbzBGTDsATId+P+dhEfaVwXVZSkREpDIo3DiQ0aAnAObzhBv74pl5CjciIiKVQeHGgcrCjSlpxTmPOT2Rny5LiYiIVAaFGwcy6l2BgQlTxgHIOnLWY+y3givciIiIVAqFG0fyCSLTv5Ht94NnvzQVoSUYREREKpXCjYOlB7aw/XJw2VmfLxtzczK/mFKr4ayyREREagyFGwdLD4y3/XLw7JP5hfl7YTKBYUBGvnpvREREHE3hxsFOBjbDMJnhHONuPD3MhPlrrhsREZHKonDjYCUefhgxbW0PzjXuJkDjbkRERCqLS8PNq6++SpcuXQgKCiIqKoqRI0eSmJh4wdf98MMPtGjRAl9fX9q0acPs2bOdUO3FK7sl/ELjbtRzIyIi4nguDTdLlixh3LhxrFq1ioSEBCwWC4MGDSIvL++cr1mxYgW33nor99xzDxs3bmTkyJGMHDmSbdu2ObHy8zPqnwo355jMT3dMiYiIVB5PV775nDlzyj2eOnUqUVFRrF+/nj59+pz1Ne+//z5DhgzhiSeeAODFF18kISGBjz76iH/961+VXvPFMOpdASYznNwPWUchpE6559VzIyIiUnmq1JibrKwsAMLDw895zMqVKxkwYEC5fYMHD2blypWVWluF+AZDrG2dqbP13mjMjYiISOVxac/NH1mtViZMmEDPnj1p3br1OY9LSUkhOjq63L7o6GhSUlLOenxRURFFRad7SLKzswGwWCxYLBYHVH5a2fksFgvm+j3wOLYR6/4llMZfV+64MH/bx56WU+jwGpzhj+10VzWhjaB2uhu1033UhDZCxdpZkc+iyoSbcePGsW3bNpYvP/v8MJfq1VdfZdKkSWfsnzdvHv7+/g59rzIJCQlEZ/lwBZC/M4EFpvIDng+eNAEe7DuaWuUGQ1dEQkKCq0uodDWhjaB2uhu1033UhDbCxbUzPz//os9XJcLN+PHjmTlzJkuXLqVu3brnPTYmJobjx4+X23f8+HFiYmLOevxTTz3FY489Zn+cnZ1NvXr1GDRoEMHBwZdf/B9YLBYSEhIYOHAgXqW9MN55j8Ci41zdqz0E17YfF5uUyWeJayj19OPqq88+tqgqK9dOLy9Xl1MpakIbQe10N2qn+6gJbYSKtbPsysvFcGm4MQyDhx9+mBkzZrB48WIaNWp0wdd0796dBQsWMGHCBPu+hIQEunfvftbjfXx88PHxOWO/l5dXpf2D8fLywsvf3zbu5thGvI6uhoib7M9Hh9p6jE7kWar1P9rK/AyriprQRlA73Y3a6T5qQhvh4tpZkc/BpQOKx40bx9dff820adMICgoiJSWFlJQUCgoK7MfceeedPPXUU/bHjzzyCHPmzOHtt99m165dTJw4kXXr1jF+/HhXNOH8Gvay/fzTfDdld0sVWErJLy5xdlUiIiJuzaXhZvLkyWRlZdG3b19iY2Pt23fffWc/JikpieTkZPvjHj16MG3aND799FPatWvHjz/+yM8//3zeQcgu07C37eef1pny9/bA18v20euOKREREcdy+WWpC1m8ePEZ+2688UZuvPHGSqjIweqffb4bk8lERIAPRzMLSMstol545QxsFhERqYmq1Dw3bsc35Jzz3URqlmIREZFKoXBT2S4w7iY1p9DZFYmIiLg1hZvKdo5xN02jAwFYdzDD2RWJiIi4NYWbyvbncTenXNU8CoBFiamUlFpdVZ2IiIjbUbipbOcYd9OpQRghfl5k5lvYeDjTNbWJiIi4IYUbZ7CPuzl9acrTw0zf5rUAWLAz1RVViYiIuCWFG2docGa4Aegfb1sAdMHO439+hYiIiFwihRtnsI+72QfZx+y7r4yrhYfZxJ7UXJJOXPyCYCIiInJuCjfO4BcKMW1tvx88Pe4mxN+Lzg3CAFiwS703IiIijqBw4yznmO9mwKlLUwt3adyNiIiIIyjcOMs55ru5Kt52S/iq/SfILdIimiIiIpdL4cZZzjHupkmtQBpFBmApNVi2O82FBYqIiLgHhRtnOce4G4CrWth6bxbo0pSIiMhlU7hxpnOMu+l/Ktws2pWK1XrhldJFRETk3BRunOkc4266NAonyMeTE3nFbDqS6fy6RERE3IjCjTOdY9yNl4eZPqdmK16o2YpFREQui8KNM51n3M2AU3dNzddsxSIiIpdF4cbZzjHu5spmUZhNsCslh6OZBS4oTERExD0o3DjbOcbdhAd407G+bbZiTegnIiJy6RRunO0c425AC2mKiIg4gsKNs51n3E3/U+NuVuw7QX6xZisWERG5FAo3rlA27uZQ+UtTcVGB1A3zo7jEyvI96S4oTEREpPpTuHGFc4y7MZlMWkhTRETkMincuELZuJsTeyE7udxTZUsxLNRsxSIiIpdE4cYV/jju5sCSck91axxOgLcHqTlFbDuW5fzaREREqrlLCjeHDx/myJEj9sdr1qxhwoQJfPrppw4rzO3FDbL93Pxtud0+nh70jrPNVrxAsxWLiIhU2CWFm9tuu41FixYBkJKSwsCBA1mzZg1PP/00L7zwgkMLdFsdbgdMsH8xnNxf7qmr4k9fmhIREZGKuaRws23bNrp27QrA999/T+vWrVmxYgXffPMNU6dOdWR97iusATS5yvb7hq/KPdWveRQmE2w9msXx7EIXFCciIlJ9XVK4sVgs+Pj4ADB//nyuvfZaAFq0aEFycvL5Xip/1Gms7efGr6HUYt9dK8iHdnVDAfXeiIiIVNQlhZtWrVrxr3/9i2XLlpGQkMCQIUMAOHbsGBEREQ4t0K01HwoBUZCXCom/lXuqbCFNzVYsIiJSMZcUbl5//XU++eQT+vbty6233kq7du0A+PXXX+2Xq+QieHidGnsDrJ9a7qmrWtjmu1m+N51CS6mTCxMREam+PC/lRX379iU9PZ3s7GzCwsLs+++//378/f0dVlyN0PEOWP4O7FsIGYdsY3GA+Nggaof4ciyrkJX7TtDv1Pw3IiIicn6X1HNTUFBAUVGRPdgcOnSI9957j8TERKKi9Ee4QsIbQ+O+gAEbTw8sNplM9rum5uvSlIiIyEW7pHAzYsQIvvzySwAyMzPp1q0bb7/9NiNHjmTy5MkOLbBGKBtYvOErKD29YGb/FqeXYjAMzVYsIiJyMS4p3GzYsIHevW3rI/34449ER0dz6NAhvvzySz744AOHFlgjNB8G/pGQmwJ75tp3d28SgZ+XB8lZhexIznZhgSIiItXHJYWb/Px8goKCAJg3bx6jRo3CbDZzxRVXcOjQIYcWWCN4ekP722y//2Fgsa+XBz2bRgKwULMVi4iIXJRLCjdNmzbl559/5vDhw8ydO5dBg2xLCaSmphIcHOzQAmuMjmNsP/fOh8zD9t39y24J13w3IiIiF+WSws1zzz3H448/TsOGDenatSvdu3cHbL04HTp0cGiBNUZkU2jYGwyrbVK/U8pWCd98JJO0nCJXVSciIlJtXFK4ueGGG0hKSmLdunXMnXt6jEj//v159913HVZcjWOfsfj0wOLoYF/a1AnBMGBRonpvRERELuSSwg1ATEwMHTp04NixY/YVwrt27UqLFi0cVlyNEz8c/MIh+6jt8tQpZZemNO5GRETkwi4p3FitVl544QVCQkJo0KABDRo0IDQ0lBdffBGr1eroGmsOT5/TA4s3/Me+235LeGIq245muaIyERGRauOSws3TTz/NRx99xGuvvcbGjRvZuHEjr7zyCh9++CHPPvuso2usWcoGFu+eA9nHAGhdJ5grm9WiuMTKPf9ZS0qWVgoXERE5l0sKN//5z3/47LPPePDBB2nbti1t27bloYce4t///jdTp051cIk1TK1m0KBnuYHFJpOJD2/rQFxUIMezi7j3y7XkF5dc4EQiIiI10yWFm5MnT551bE2LFi04efLkZRdV49lnLP4SrLZFM4N9vfh8TBfCA7zZdjSbx77bjNWqWYtFRET+7JLCTbt27fjoo4/O2P/RRx/Rtm3byy6qxou/FnxDIesw7Ftk310/wp9P7+iEt4eZOdtTeHNeoutqFBERqaIuaVXwN954g2HDhjF//nz7HDcrV67k8OHDzJ4926EF1khevtDuVlg9GdZPgbgB9qc6Nwzn9Rva8Oh3m5m8eB+NIwO4sXM9FxYrIiJStVxSz82VV17J7t27ue6668jMzCQzM5NRo0axfft2vvrqqwufQC6s06mBxYm/QU5Kuaeu61CXh69qCsA/Zmxl9f4Tzq5ORESkyrrkeW5q167Nyy+/zH//+1/++9//8tJLL5GRkcHnn3/uyPpqrqh4qHcFGKXlZiwu8+iAZgxrE4ul1OD/vl7PwfQ8FxQpIiJS9VxyuBEnKDewuPz8QWazibdubEe7uiFk5lu4+z9rycq3OL9GERGRKkbhpiprOQJ8QiDzEBxYfMbTft4e/PvOztQO8WV/Wh4PTVuPpVSTKIqISM2mcFOVeftDu5ttv6+fetZDooJ9+WxMF/y9Pfh97wme+2U7hqFbxEVEpOaq0N1So0aNOu/zmZmZl1OLnE2nsbDmU9g1C3JTITDqjENa1g7mg1s6cN9X6/h2TRJNowK5p1cj59cqIiJSBVSo5yYkJOS8W4MGDbjzzjsrq9aaKboV1O0C1hLY9M05DxvQMpqnr44H4KVZO1iw87izKhQREalSKtRzM2XKlMqqQ86n01g4shbWfAZtb4Hg2LMedk+vRuxLy+XbNYf5y7cbmX5/d9rUDXFurSIiIi6mMTfVQavrILguZB+BLwbBiX1nPcxkMvHCiNb0aBJBXnEpN3+6kkW7Up1crIiIiGsp3FQH3gFw1ywIbwyZSfDFYDi26ayHenmY+dcdnejVNJL84lLu+c9avlp50KnlioiIuJLCTXUR1hDungsxbSEvDaZeAweWnvXQYF8vptzVhZs618VqwLO/bOelmTu00KaIiNQICjfVSWAUjJ0JDXpBcQ58fT3s/N9ZD/XyMPP69W15YnBzAD5bfoAHv1lPQXGpMysWERFxOoWb6sY3BG7/L7S4BkqL4fs7Yf1/znqoyWRiXL+mvH9Le7w9zMzdfpxb/r2KtJwiJxctIiLiPAo31ZGXL9z4H+hwBxhW+N9fYNnbcI7J+0a0r8M393Uj1N+LzYczue7j39mbmuPkokVERJxD4aa68vCEaz+EXo/aHi94AeY+fcYaVGW6NAxnxkM9aRjhz5GMAkZ9vIIV+9KdWLCIiIhzKNxUZyYTDJgIg162PV71T/j5QSg9+wKajSID+OmhnnRuEEZ2YQl3fr6GH9cfcV69IiIiTqBw4w56jIeR/wKTB2yZDtNHQ3H+WQ8ND/Dm63u7MbxdbUqsBo//sJl3EnZrPSoREXEbCjfuov2tcMs08PSFPXPhq5GQk3LWQ329PHj/5vY81LcJAB8s2MOj322i0KI7qUREpPpTuHEnzYfAHT/b7qg6vBrebwe//f2sIcdsNvHkkBa8NqoNHmYTP286xg3/WsGRjLP3+IiIiFQXCjfupkF3uGuObbHNkkJYPRneawuzn4TsY2ccfkvX+nx1d1fCA7zZdjSbaz/6nRV7NdBYRESqL4UbdxTdEu5JgNt/gnrdoLQI1nwC77eHWY9D1tFyh/doGsmv43vSpk4IJ/OKuf3z1Xy6dJ/G4YiISLWkcOOuTCZo2t+2ZMOdv0D9HraQs/bf8EF7mPkYZB62H143zJ8fHujODZ1sSza8MnsXD3+7kfziEte1QURE5BIo3Lg7kwka94W7ZsOY/9mWbigthnWfwwcd4H8TbItxYhto/OYNbXlxRCs8zSZmbklm1McrOHQiz6VNEBERqQiFm5rCZIJGfWyri4+ZCQ17g9UC66fYQs7sJ6CkGJPJxB3dG/Lt/VdQK8iHXSk5DP9wOYsSU13dAhERkYuicFMTNeptW4Bz7GxodCVYS2DNp7Z1qkps6051aRjOzId70bF+KNmFJdw9dS0fLtijlcVFRKTKc2m4Wbp0KcOHD6d27dqYTCZ+/vnn8x6/ePFiTCbTGVtKytnnc5ELaNgTxvwKt063zY+z+zeYfhtYCgCIDvZl+v3dGd2tPoYBbyfs5v++Xk9OocbhiIhI1eXScJOXl0e7du345z//WaHXJSYmkpycbN+ioqIqqcIaovlQuO078PSDvfNh2s1QbBtn4+1p5uXr2vDG9W3x9jCTsOM4N3yyiqMahiMiIlWUpyvffOjQoQwdOrTCr4uKiiI0NNTxBdVkjfvC7f+FaTfBgSXwzY22wOMTBMBNXerRPCaIB75ez/70fN5K9yA9MJHHBrcg0Mel/4xERETKqZZ/ldq3b09RURGtW7dm4sSJ9OzZ85zHFhUVUVRUZH+cnZ0NgMViwWI5+wKTl6rsfI4+r9PU6Yrp1h/wmH4TpkO/Y/3yOkpv+Q58gwFoGRPAjAe68dyvO5i3M40vVhxi1tYU/j6kGcPaxGAymVzcAMep9t/lRVI73Yva6T5qQhuhYu2syGdhMqrITG0mk4kZM2YwcuTIcx6TmJjI4sWL6dy5M0VFRXz22Wd89dVXrF69mo4dO571NRMnTmTSpEln7J82bRr+/v6OKt+thObvp/veN/EuzSPDvxErmzyBxTOw3DE7M0z8eNBMeqEt0MQFW7mxsZVoP1dULCIi7i4/P5/bbruNrKwsgoODz3tstQo3Z3PllVdSv359vvrqq7M+f7aem3r16pGenn7BD6eiLBYLCQkJDBw4EC8vL4ee2+lStuL57Q2Y8k9gRLeh5LYfwT8CON3OPv2uYuqqo/xr6QGKSqx4eZi4u0dDHurbCH/vatkpaOdW3+V5qJ3uRe10HzWhjVCxdmZnZxMZGXlR4aZ6/wUCunbtyvLly8/5vI+PDz4+Pmfs9/LyqrR/MJV5bqep19E2H86XIzAd34rX1yNtd1YFnh68Hejny6ODWnB9p/pM+t92FuxK5ZNlB5i5NYVnr2nJ4FbR1f5SlVt8lxdB7XQvaqf7qAlthItrZ0U+h2o/z82mTZuIjY11dRnuKboljJ0FgTGQthOmDoPs5DMOqx/hz+dju/DvOztTJ9SPo5kFPPD1eu6aupaD6bqtSkREnMul4SY3N5dNmzaxadMmAA4cOMCmTZtISrItB/DUU09x55132o9/7733+OWXX9i7dy/btm1jwoQJLFy4kHHjxrmi/JqhVjPb0g3BdSF9N0y9GrKPnvXQgS2jmf/YlYzv1xRvDzOLE9MY9N5S3knYTaGl1MmFi4hITeXSy1Lr1q2jX79+9sePPfYYAGPGjGHq1KkkJyfbgw5AcXExf/3rXzl69Cj+/v60bduW+fPnlzuHVIKIJraA85/hcHI/nl8OJ86/K+bFm8BaDJZ8sBSCJR+/kkIet+Qzvl4ex09kUFJUwPGlYdy/cTwP3TCEKxpHuLo1IiLi5lwabvr27cv5xjNPnTq13OMnn3ySJ598spKrkrMKa3Aq4FyL6eQ+WmYlwZlXqOx8gQYAZmhCMvF5T3Lvv4/TrMsA/j40nhA/97+GLCIirlHtBxSLE4XUhbtmU7r8PY7s3UHdRs3w8PEHL3/b8g1e/uDl+4fHfuDhRcm85wlL3sA071d4ZF0WA3b2ZuLwVlztZnPjiIhI1aBwIxUTFIN1wItsKp5N7cFX43ERo9c975oJ/70Xn8TZfOz9Pi/npzNuWhED4qN4YURraodqchwREXGcan+3lFQD3gFw89fQ5T7MGDzr9TUTvb5k4c4UBr6zhP+sOEipVhsXEREHUbgR5zB7wNVvwsAXARjrMYdpIR9TUlzA879u54Z/rSAxJcfFRYqIiDtQuBHnMZmg51/ghi/Aw5srilawPPod6vnkszEpk2EfLOOtuYm6bVxERC6Lwo04X+vr4c5fwDeUWllbWBT2Mrc1LaHEavDRor3c9MlKTuQWXfg8IiIiZ6FwI67RoAfcMw9C6+OZeYCXTz7Kt0PMhPl7seVIFjd+spKjmQWurlJERKohhRtxnVrN4Z75ENseU/4Jui8fy+xBWdQO8WV/Wh7Xf7yCPcc1DkdERCpG4UZcKyjatn5V3GAoKSR2zn0kNP2R+8PWY8o+yo2frGRDUoarqxQRkWpE89yI6/kEwi3TYPbjsH4KAdun8Q/gH75wpDSSDZ/FE3jFYJp1GQSRzWwDk0VERM5B4UaqBg9PuOZdaHEN7FsISSswkrdQl3TqmpbBmmWw5hnwj4D63W1jdup3h5i2tteKiIicor8KUnWYTBA3wLYBpqIcLIfWMH/ODELT1tPBvAff/BOwa6ZtAwiMhjtmQHQrFxYuIiJVicbcSNXlE4RXs/4MGv8hszv9mzZFnzOqaCLLGj6M0Www+IZA7nGY/QScZwFWERGpWRRupMrzMJt4YUQrHuofzwajGXfs6s7EgOew/t/vtgU6D/0Ou2a5ukwREakiFG6kWjCZTDw6sBmTrm2FyQT/WXmIR+akU9rtIdsBCc9BSbFrixQRkSpB4UaqlTE9GvLeze3xNJv43+ZjPHjoSqz+teDkPlg/xdXliYhIFaBwI9XOiPZ1+GxMZ/y8PJi3N493LKNsTyx+DQoyXVqbiIi4nsKNVEt9m0cx/f4rqBvmx+ScXuy21oGCk1iXvuXq0kRExMUUbqTaalcvlNmP9GZYu3q8UnIbAKUr/8XxQ7tcXJmIiLiSwo1Ua8G+Xrx/S3uGjxrDCqMNXljYNGUCc7Ylu7o0ERFxEYUbqfZMJhPXd65Hg1vfwYqJwazk02+m89RPW8gvLnF1eSIi4mQKN+I26rToitFuNABPe33Dt2uSGP7hcrYfy3JxZSIi4kwKN+JWPPo/A17+dDLv4daADexLy+O6f67g8+UHMDSLsYhIjaBwI+4lOBZ6/AWAlwJ/ZEiLMIpLrbw4cwd3TV1LWk6RiwsUEZHKpnAj7qfnXyAwBo+sQ0yOW8eLI1vj42lmcWIaQ99fxrI9aa6uUEREKpHCjbgf7wC46hkATMve4o62Qfw6vhfNo4NIzy3izi/W8MacXZSUWl1cqIiIVAaFG3FP7W+D6NZQmAVL3qB5TBC/jO/Jbd3qYxjw8eJ93PzpKo5mFri6UhERcTCFG3FPZg8Y9JLt97X/hhP78PXy4JXr2vDP2zoS5OPJ+kMZXP3+MuZuT3FtrSIi4lAKN+K+mvSDpgPBWmJbNfyUYW1jmfWX3rSrG0JWgYX/+2o9E3/dTqGl1IXFioiIoyjciHsb9CKYzLBrJhz83b67foQ/PzzQg/v7NAZg6oqDjPp4BYcO7IYdv2Je+AKdDn4M6XtcVbmIiFwiT1cXIFKpouKh4xhYPwXmPQP3LgCzLdN7l+TyjxbHublwPYe2LKPlyT3E/CcDAA+gLmBMux7umQeh9VzXBhERqRCFG3F//f4BW3+AYxvgtyehOA+Orof03YBBE6AJgAlKDDOJRj2ywtvSumAdwTnH4OtRcNccCIhwbTtEROSiKNyI+wuMgl6PwsIXbYOL/yi0AdTpBHU6UVq7E5/uDuStRUlYU6C170B+9H8V3/TdMO1GuPNX8Al0TRtEROSiKdxIzdB9HBzfBoXZULezLdDU7giBteyHeAAPNYROTWvzl+kb2ZYdybCix/jF7wUCj66H7++AW78DT2+XNUNERC5MA4qlZvDygxunwh0/2S5TNRtcLtj8UbfGEfxvXHd6RVs5ZKrL7QVPkG/4wL6FFPxwP1g1+Z+ISFWmcCNyFmH+3tzY2Mrsh3tQu3UvHrBMwGJ44Jc4g3Wf/B9Z+cWuLlFERM5B4UbkPBpFBvDx6E48+sCDfBz2OACdj3/PV28+zGfL9lNUorlxRESqGoUbkYvQoX4Yf3nkKRI72NasGm9MZ9+cj7jqrSXM2HgEq9VwcYUiIlJG4UbkIplMJpqPeAJrL1sPzkteU2idvYRHv9vMNR8uZ+lurTYuIlIVKNyIVJC5/zPQcQweWPnY559c5bOLHcnZ3PnFGu78Yg27UrJdXaKISI2mcCNSUSYTXPMuxA/Hw7Dwuc87/KNDMV4eJpbuTuPq95fxtx+3cDy70NWViojUSAo3IpfC7AGjPoOGvTEV53J/0hMsvrs+w9rEYjXgu3WH6fvmYt5N2E1eUYmrqz23k/upnbEGDI0ZEhH3oXAjcqm8fOGWbyCmDeSlUWf6QP5peY6VXZdzX3QivpYM3l+wh35vLea7tUmUVrVBx0fX4zllIF0OfoRp2w+urkZExGE0Q7HI5fANgdt/gi9HQOoOOLiMWJbxNPC0LxwxxbK6sAkbf45jyZJ23HzNEK5sEevqquHIevjqOkxFWQB4LH8b2t9i65ESEanmFG5ELldgFDywHNIS4cgaOLwWjqyF9ETqGsnU9Ujmeo/lkAt53/qww7cFUS17E9n9dtuq5c52eK1tMdCibKx1u1GSvA3vk/tg23+h7U3Or0dExMEUbkQcwewB0S1tW6extn0FGbYekiNrsBxaTenhtQSU5tGyaDNs3AwbPyKrdm+C+03A1LS/baByZTu8Br4aBcU50KAnpTd9w76vHyc++UdY8ga0vl69NyJS7SnciFQWvzCIGwBxA/ACvKxWkvduZuGCmUQcW8JA8zpCji2Db5aRHdQE/z5/wbP9zbZ1sCpD0ir4+noozoWGveG278Dkzf5aA2mRMR/TiT2wfQa0uaFy3l9ExEk0oFjEWcxmYpt1YPSDz9Jo3Azejp/OVOtQcg1fgnP24TnrEfLfiKdg7ouQm+rY9z604lSPTS406gO3fQ/eAQCUePhh7fqA7bglb2hhUBGp9hRuRFygeUwQT94yhGv/9iXf9prDe+YxHDEi8bdk4LfyLUrebknm9Pvh+I7Lf7ODy+HrG8CSB437wq3fgbd/uUOsXe63DY5OT4QdP1/+e4qIuJDCjYgLhQd4c9/ADjz0j/dYf+1CXgv8OxutTfE0LITu+g4md+fk5Kux7pwFloKKv8GBZfDNjbZg0+QquHX6GcEGAN9guOIh2+/qvRGRak7hRqQK8PY0M6JTA/72179TencCb9b9kNmlXSk1TIQf/x3zd7dheaU+6Z9cS/GKTyDj4IVPun/xqWCTD00HwC3fnn88T7cHwCcE0nbCzl8d1TQREadTuBGpQkwmE50bhvPEvXfS9rFf+Ff7//IfruGoEYGXUUxk8hK85z0J77cj4432ZMx4EmP/YigpLn+ifYtg2s1QUgBxg+Dmb2yTDp6PXyhcobE3IlL96W4pkSqqbpg/467rT/6wK1m+O40ft6zBc/98OhevoZNpN2H5B2DzJ7D5E4rMfmTG9iK07TB8AkLg5wehpBCaDYGbvgRPn4t70ysehFWTIXU77JoJLa+t3EaKiFQChRuRKs7f25NBrWMZ1HoEhnEt+9JymbZtP5nb5lEnfRl9TBupZc0m+mgCHE2wv64kbgieFQk2YLt9vdv/wdI3bb03La4Bszp4RaR6UbgRqUZMJhNNo4JoelU7uKodeUWPsmpfGrs3Lcf7wHw6Fq2jnWkfv1m78PTuOxk+cw+3datPfGzwxb/JFQ/Bqn/B8a2QOBvir6m8BomIVAKFG5FqLMDHk/4tY+nf8kYM4wYOpOfx+dYkvlmXQubJAr5adYivVh2iU4MwRnerz9VtYvH1usAMxP7h0O1+WPY2LHkdWgxzzuzJIiIOov5mETdhMploXCuQ+65qycLH+/HNvd24uk0MnmYT6w9l8Nj3m+n2ygJenLmDfWm55z9Z9/HgHQgpW2D3HOc0QETEQdRzI+KGzGYTPZtG0rNpJKk5hfyw7gjTVidxNLOAz5cf4PPlB+jeOIKbO9eh9Gw3RfmHQ9f7YPm7sPg128Bk9d6ISDWhcCPi5qKCfBnXrykPXNmEpbvT+GZ1Egt3HWfl/hOs3H8Cfw8PZmZuoHPDCDo1CKNd3VD8vD1svTerP4HkTbBnHjQb7OqmiIhcFIUbkRrCw2yiX4so+rWI4lhmAdPXHua7NUkczyliUWI6ixLT7ce1jA22jdNpcAtxe7/AWPwaprhB6r0RkWpB4UakBqod6sdjA5vxYO8GfPrjHPzqtWLzkWzWH8ogJbuQrUez2Ho0i//RhWU+3+B/bAMffToZ35ZD6NYogla1gzGbFXREpGpSuBGpwTw9zDQMgqt7NMDLywuAY5kFrD+UwYakDDYcymDa8QHc6zGLnkc/57oD9QETYf5e9GwaSe+4SHrF1aJO6HmWdRARcTKFGxEpp3aoH7VD/RjerjYAhRlNKP1oAR3YyyMNkvgipQkZ+RZmbklm5pZkABrXCqB300h6x9XiiiYRBPpU8P9aco7D0fUQ1gCiWzm6SSJSwyjciMh5+YbFQpd7YNU/edRrBuOfncPmI1ks25POsj1pbD6Sxf60PPan5fGflYfwNJvoWD+MXnG2np22dUPx+OMlrFILHN8Gh9fCkTVweDVkJtme8/CGm7/W4GURuSwKNyJyYT0fgXWfw5E1eO2ZTef6PegcW5tHr2pEVpHByv0nWb43jWV70jl0Ip81B0+y5uBJ3knYTWO/fG6tfZw+/gdoXLADr+ObbCuVl2OCwCjIPQ7TR8NN/7FNHigicgkUbkTkwoKiodNdsHoyfHd7uadCMDHE04chHj7g6U1JpBf5Vk9ySjywFudTzzgOR8ufrsgjkKKYTgQ27YG5fleo0wm8/OG/98KOn+H7O+H6z6HVSKc1UUTch8KNiFycXo/C3gQ4eQCM0j88YdhWIC8phCLb/6kEn9rKpPs1Yl1pHAvzGrDBGsc+ozbGPjMRKd70aRZO35xc+sT5EXb95+DhBVt/gB/vtr1P6+ud205LARxZC5jANxh8gsAnxPa7h5dzaxGRS6JwIyIXJygaHl5v+91aCiVFUFoEJcW2YFNaXH5faRGYzBDThki/MIYAHbILWZKYxqLEVJbvSedEXjEzNh5lxsajmE3QoX4YA1s8yW3NDYITf7T15JSWQLubK7dtxXmwJwF2/AK754Il7+zHefqCz6nAYw8+wbb9f2z3GT+LTn8+RinED4chr4NPYOW2S6SGUrgRkYoze4C3P+BfoZdFB/tyU5d63NSlHpZSK+sPZbA4MY3FiansSslh/aEM1h/K4HVG8lFgJsNK5mPM+D+sJcV4dLrDsW0ozLbNvLzjZ9gzH0oKTj8XFGsLLoXZUJRzOuyU9VDlpV7ee2/8Go6sg5u+hFrNL+9cInIGhRsRcQkvDzNXNI7gisYR/H1oC5KzCliwM5WEHcdZue8E43PHkuFpcLvnAjz+N57v1x4kqOe99G5Wq+K3mpcpzILtCbDzV9i7wNarUiasIcRfCy1HQp2O5WdjLi2B4pzTYafo1M/CbNvvJUXg6Q0ePuDpY7vry9PHdhnrz/uyjsAv4yFtF3zaD679ANrccDkfpYj8icKNiFQJsSF+3H5FA26/ogG5RSUs251Gwva6mHd5cxu/cVPKWzwz/QSPMJjuTSIY0DKaPnGR1A/3x3S+ZSFyUjDtnM0V+6bgufkesFpOPxfRFFqOsG0xbc+9vISHJ/iF2bbLFRUP/7cU/nsPHFxm+3l4NQx62RaQROSyuTTcLF26lDfffJP169eTnJzMjBkzGDly5Hlfs3jxYh577DG2b99OvXr1eOaZZxg7dqxT6hUR5wj08WRom1iGtomlpOQbkn96gtgdn/OS1xS8LCVM2T2UJbvTAKgT6kePJhH0aBpBjyaRRAf5QPJm29iZ3b/BsY14AtFlJ68VfzrQRMW7Zr2soGi442dY9DIsfwfWfApHN8CNUyG0nvPrEXEzLg03eXl5tGvXjrvvvptRo0Zd8PgDBw4wbNgwHnjgAb755hsWLFjAvffeS2xsLIMHa9IvEXfk6elB7I1vw/wg+P09nvf6ioHNw3k3fwgbkzI5mlnA/9bv4+TGXygwb2SQ1yYijZPlzmGt3ZFEoxFNr/0rXrFVZAZkD08Y8DzU6wYz7oej6+CT3jDqM4gb4OrqRKo1l4aboUOHMnTo0Is+/l//+heNGjXi7bffBiA+Pp7ly5fz7rvvKtyIuDOTCQZMtI1bWfoGPfa/T48r/ShqX4vcLTMJTl6Bl3Fq/IwBeYYPy6xtWWjtwLGo3jSPbYz3yf08HNaUKnczd/MhtstU399p63H65ga48km48m+2gdsiUmHVaszNypUrGTCg/H/RDB48mAkTJpzzNUVFRRQVnR40mJ2dDYDFYsFisZzrZZek7HyOPm9VUxPaWRPaCNWwnb2fxIwZj6WvwZLX8AF8Tj1lBNelsNFAtgRcwZycJiw7mMfetDxIhuXJhwAPpr2+mIHx0QxtHU33xuF4eZhd2Jg/CKwDd87CnPAMHhumwpLXsSatpnTEvyAg8qJPU+2+z0tUE9pZE9oIFWtnRT4Lk2EYxiVX5UAmk+mCY26aNWvGXXfdxVNPPWXfN3v2bIYNG0Z+fj5+fmeuTDxx4kQmTZp0xv5p06bh71+x21hFpGpoenwWLZJ/Isu/ASnBHUgJaU+Ob90zxs9kFcOeLBO7s0xszzSRazn9vL+HQZtwg/YRBs1CDDyrSM6pe/J32h2egqe1mAKvMNY2HE9GYJyryxJxufz8fG677TaysrIIDg4+77HVqufmUjz11FM89thj9sfZ2dnUq1ePQYMGXfDDqSiLxUJCQgIDBw7Ey6vKdX47TE1oZ01oI1Tndl6NlX8SBAQBF/rTb7FYmDsvgdC4ziQkpjN3eyon8opZnWZidRoE+3rSPz6Koa2i6dkkAm+XJp2rMVJvx/jpLvxO7KX3vlexDngRa+d7Lzj4ufp+nxVTE9pZE9oIFWtn2ZWXi1Gtwk1MTAzHjx8vt+/48eMEBweftdcGwMfHBx8fnzP2e3l5Vdo/mMo8d1VSE9pZE9oINaOdZhP0ahZFv1Z1eHGkwZoDJ5m9NZnftqWQnlvEjI3HmLHxGEG+ngyMj6ZdvVAaRPjTICKAumF+zr2EVact3L8YfhmPacfPeMx7Co/kjTD8PfAOuODLa8L3CTWjnTWhjXBx7azI51Ctwk337t2ZPXt2uX0JCQl0797dRRWJSHXkYTbRvUkE3ZtEMPHaVqw7eDropOYU8dPGo/y08Wi542uH+tIwIsAWeMID7MGnfrg/ft6VMPDXJ8h2a/iqj2Hes7D1ezi+HW7+CiKaOP79RNyIS8NNbm4ue/futT8+cOAAmzZtIjw8nPr16/PUU09x9OhRvvzySwAeeOABPvroI5588knuvvtuFi5cyPfff8+sWbNc1QQRqeY8zCa6NY6gW+MInh/einWHMli4K5X9abkcOpHPoZN5FFqsHD5ZwOGTBSzbc+Y56of706dZJP2aR9GjSaTjwo7JBN3HQWw7+GEspG63zWo86lPbXVYiclYuDTfr1q2jX79+9sdlY2PGjBnD1KlTSU5OJikpyf58o0aNmDVrFo8++ijvv/8+devW5bPPPtNt4CLiEGazia6NwunaKNy+zzAMUnOKOJiex6GT+Rw6kWcLPSfyOXgij5zCEpJO5vP1qiS+XpWEt6eZ7o0juKpFFP2aR1E/wgE3LjTsdep28TFwZA18ezP0eRL6/l23i4uchUvDTd++fTnfzVpTp04962s2btxYiVWJiJxmMpmIDvYlOtiXbo0jyj1nGAYZ+RY2JmWwKDGVRbvSOJpZwJLdaSzZncbzbKdJrQD6NY/iqhZRdG4YfumDlYNrw9hZMPcfsPbfsPQNOLYBRv0b/MMv/HqRGqRajbkREalKTCYT4QHe9I+Ppn98NIZhsCc1l4W7Ulm0K5V1hzLYl5bHvrQDfLb8AAHeHvSKi6R/i2j6tqhFVJBvxd7Q0xuGvQV1O8P/JsDe+fBpX9s4nNh2ldFEkWpJ4UZExEFMJhPNooNoFh3EA1c2IavAwvI96SxKTGVxYirpucXM3X6cudttd322rRvCVS1svTqta4dgNl/kOlftboHoVvDd7ZBxED4fBNe8C61urLzGiVQjCjciIpUkxM+LYW1jGdY2FqvVYNuxLHuvzuYjWWw5tb03fw+1gny4qnkU/VpE0SsukkCfC/zfc0wb2+3iP90Pe+bBzw9iTlqDydrbKW0TqcoUbkREnMBsNtG2biht64YyYUAzUnMKWbwrjYW7Ulm2J420nCK+W3eY79YdxtvDTLfG4VzVIor+LaLPPSjZLwxu/c42/mbxa3hsmMJVPr9hrnUUOt6usThSYynciIi4QFSQLzd1qcdNXepRVFLKmgMnWbgrlYW7Ujl0Ip9le9JZtiedSf/bQdOoQPrHRzEgPpqO9cPw+OPlK7PZdtdU7Y4YM+4nsCAF5j8Li16CliOg811Qv/sFZzcWcScKNyIiLubj6UHvuFr0jqvFc9e0ZH96Hgt32oLOmoMn2Zuay97UXD5Zsp9Qfy/6NY+if3wUfZrVItj31KytzQZRMm4D27+bRLvi9ZiOb7VN/Lf1e4hsDp3G2sbqVKQ3p6QIUnfAsU2QsgW8/G2BqU5nW6gSqaIUbkREqhCTyUSTWoE0qRXIfX0ak1VgYcnuNBbuPM6ixDQy8y3M2HiUGRuP4nlqXp7+8dEMiI+idnAQhyKvotXQN/FK2wrrp8LWHyE9EeY+BQsmQcuRtt6cet3K9+ZYCm2TBB7bBMmbbD9Td4L1Tysxr/wIgutCq5HQ6jqo00m9QlLlKNyIiFRhIX5eXNuuNte2q01JqZX1hzJYsCuVBTuPsy8tjxX7TrBi3wlenLmDJrUCaOBpJuzASa5o0gHvazvBoJdtvTfrpsLxrbBlum2rFW8LKFlHbGEmdSdYS84swC8MYtvbbjXPPgaJsyH7iC3krPwIQuqfDjq1OyjoSJWgcCMiUk14epjtS0X84+p4DqbnMX/ncRbsTGXtwZO2OXUws3DKevy9PejRJJK+zWvRt/lt1O18DxxdD+umwLb/QtpOWLyz/Bv4hUPt9rYwU/YztP6fengKYO8C2D4DEn+DrCRY8YFtC2toCzmtroOYtgo64jIKNyIi1VTDyADu7d2Ye3vbLl8t2pnCtEWb2F/gS3puMfN3Hmf+TtucOk2jAunbrBZ9W02iy4CX8NnxIxz6HcIbnw4zIfUuHEi8/CD+GttWnA97E2xBZ/dc25w7y9+1bWENIbSBbQFQn2DwCbT97n3q5x8370DbewfWquRPTGoKhRsRETcQ4ufFsDYxmA5bGTLkSvakF7A4MZXFiWlsSMqwD0r+bPkB/Lw86NGkPX2bD6R7kwia1ArEdCm9LN6nBhi3HAHFebaAs32Gbd6djIO27aKZbHd1tR5lO19gVMXrETlF4UZExM2YzSZa1wmhdZ0Qxl8VR1a+hWV701iSaFvzKjWnyDZuZ1cqABEB3nRtFE63RuF0axxB8+igi58tuYx3gC2YtB4FRbmQtBIKMqAo2/a4KMe2FeeW31ecC4XZkHMMklbYtt+ehAY9beeKvxYCIivhUxJ3pnAjIuLmQvy9uKZtba5pWxvDMNiRnM3ixDSW70lnQ1IGJ/KK+W1bCr9tSwEg1N+LLg1PhZ1GEbSsHVx+bp0L8QmEuIEVKzLrCGz/2dbzc3QdHFxm22Y9Do362MbxxA/XxIRyURRuRERqEJPJRKvaIbSqHcK4fk0pKilly5Es1hw4yar9J1h/KIPMfAsJO46TsMM2XifIx5PODcPoHVeLa9rFVnzBz4sRUhd6jLdtGYdgx8+w7SfbnVz7F9m2WY9B436YWlyLZ6m342sQt6FwIyJSg/l4etClYThdGoYzrl9TLKVWth/LZvX+E6w+cJK1B06SU1TCosQ0FiWm8fLsnfRqGsmojnUY1DIGP28PxxcV1gB6PmLbTu639eZsnwEpW2FvAp57Exjo4Y85cCd0fwiCoh1fg1RrCjciImLn5WGmfb1Q2tcL5f+ubEKp1WBncjar9p9g5pZkNh3OZMlu29idAG8PhrSO5boOdejeJKJil64uVnhj6P1X25a+B7b/jLH5W7xP7oMV78Hqj20zL3d/GGo1c/z7S7WkcCMiIufk8YfByff2bsz+tFx+3nSMGRuPcPhkAf/dcIT/bjhCTLAvI9rX5rqOdWgRE1w5xUTGwZVPUNL9L2z49mW6WFZhPrIaNnxp25oPg55/gfpXVPzc2cfg8GpI3mK7LT7+Ws3TU40p3IiIyEVrXCuQxwY249EBcaw/lMFPG48ya0syKdmFfLJ0P58s3U+LmCBGdaxDv+ZRNI26xNvMz8dkJiW0E6VXP4s5eYNtAsFdsyDx1Fa3qy3kNB929jWwrKVwfLstzBxeDUmrbZMR/lGTq2DY27aeI6l2FG5ERKTCTCYTnRuG07lhOM8Pb8miXanM2HiUhbtS2ZWSwyuzd/HK7F2Ouc38fOp3g/rf2C5ZrfgQNn8LR9bAd7dDRFPoPh5aXGNbeiJpNRxeBUfW2W5BL9cgM0S3hlotYMcvsG8hfNwd+jwBPf4CnhrAXJ0o3IiIyGXx8bSNvRnSOpbM/GJmbklm9tbkC95mfkXjCOJjK3ib+blExsG1H0C/p2HNJ7D2MzixF2ZOsG1/5h0E9brYFhCt1w3qdrbNlgzQ9++2O7P2L4aFL8LWH+Ca96BB98uvU5xC4UZERBwm1N+b269owO1XNKC4xMqWI5msvojbzDs3DKdV7WBa1g6+vFvNg6Kh/3PQ61HbOJyVH9sW+gytfzrI1L8ColqC+Rx3ekU0gTt+toWaOU9B2i6YMgQ6joEBEzXXTjWgcCMiIpXC29Nsv3RVdpv5tqNZrD5wktX7T7DuYEa528zLRAZ6Ex9rCzotY21bo8gAPD3OMn7mXHyCoPs46PaAbUZkv7CKFW8yQduboOkAmP/8qUHL/7Gtij74VWhzgwYcV2EKNyIi4hReHmY61A+jQ/0wHvjTbeabj2SxMzmb/Wm5pOcWs2xPOsv2pNtf6+NppnlMEC1jg2keHUBOLlhKrXh5XeBNzR4VDzZ/5B8O134I7W6F/02A9ET46V7Y9DUMe8fWyyNVjsKNiIi4xB9vMy9TUFxK4vEcdiZns+NYNjuSs9mZnE1+sW0m5S1Hsk4d6cnkXQtpXy+Mzg3D6NQgjI4Nwgj2vVDauUQNesADy2HF+7DkTdt4nI+72+7KimwOHl7g6QMe3rbtXL/7hWlwshMo3IiISJXh5+1hn0SwjNVqkHQynx2nAs/Wo5ms3ZdGvsXKyv0nWLn/BGC7StQ8Osg2hqdBOJ0ahFE3zM9xt6J7etvunmo16vSA46VvVuwcJg/b7eWRzWyTDkY2s4WjyDjwraT5gWoghRsREanSzGYTDSMDaBgZwNVtYrFYLMycNZvmXfqw6UgO6w6dZP2hDA6dyGdXSg67UnL4epVt3proYB+6NAynT7Na9G1Wi6hgB6yLZR9w/CNs/wmK86DUAqVFUFIMpcV/+L3I9lxJke13oxRO7LFtibPKnzco9lTYaYY5vCmRORlQOpALX3uTP1O4ERGRasdsgrioQFrWCeO2bvUBSM0pZP3BDNYdsm3bj2ZxPLuImVuSmbklGYD42GD6Nq/Flc1q0alBGF4VGaT8RyYTtL3Rtl0sw7DNhJyeaJuXJy0R0nfbttzjkJNs2w4swQPoCRgffgEd74ROYyG03qXVWgMp3IiIiFuICvJlaJtYhraJBWzjdzYdzmTlvnSW7E5jy1HboOWdydlMXryPIB9PejaN5MpTYad2qF/lFmgyQUgd29bkqvLPFWTaAk/6bkhPxJqaiOXA7/jkpcKyt2D5OxA3CDrfbbuD61y3sQugcCMiIm7Kz9uD7k0i6N4kgscGNedEbhHL9qSzODGVpXvSOZlXzJztKczZbptgsFl0IH2bR9GtUTht6oZc3nw7FS429NSkgl0AKLVYmDvzV65uYuC58T9wYCnsnmPbQupDpzHQ4Y6Kr4henG+b3DDjABhWMHuB2RM8PG0/z/XY08dWo3fQ2Ze0qGIUbkREpEaICPRhZIc6jOxQB6vVYOvRLBYnprFkdyqbDmey+3guu4/n8unS/QDEBPvSpm4IbeuE2H7WDSU8wHl3OhlmT4z4q6HtDbZenXVTYNM3tnWwFr4Ii1+1LS3R+W5o1Of0vDuGAbmppy952XuE9py5hlZFmczgEwy+Ibaw4xsCvqF/eHzq99D60Gzw5b3XZVC4ERGRGsdsNtGuXijt6oXyyIA4MvKKWb43naW709h0OJO9abmkZBeSsqPQPpsyQJ1QP9rWPRV26oTSuk4wof5OCDyRcTDkFej/LGz/GdZ9YVtDa8fPti2iKdTpZOuVSd8LRVnnPpdfGIQ3sfXGlFrAWgJWi21BUfvjP2ylFrAUnBoQbYXCTNuWeejc71Gnk8KNiIiIK4UFeDO8XW2Gt6sNQF5RCduPZbPlSCZbj2ax9UgW+9PzOJpZwNHMAvtaWQARAd40jAyg0R+2hhEBNIz0x9/bwX9mvfyg/a22LWWrLeRs+d4Wak7sPX2cyQyhDU7dfRVnvwuLyGYQEHFp720phMKsU+EmyzZOyP44s/xjF6+mrnAjIiLyJwE+nnRtFE7XRqfXkcoutLDtVNDZcupn0sl8TuQVcyKvmPWHMs44T0ywLw0j/e2hJy46iDZ1QogM9Ln8ImPawDXvwsAXYPsM2x1XEaeCTHhj8HLwmCEvX9tW0XE+LqBwIyIichGCfb3o0SSSHk0i7ftyCi0cOpHPgfQ8DqTncTA9jwMnbD8z8i22S1vZhazaf7LcuWJDfGldJ4Q2p7bWdUKoFXSJgccnyHa7uNgp3IiIiFyiIF+vM5aQKJOZX2wLPCfyOJCez/60XNv6Wel5JGcVkpxVfjzPHwNPfEwA2cXObIl7UbgRERGpBKH+3nSo702H+uUX7swtKjm1jEQW245mseVI5jkCjyfv7VpM85gg2xZt+xkXHUSgj/58n48+HREREScKPMt4nrMGnrRcTuQVs2LfCVbsO1HuHHXD/GgRE0SzU4GneUwQDSMC8PXS5H6gcCMiIuJyfw48FouFGf+bTdOOPdmbXsDulBwSj+eQmJJDak4RRzIKOJJRwPydqeXOE+rvRXSQL1HBPkQF+RId7ENUkA/Rwb5EBfsSFeRDVLAPPp7uHYIUbkRERKogHw9oUyeEjg0jy+3PyCsm8XgOu4/bFgndnWILPTlFJWTmW8jMt5B4POe85w7z96J2qB/1wvypF+5HvXB/6obZHtcN88fPu3qHH4UbERGRaiQswJsrGkdwRePT89UYhkFWgYXj2UWk5hTaf6ZmF3E8u5DUnFM/s4soLrWSkW8hI9/C9mPZZ32PyEAfW9gJ96demB9RQT74eHng5WHG29OMt4cZH89Tv596XPacj6cZf28PIhxxu/slUrgRERGp5kwmE6H+3oT6e9M8Juicx5WFoJTsQo6cLOBwRj5HMgo4fDKfwxkFHDmZT05RCem5RaTnFrHpcOYl1dOuXii/jOt5ia25fAo3IiIiNcQfQ1CLmOAznjcMg+yCEg5n5J8KPLbwcyK3mKISK8WlVopLSikusWIpNSi277Pani8pxVJq4Ofl2sU1FW5EREQEsIWfEH8vQvzPPndPdVH11y0XERERqQCFGxEREXErCjciIiLiVhRuRERExK0o3IiIiIhbUbgRERERt6JwIyIiIm5F4UZERETcisKNiIiIuBWFGxEREXErCjciIiLiVhRuRERExK0o3IiIiIhbUbgRERERt+Lp6gKczTAMALKzsx1+bovFQn5+PtnZ2Xh5eTn8/FVFTWhnTWgjqJ3uRu10HzWhjVCxdpb93S77O34+NS7c5OTkAFCvXj0XVyIiIiIVlZOTQ0hIyHmPMRkXE4HciNVq5dixYwQFBWEymRx67uzsbOrVq8fhw4cJDg526LmrkprQzprQRlA73Y3a6T5qQhuhYu00DIOcnBxq166N2Xz+UTU1rufGbDZTt27dSn2P4OBgt/7HWKYmtLMmtBHUTnejdrqPmtBGuPh2XqjHpowGFIuIiIhbUbgRERERt6Jw40A+Pj48//zz+Pj4uLqUSlUT2lkT2ghqp7tRO91HTWgjVF47a9yAYhEREXFv6rkRERERt6JwIyIiIm5F4UZERETcisKNiIiIuBWFGwf55z//ScOGDfH19aVbt26sWbPG1SU51MSJEzGZTOW2Fi1auLqsy7Z06VKGDx9O7dq1MZlM/Pzzz+WeNwyD5557jtjYWPz8/BgwYAB79uxxTbGX4ULtHDt27Bnf75AhQ1xT7CV69dVX6dKlC0FBQURFRTFy5EgSExPLHVNYWMi4ceOIiIggMDCQ66+/nuPHj7uo4ktzMe3s27fvGd/nAw884KKKL83kyZNp27atfXK37t2789tvv9mfd4fvEi7cTnf4Lv/stddew2QyMWHCBPs+R3+fCjcO8N133/HYY4/x/PPPs2HDBtq1a8fgwYNJTU11dWkO1apVK5KTk+3b8uXLXV3SZcvLy6Ndu3b885//POvzb7zxBh988AH/+te/WL16NQEBAQwePJjCwkInV3p5LtROgCFDhpT7fr/99lsnVnj5lixZwrhx41i1ahUJCQlYLBYGDRpEXl6e/ZhHH32U//3vf/zwww8sWbKEY8eOMWrUKBdWXXEX006A++67r9z3+cYbb7io4ktTt25dXnvtNdavX8+6deu46qqrGDFiBNu3bwfc47uEC7cTqv93+Udr167lk08+oW3btuX2O/z7NOSyde3a1Rg3bpz9cWlpqVG7dm3j1VdfdWFVjvX8888b7dq1c3UZlQowZsyYYX9stVqNmJgY480337Tvy8zMNHx8fIxvv/3WBRU6xp/baRiGMWbMGGPEiBEuqaeypKamGoCxZMkSwzBs352Xl5fxww8/2I/ZuXOnARgrV650VZmX7c/tNAzDuPLKK41HHnnEdUVVkrCwMOOzzz5z2++yTFk7DcO9vsucnBwjLi7OSEhIKNeuyvg+1XNzmYqLi1m/fj0DBgyw7zObzQwYMICVK1e6sDLH27NnD7Vr16Zx48aMHj2apKQkV5dUqQ4cOEBKSkq57zYkJIRu3bq53XcLsHjxYqKiomjevDkPPvggJ06ccHVJlyUrKwuA8PBwANavX4/FYin3fbZo0YL69etX6+/zz+0s88033xAZGUnr1q156qmnyM/Pd0V5DlFaWsr06dPJy8uje/fubvtd/rmdZdzluxw3bhzDhg0r971B5fxvs8YtnOlo6enplJaWEh0dXW5/dHQ0u3btclFVjtetWzemTp1K8+bNSU5OZtKkSfTu3Ztt27YRFBTk6vIqRUpKCsBZv9uy59zFkCFDGDVqFI0aNWLfvn384x//YOjQoaxcuRIPDw9Xl1dhVquVCRMm0LNnT1q3bg3Yvk9vb29CQ0PLHVudv8+ztRPgtttuo0GDBtSuXZstW7bwt7/9jcTERH766ScXVltxW7dupXv37hQWFhIYGMiMGTNo2bIlmzZtcqvv8lztBPf5LqdPn86GDRtYu3btGc9Vxv82FW7kogwdOtT+e9u2benWrRsNGjTg+++/55577nFhZeIIt9xyi/33Nm3a0LZtW5o0acLixYvp37+/Cyu7NOPGjWPbtm1uMS7sfM7Vzvvvv9/+e5s2bYiNjaV///7s27ePJk2aOLvMS9a8eXM2bdpEVlYWP/74I2PGjGHJkiWuLsvhztXOli1busV3efjwYR555BESEhLw9fV1ynvqstRlioyMxMPD44xR3cePHycmJsZFVVW+0NBQmjVrxt69e11dSqUp+/5q2ncL0LhxYyIjI6vl9zt+/HhmzpzJokWLqFu3rn1/TEwMxcXFZGZmlju+un6f52rn2XTr1g2g2n2f3t7eNG3alE6dOvHqq6/Srl073n//fbf7Ls/VzrOpjt/l+vXrSU1NpWPHjnh6euLp6cmSJUv44IMP8PT0JDo62uHfp8LNZfL29qZTp04sWLDAvs9qtbJgwYJy10zdTW5uLvv27SM2NtbVpVSaRo0aERMTU+67zc7OZvXq1W793QIcOXKEEydOVKvv1zAMxo8fz4wZM1i4cCGNGjUq93ynTp3w8vIq930mJiaSlJRUrb7PC7XzbDZt2gRQrb7Ps7FarRQVFbnNd3kuZe08m+r4Xfbv35+tW7eyadMm+9a5c2dGjx5t/93h3+flj3+W6dOnGz4+PsbUqVONHTt2GPfff78RGhpqpKSkuLo0h/nrX/9qLF682Dhw4IDx+++/GwMGDDAiIyON1NRUV5d2WXJycoyNGzcaGzduNADjnXfeMTZu3GgcOnTIMAzDeO2114zQ0FDjl19+MbZs2WKMGDHCaNSokVFQUODiyivmfO3MyckxHn/8cWPlypXGgQMHjPnz5xsdO3Y04uLijMLCQleXftEefPBBIyQkxFi8eLGRnJxs3/Lz8+3HPPDAA0b9+vWNhQsXGuvWrTO6d+9udO/e3YVVV9yF2rl3717jhRdeMNatW2ccOHDA+OWXX4zGjRsbffr0cXHlFfP3v//dWLJkiXHgwAFjy5Ytxt///nfDZDIZ8+bNMwzDPb5Lwzh/O93luzybP98F5ujvU+HGQT788EOjfv36hre3t9G1a1dj1apVri7JoW6++WYjNjbW8Pb2NurUqWPcfPPNxt69e11d1mVbtGiRAZyxjRkzxjAM2+3gzz77rBEdHW34+PgY/fv3NxITE11b9CU4Xzvz8/ONQYMGGbVq1TK8vLyMBg0aGPfdd1+1C+dnax9gTJkyxX5MQUGB8dBDDxlhYWGGv7+/cd111xnJycmuK/oSXKidSUlJRp8+fYzw8HDDx8fHaNq0qfHEE08YWVlZri28gu6++26jQYMGhre3t1GrVi2jf//+9mBjGO7xXRrG+dvpLt/l2fw53Dj6+zQZhmFcWp+PiIiISNWjMTciIiLiVhRuRERExK0o3IiIiIhbUbgRERERt6JwIyIiIm5F4UZERETcisKNiIiIuBWFGxGpkUwmEz///LOryxCRSqBwIyJON3bsWEwm0xnbkCFDXF2aiLgBT1cXICI105AhQ5gyZUq5fT4+Pi6qRkTciXpuRMQlfHx8iImJKbeFhYUBtktGkydPZujQofj5+dG4cWN+/PHHcq/funUrV111FX5+fkRERHD//feTm5tb7pgvvviCVq1a4ePjQ2xsLOPHjy/3fHp6Otdddx3+/v7ExcXx66+/2p/LyMhg9OjR1KpVCz8/P+Li4s4IYyJSNSnciEiV9Oyzz3L99dezefNmRo8ezS233MLOnTsByMvLY/DgwYSFhbF27Vp++OEH5s+fXy68TJ48mXHjxnH//fezdetWfv31V5o2bVruPSZNmsRNN93Eli1buPrqqxk9ejQnT560v/+OHTv47bff2LlzJ5MnTyYyMtJ5H4CIXLrLXtpTRKSCxowZY3h4eBgBAQHltpdfftkwDNvK1w888EC513Tr1s148MEHDcMwjE8//dQICwszcnNz7c/PmjXLMJvN9tXMa9eubTz99NPnrAEwnnnmGfvj3NxcAzB+++03wzAMY/jw4cZdd93lmAaLiFNpzI2IuES/fv2YPHlyuX3h4eH237t3717uue7du7Np0yYAdu7cSbt27QgICLA/37NnT6xWK4mJiZhMJo4dO0b//v3PW0Pbtm3tvwcEBBAcHExqaioADz74INdffz0bNmxg0KBBjBw5kh49elxSW0XEuRRuRMQlAgICzrhM5Ch+fn4XdZyXl1e5xyaTCavVCsDQoUM5dOgQs2fPJiEhgf79+zNu3Djeeusth9crIo6lMTciUiWtWrXqjMfx8fEAxMfHs3nzZvLy8uzP//7775jNZpo3b05QUBANGzZkwYIFl1VDrVq1GDNmDF9//TXvvfcen3766WWdT0ScQz03IuISRUVFpKSklNvn6elpH7T7ww8/0LlzZ3r16sU333zDmjVr+PzzzwEYPXo0zz//PGPGjGHixImkpaXx8MMPc8cddxAdHQ3AxIkTeeCBB4iKimLo0KHk5OTw+++/8/DDD19Ufc899xydOnWiVatWFBUVMXPmTHu4EpGqTeFGRFxizpw5xMbGltvXvHlzdu3aBdjuZJo+fToPPfQQsbGxfPvtt7Rs2RIAf39/5s6dyyOPPEKXLl3w9/fn+uuv55133rGfa8yYMRQWFvLuu+/y+OOPExkZyQ033HDR9Xl7e/PUU09x8OBB/Pz86N27N9OnT3dAy0WkspkMwzBcXYSIyB+ZTCZmzJjByJEjXV2KiFRDGnMjIiIibkXhRkRERNyKxtyISJWjq+UicjnUcyMiIiJuReFGRERE3IrCjYiIiLgVhRsRERFxKwo3IiIi4lYUbkRERMStKNyIiIiIW1G4EREREbeicCMiIiJu5f8BrG21GfR7WwgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convnext_acc= evaluate_model(model, test_loader, device, verbose=True)"
      ],
      "metadata": {
        "id": "ZfyWlzdZ4ShK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add8520a-085e-472e-f936-a768d38f9690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvNeXt needs a \"modern\" training recipe — strong augmentations, big cosine schedules, carefully adjusted stems and norms — whereas ResNet-50 is more forgiving on a small dataset. The design of ConvNeXt was tuned for large-scale ImageNet-style training. On very small, low-res data, a classic ResNet with the tried-and-true CIFAR tweaks can still win out.\n",
        "\n"
      ],
      "metadata": {
        "id": "NHyFfuQvGGze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/facebookresearch/ConvNeXt\n",
        "# https://github.com/FrancescoSaverioZuppichini/ConvNext\n",
        "# https://medium.com/towards-data-science/implementing-convnext-in-pytorch-7e37a67abba6\n",
        "# https://tech.bertelsmann.com/en/blog/articles/convnext?source=post_page325607a08c46\n",
        "# https://medium.com/@atakanerdogan305/convnext-next-generation-of-convolutional-networks-325607a08c46\n",
        "# https://medium.com/data-science/residual-bottleneck-inverted-residual-linear-bottleneck-mbconv-explained-89d7b7e7c6bc"
      ],
      "metadata": {
        "id": "R710JzWh5XS7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}