{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net from scratch in PyTorch\n",
        "\n",
        "Image segmentation is the process of dividing an image into multiple segments or regions to simplify its representation and make it easier to analyze. Segmentation provides context and meaning to individual pixels, transforming raw images into structured data that machines can interpret. By segmenting images, we can identify and extract specific objects, delineate boundaries, and even classify regions based on their content. Creating models that excel at segmentation is not just about accurate delineation; it is about enabling machines to understand and interpret visual data with precision and efficiency.\n",
        "\n",
        "U-Net stands out as a state-of-the-art solution that has revolutionized the field of image segmentation.\n",
        "\n",
        "https://arxiv.org/abs/1505.04597"
      ],
      "metadata": {
        "id": "TIkMRP7qC5Ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeBpAmMzCyVY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "TpYl6Ll2DFAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many trainable weights the model has\n",
        "def count_parameters(model) -> None:\n",
        "    total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "id": "Jnh3TP_4DFDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Implementation\n",
        "\n",
        "The U-Net architecture is characterized by its U-shaped structure, which gives it its name. It consists of an encoding path, a bottleneck, and a decoding path.\n",
        "\n",
        "The basic block of a U-Net is the **Double Convolutional Block**, which consists of two convolutions of 3x3 followed by ReLU activation. We use BatchNorm to maintain training stability (although the original paper didn't mention it, modern versions often incorporate it)."
      ],
      "metadata": {
        "id": "l6JRC5hrDdbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements two customizable CNN layers as a block.\n",
        "    U-Net-style: Input -> Conv2d -> BatchNorm2d -> ReLU -> Conv2d -> BatchNorm2d -> ReLU -> Output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bias=False, activation=None) -> None:\n",
        "        super(ConvBlock, self).__init__()\n",
        "        # first convolutional layer\n",
        "        self.conv1= nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=bias\n",
        "        )\n",
        "        # Batch Normalization to stabilize training\n",
        "        self.norm1= nn.BatchNorm2d(out_channels)\n",
        "        # Activation function -- ReLU is the default in U-Net\n",
        "        self.activation1= nn.ReLU() if activation is None else activation\n",
        "\n",
        "        # second convolutional layer\n",
        "        self.conv2= nn.Conv2d(\n",
        "            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=bias\n",
        "        )\n",
        "        # Batch Normalization to stabilize training\n",
        "        self.norm2= nn.BatchNorm2d(out_channels)\n",
        "        # Activation function -- ReLU is the default in U-Net\n",
        "        self.activation2= nn.ReLU() if activation is None else activation\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.conv1(x)\n",
        "        x= self.norm1(x)\n",
        "        x= self.activation1(x)\n",
        "\n",
        "        x= self.conv2(x)\n",
        "        x= self.norm2(x)\n",
        "        x= self.activation2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "LhSBrWWtDFGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding Path:** Captures the context of the input image by using a series of convolutional and max-pooling layers to downsample the spatial dimensions. It \"contracs\" the original images, but channels grow (feature learning).\n",
        "\n",
        "Each stage in the contracting path consists of ConvBlock followed by a 2x2 max pooling operation with a stride of 2 for downsampling. Before doing the max pooling, we save the convolutioned tensor. That convolutioned tensor is later used as skip connections and concatenated with an upsampled tensor."
      ],
      "metadata": {
        "id": "uBx3Dm4ESaaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements an encoder block of the U-Net architecture.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bias=False, activation=None) -> None:\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        # learn features\n",
        "        self.conv= ConvBlock(in_channels, out_channels, bias=bias, activation=activation)\n",
        "        # reduce size by half\n",
        "        self.pool= nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip= self.conv(x)     # feature map (also used for skip connection)\n",
        "        map = self.pool(skip)  # downsampled map\n",
        "\n",
        "        return skip, map\n"
      ],
      "metadata": {
        "id": "uvc2J6rQDFIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoding Path:** Uses upsampling and convolutional layers to produce a segmentation map that has the same spatial dimensions as the input image. It \"expands\" the contracted images (reconstruction).\n",
        "\n",
        "The Upsampling is done with a deconvolution (ConvTranspose2d) followed by a ConvBlock. We double the height and width of the image, then we concatenate the upsampled map with the matching encoder output (skip connection), and finally clean it up with a ConvBlock."
      ],
      "metadata": {
        "id": "PutE1zkSSf1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a decoder block of the U-Net architecture.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bias=False, activation=None) -> None:\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        # upsampling -> doubles height and width\n",
        "        self.up_conv= nn.ConvTranspose2d(\n",
        "            in_channels, out_channels, kernel_size=2, stride=2, bias=bias\n",
        "        )\n",
        "        # ConvBlock gets upsampled + skip features\n",
        "        self.conv= ConvBlock(\n",
        "            out_channels + out_channels, out_channels, bias=bias, activation=activation\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x= self.up_conv(x)              # upsample the inputs\n",
        "        x= torch.cat((x, skip), dim=1)  # concat with the skip connection\n",
        "        x= self.conv(x)                 # learn details\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "lOYkIP9gDFLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the U-Net network\n",
        "\n",
        "U-Net's strength in segmentation comes from its use of **skip connections**, which connect the encoding and decoding paths by fusing low-level and high-level features. This helps retain spatial details lost during downsampling, preserving the image's local and global context. By maintaining this spatial information, U-Net achieves more accurate segmentation masks. The skip connections assist the network in grasping the relationships between image parts, leading to improved segmentation results.\n",
        "\n",
        "The Bottleneck is the deepest compressed representation."
      ],
      "metadata": {
        "id": "RPMvx_PfDkDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    The U-Net architecture implementation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, num_classes=1, segmentation=True, dropout=0.1, bias=False,\n",
        "                 activation=None) -> None:\n",
        "        super(UNet, self).__init__()\n",
        "        # Activation function -- ReLU is the default in U-Net\n",
        "        activation= nn.ReLU() if activation is None else activation\n",
        "\n",
        "        # Encoder -> shrinking image, increasing channels\n",
        "        self.e1= EncoderBlock(in_channels, 64, bias=bias, activation=activation)\n",
        "        self.e2= EncoderBlock(64, 128, bias=bias, activation=activation)\n",
        "        self.e3= EncoderBlock(128, 256, bias=bias, activation=activation)\n",
        "        self.e4= EncoderBlock(256, 512, bias=bias, activation=activation)\n",
        "\n",
        "        # Bottleneck -> middle of the U\n",
        "        self.bottleneck= ConvBlock(512, 1024, bias=bias, activation=activation)\n",
        "\n",
        "        # Decoder -> expanding image, using skip connections\n",
        "        self.d1= DecoderBlock(1024, 512, bias=bias, activation=activation)\n",
        "        self.d2= DecoderBlock(512, 256, bias=bias, activation=activation)\n",
        "        self.d3= DecoderBlock(256, 128, bias=bias, activation=activation)\n",
        "        self.d4= DecoderBlock(128, 64, bias=bias, activation=activation)\n",
        "\n",
        "        self.dropout= nn.Dropout(p=dropout)\n",
        "        if segmentation:\n",
        "            # Output layer -> 1 output channel for binary segmentation\n",
        "            self.output= nn.Conv2d(64, num_classes, kernel_size=1, stride=1, padding=0, bias=bias)\n",
        "        else:\n",
        "            # U-Net was not designed as a classifier, but why not?\n",
        "            self.output= nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(output_size=1),\n",
        "                nn.Flatten(start_dim=1),\n",
        "                nn.Linear(64, num_classes),\n",
        "            )\n",
        "\n",
        "        # initialize parameters with Xavier initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        skip1, map1= self.e1(x)\n",
        "        skip2, map2= self.e2(map1)\n",
        "        skip3, map3= self.e3(map2)\n",
        "        skip4, map4= self.e4(map3)\n",
        "        # Bottleneck\n",
        "        b= self.bottleneck(map4)\n",
        "        # Decoder\n",
        "        d1= self.d1(b,  skip4)\n",
        "        d2= self.d2(d1, skip3)\n",
        "        d3= self.d3(d2, skip2)\n",
        "        d4= self.d4(d3, skip1)\n",
        "        # Output\n",
        "        out= self.output(d4)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "VEl8dKQPDFRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img= torch.randn(1, 3, 224, 224).to(device)  # a single image batch\n",
        "model= UNet(in_channels=3, num_classes=1).to(device)\n",
        "count_parameters(model)\n",
        "print(model(img).shape)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "WAg2ktjxDFTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c05ae3-bef1-41eb-c618-35a3dba6c543"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 31036672\n",
            "torch.Size([1, 1, 224, 224])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (e1): EncoderBlock(\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (e2): EncoderBlock(\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (e3): EncoderBlock(\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (e4): EncoderBlock(\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (bottleneck): ConvBlock(\n",
              "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation1): ReLU()\n",
              "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation2): ReLU()\n",
              "  )\n",
              "  (d1): DecoderBlock(\n",
              "    (up_conv): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (d2): DecoderBlock(\n",
              "    (up_conv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (d3): DecoderBlock(\n",
              "    (up_conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (d4): DecoderBlock(\n",
              "    (up_conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
              "    (conv): ConvBlock(\n",
              "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation1): ReLU()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (output): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Function\n",
        "\n",
        "TODO\n",
        "- Strong data augmentation for training.\n",
        "- Play with different learning rate values.\n",
        "- More training epochs.\n",
        "- Larger batch sizes.\n",
        "- Checkpointing."
      ],
      "metadata": {
        "id": "yl3DIXyeD4cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs,\n",
        "            device, eval_interval=1, dice_coef=None, verbose=False):\n",
        "\n",
        "    tr_loss_hist= []\n",
        "    tr_dcs_hist = []\n",
        "    vl_loss_hist= []\n",
        "    vl_dcs_hist = []\n",
        "\n",
        "    # --- training loop ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_loss= []\n",
        "        batch_dcs = []\n",
        "        start= time.time()\n",
        "\n",
        "        # --- training steps ---\n",
        "        # iterating over all batches\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # --- minibatch construction ---\n",
        "            images= images.float().to(device)\n",
        "            labels= labels.float().to(device)\n",
        "\n",
        "            # --- forward pass and get loss ---\n",
        "            logits= model(images)\n",
        "\n",
        "            if dice_coef is not None:\n",
        "                dcs= dice_coef(logits, labels)\n",
        "                batch_dcs.append(dcs.item())\n",
        "            loss= criterion(logits, labels)\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "\n",
        "            # --- backward pass to calculate the gradients ---\n",
        "            loss.backward()\n",
        "\n",
        "            # --- update the parameters using the gradient ---\n",
        "            optimizer.step()\n",
        "\n",
        "        # --- evaluation and track stats ---\n",
        "        tr_loss_hist.append(np.mean(batch_loss))\n",
        "        if dice_coef is not None:\n",
        "            tr_dcs_hist.append(np.mean(batch_dcs))\n",
        "\n",
        "        if epoch% eval_interval== 0 or epoch== epochs-1:\n",
        "            model.eval()\n",
        "            val_loss= []\n",
        "            val_dcs = []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels= images.float().to(device), labels.float().to(device)\n",
        "                    logits= model(images)\n",
        "\n",
        "                    if dice_coef is not None:\n",
        "                        dcs_v= dice_coef(logits, labels)\n",
        "                        val_dcs.append(dcs_v.item())\n",
        "                    loss_v= criterion(logits, labels)\n",
        "                    val_loss.append(loss_v.item())\n",
        "\n",
        "            if dice_coef is not None:\n",
        "                val_dcs= np.mean(val_dcs)\n",
        "            val_loss= np.mean(val_loss)\n",
        "\n",
        "            end= time.time()\n",
        "            dt= end - start\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch: {epoch} | Train Loss: {tr_loss_hist[-1]:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f} | dt/epoch: {dt*1000:.2f}ms\")\n",
        "                if dice_coef is not None:\n",
        "                    print(f\"Train DICE: {tr_dcs_hist[-1]:.4f} | Val DICE: {val_dcs:.4f}\")\n",
        "\n",
        "            # for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "            if scheduler is not None:\n",
        "                scheduler.step(val_loss)\n",
        "\n",
        "        if dice_coef is not None:\n",
        "            vl_dcs_hist.append(val_dcs)\n",
        "        vl_loss_hist.append(val_loss)\n",
        "\n",
        "    if dice_coef is not None:\n",
        "        return tr_loss_hist, vl_loss_hist, tr_dcs_hist, vl_dcs_hist\n",
        "\n",
        "    return tr_loss_hist, vl_loss_hist\n"
      ],
      "metadata": {
        "id": "Xr83uT_OD52c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device, criterion=None, dice_coef=None, verbose=False):\n",
        "    model.eval()\n",
        "    correct= 0\n",
        "    total= 0\n",
        "    batch_loss= 0\n",
        "    batch_dcs= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels= images.float().to(device), labels.float().to(device)\n",
        "            logits= model(images)\n",
        "\n",
        "            if dice_coef is not None:\n",
        "                loss= criterion(logits, labels)\n",
        "                dcs = dice_coef(logits, labels)\n",
        "\n",
        "                batch_loss+= loss.item()\n",
        "                batch_dcs += dcs.item()\n",
        "            else:\n",
        "                y_pred= torch.argmax(logits, dim=1)\n",
        "                correct += (y_pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    if dice_coef is not None:\n",
        "        eval_loss= batch_loss / len(test_loader)\n",
        "        eval_dcs= batch_dcs / len(test_loader)\n",
        "    else:\n",
        "        acc= correct / total\n",
        "\n",
        "    if verbose:\n",
        "        if dice_coef is not None:\n",
        "            print(f\"Loss: {eval_loss:.4f} | DICE: {eval_dcs:.4f}\")\n",
        "        else:\n",
        "            print(f\"Accuracy: {(acc * 100):.2f}%\")\n",
        "\n",
        "    if dice_coef is not None:\n",
        "        return eval_loss, eval_dcs\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "7P6T3RbwDFmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(train_loss, valid_loss, train_dice=None, valid_dice=None):\n",
        "    # plot training and validation losses\n",
        "    epochs= list(range(1, len(train_loss) + 1))\n",
        "\n",
        "    if train_dice is not None:\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "\n",
        "    plt.plot(epochs, train_loss, label='Train Loss')\n",
        "    plt.plot(epochs, valid_loss, label='Validation Loss')\n",
        "    plt.xticks(ticks=list(range(1, len(train_loss) + 1 + 1, 1)))\n",
        "    plt.title('Losses over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if train_dice is not None:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, train_dice, label='Training DICE')\n",
        "        plt.plot(epochs, valid_dice, label='Validation DICE')\n",
        "        plt.xticks(ticks=list(range(1, len(train_dice) + 1 + 1, 1)))\n",
        "        plt.title('DICE Coefficient over epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('DICE')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ugOXpMjtEAv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation -- Loading the Carvana Dataset\n",
        "\n",
        "https://www.kaggle.com/c/carvana-image-masking-challenge"
      ],
      "metadata": {
        "id": "HKNr-V9fKVpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "9EWLA0_pDFZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarvanaDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_path, limit=None):\n",
        "        self.root_path= root_path\n",
        "        self.limit = limit\n",
        "        self.images= sorted([root_path + '/train/' + i for i in os.listdir(root_path + '/train/')])[:self.limit]\n",
        "        self.masks = sorted([root_path + '/train_masks/' + i for i in os.listdir(root_path + '/train_masks/')])[:self.limit]\n",
        "\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.Resize((512, 512)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        if self.limit is None:\n",
        "            self.limit= len(self.images)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.images[index]).convert('RGB')\n",
        "        mask= Image.open(self.masks[index]).convert('L')\n",
        "\n",
        "        img = self.transform(img)\n",
        "        mask= self.transform(mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.images), self.limit)\n"
      ],
      "metadata": {
        "id": "uYFdf1AeDFWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR= 'carvana/'\n",
        "WORKING_DIR= 'working/'\n",
        "\n",
        "if len(os.listdir(WORKING_DIR)) <= 1:\n",
        "\n",
        "    with zipfile.ZipFile(DATASET_DIR + 'train.zip', 'r') as zip_file:\n",
        "        zip_file.extractall(WORKING_DIR)\n",
        "\n",
        "    with zipfile.ZipFile(DATASET_DIR + 'train_masks.zip', 'r') as zip_file:\n",
        "        zip_file.extractall(WORKING_DIR)\n",
        "\n",
        "    print(\n",
        "        len(os.listdir(WORKING_DIR + 'train')),\n",
        "        len(os.listdir(WORKING_DIR + 'train_masks'))\n",
        "    )\n",
        "\n",
        "train_dataset= CarvanaDataset(WORKING_DIR)\n",
        "generator= torch.Generator().manual_seed(25)\n",
        "\n",
        "train_dataset, test_dataset= random_split(train_dataset, [0.8, 0.2], generator=generator)\n",
        "test_dataset, val_dataset  = random_split(test_dataset,  [0.5, 0.5], generator=generator)\n",
        "\n",
        "batch_size= 8\n",
        "\n",
        "train_loader= DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "5iwwKdkbeAiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(val_loader)"
      ],
      "metadata": {
        "id": "JdKFdWRkVgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Segmentation Performance with the DICE Metric\n",
        "\n",
        "The DICE metric provides a measure of the similarity between two sets, in this case, the predicted segmentation and the ground truth segmentation. It calculates the overlap between the two sets, taking into account both the false positives and false negatives.\n",
        "\n",
        "$$\\text{DICE score} = \\frac{2 * (\\text{number of common elements})}{(\\text{number of elements in set }A + \\text{number of elements in set }B)}$$\n",
        "\n",
        "The DICE coefficient ranges from 0 to 1, where a value closer to 1 indicates a higher degree of overlap and thus better segmentation performance. A DICE score of 1 would mean a perfect overlap between the predicted and ground truth segmentations, while a score of 0 would indicate no overlap at all."
      ],
      "metadata": {
        "id": "1lGfUXSsBNit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DICE:\n",
        "\n",
        "    def __init__(self, eps=1e-7):\n",
        "        self.eps= eps\n",
        "\n",
        "    def __call__(self, y_pred, y_true):\n",
        "        y_pred_copy= y_pred.clone()\n",
        "\n",
        "        y_pred_copy[y_pred_copy < 0.]= 0\n",
        "        y_pred_copy[y_pred_copy > 0.]= 1\n",
        "\n",
        "        intersection= abs(torch.sum(y_pred_copy * y_true))\n",
        "        union= abs(torch.sum(y_pred_copy) + torch.sum(y_true))\n",
        "        dice= (2.0 * intersection + self.eps) / (union + self.eps)\n",
        "\n",
        "        return dice\n"
      ],
      "metadata": {
        "id": "GjvxgLIkCuTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup using TF32 and Fused AdamW"
      ],
      "metadata": {
        "id": "hFPpG74UGgje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_fused= False\n",
        "\n",
        "if device== 'cuda': # TF32 computationally more efficient (slightly the same precision of FP32)\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    # create AdamW optimizer and use the fused version of it is available\n",
        "    fused_available= 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "    # fused is a lot faster when it is available and when running on cuda\n",
        "    use_fused= fused_available\n",
        "\n",
        "\n",
        "# --- U-Net ---\n",
        "in_channels= 3\n",
        "num_classes= 1\n",
        "segmentation= True\n",
        "dropout= 0.1\n",
        "\n",
        "model= UNet(in_channels, num_classes, segmentation, dropout).to(device)\n",
        "count_parameters(model)\n",
        "\n",
        "\n",
        "# train_loader has size 509, so 10 epochs have 5,090 steps\n",
        "epochs= 10\n",
        "learning_rate= 3e-4\n",
        "\n",
        "optimizer= torch.optim.AdamW(\n",
        "    model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-4,\n",
        "    fused=use_fused\n",
        ")\n",
        "print(f\"Using fused AdamW: {use_fused}\")\n",
        "\n",
        "criterion= nn.BCEWithLogitsLoss()\n",
        "dice_coefficient= DICE()\n",
        "\n",
        "scheduler= None"
      ],
      "metadata": {
        "id": "NUYBkW_AGgjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss, vl_loss, tr_dice, vl_dice= trainer(model, train_loader, val_loader, optimizer, criterion,\n",
        "                                            scheduler, epochs, device, dice_coef=dice_coefficient,\n",
        "                                            verbose=True)"
      ],
      "metadata": {
        "id": "aQNgK6oJGgjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "plot_losses(tr_loss, vl_loss, tr_dice, vl_dice)"
      ],
      "metadata": {
        "id": "5XxA0xJUGgjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss, eval_dcs= evaluate_model(model, test_loader, device, criterion,\n",
        "                                    dice_coef=dice_coefficient, verbose=True)"
      ],
      "metadata": {
        "id": "gJSOdFUBGgjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Results"
      ],
      "metadata": {
        "id": "yrrsmzjzagJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_images_inference(model, image_tensors, mask_tensors, device):\n",
        "    transform= transforms.Compose([\n",
        "        transforms.Resize((512, 512))\n",
        "    ])\n",
        "\n",
        "    # Iterate for the images, masks and paths\n",
        "    for image_pth, mask_pth in zip(image_tensors, mask_tensors):\n",
        "        # Load the image\n",
        "        img= transform(image_pth)\n",
        "\n",
        "        # Predict the imagen with the model\n",
        "        pred_mask= model(img.unsqueeze(0))\n",
        "        pred_mask= pred_mask.squeeze(0).permute(1, 2, 0)\n",
        "\n",
        "        # Load the mask to compare\n",
        "        mask= transform(mask_pth).permute(1, 2, 0).to(device)\n",
        "\n",
        "        print(f\"DICE coefficient: {round(float(dice_coefficient(pred_mask, mask)), 5)}\")\n",
        "\n",
        "        # Show the images\n",
        "        img= img.detach().cpu().permute(1, 2, 0)\n",
        "        pred_mask= pred_mask.detach().cpu()\n",
        "        pred_mask[pred_mask < 0]= 0\n",
        "        pred_mask[pred_mask > 0]= 1\n",
        "\n",
        "        plt.figure(figsize=(15, 16))\n",
        "        plt.subplot(131), plt.imshow(img), plt.title(\"original\")\n",
        "        plt.subplot(132), plt.imshow(pred_mask, cmap=\"gray\"), plt.title(\"predicted\")\n",
        "        plt.subplot(133), plt.imshow(mask, cmap=\"gray\"), plt.title(\"mask\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "E9BvaUYcZ2kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n= 10\n",
        "\n",
        "image_tensors= []\n",
        "mask_tensors = []\n",
        "\n",
        "for _ in range(n):\n",
        "    random_index = random.randint(0, len(test_loader.dataset) - 1)\n",
        "    random_sample= test_loader.dataset[random_index]\n",
        "\n",
        "    image_tensors.append(random_sample[0])\n",
        "    mask_tensors.append(random_sample[1])\n",
        "\n",
        "random_images_inference(model, image_tensors, mask_tensors, device=\"cpu\")"
      ],
      "metadata": {
        "id": "1CUVBeGFaM3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "mpchzGLER0NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification -- Loading the CIFAR10 Dataset"
      ],
      "metadata": {
        "id": "l1a_G8-ODsF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation -- define transformations for the dataset\n",
        "transform= transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std= [0.2023, 0.1994, 0.2010]), # CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# load the CIFAR-10 dataset\n",
        "train_dataset= datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "train_size= int(0.9 * len(train_dataset))\n",
        "val_size  = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset= random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size= 128\n",
        "train_loader= DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "ICNPkKbMDFeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8f04cb-5171-468d-ca2c-78a7cfd4f7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(val_loader)"
      ],
      "metadata": {
        "id": "PADFIyXpDFiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42163e6c-d806-44a8-af81-594e38499841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup using TF32, Fused AdamW, and Label Smoothing"
      ],
      "metadata": {
        "id": "WiutcMgtGtS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_fused= False\n",
        "\n",
        "if device== 'cuda': # TF32 computationally more efficient (slightly the same precision of FP32)\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    # create AdamW optimizer and use the fused version of it is available\n",
        "    fused_available= 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "    # fused is a lot faster when it is available and when running on cuda\n",
        "    use_fused= fused_available\n",
        "\n",
        "\n",
        "# --- U-Net ---\n",
        "in_channels= 3\n",
        "num_classes= 10\n",
        "segmentation= False\n",
        "dropout= 0.1\n",
        "\n",
        "model= UNet(in_channels, num_classes, segmentation, dropout).to(device)\n",
        "count_parameters(model)\n",
        "\n",
        "\n",
        "# train_loader has size 352, so 20 epochs have 7,040 steps\n",
        "epochs= 20\n",
        "learning_rate= 5e-4\n",
        "\n",
        "optimizer= torch.optim.AdamW(\n",
        "    model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-4,\n",
        "    fused=use_fused\n",
        ")\n",
        "print(f\"Using fused AdamW: {use_fused}\")\n",
        "criterion= nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "# for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "scheduler= ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e-6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c1ca3f-6b2e-4fb2-b610-40fae49a5c4f",
        "id": "uWDrvo-kGtS6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 31037258\n",
            "Using fused AdamW: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss, vl_loss= trainer(model, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                          epochs, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5034754a-7b6f-4027-e5eb-bc313dea9ca9",
        "id": "5nxcVjgiGtS7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 1.8373 | Val Loss: 1.7031 | dt/epoch: 255497.07ms\n",
            "Epoch: 1 | Train Loss: 1.5375 | Val Loss: 1.5657 | dt/epoch: 253427.10ms\n",
            "Epoch: 2 | Train Loss: 1.3497 | Val Loss: 1.3960 | dt/epoch: 253368.25ms\n",
            "Epoch: 3 | Train Loss: 1.2287 | Val Loss: 1.2213 | dt/epoch: 253465.64ms\n",
            "Epoch: 4 | Train Loss: 1.1429 | Val Loss: 1.4235 | dt/epoch: 253571.41ms\n",
            "Epoch: 5 | Train Loss: 1.0830 | Val Loss: 1.2278 | dt/epoch: 254166.69ms\n",
            "Epoch: 6 | Train Loss: 1.0283 | Val Loss: 1.0704 | dt/epoch: 254149.52ms\n",
            "Epoch: 7 | Train Loss: 0.9830 | Val Loss: 1.1291 | dt/epoch: 253595.28ms\n",
            "Epoch: 8 | Train Loss: 0.9395 | Val Loss: 1.1003 | dt/epoch: 253830.82ms\n",
            "Epoch: 9 | Train Loss: 0.9068 | Val Loss: 1.0836 | dt/epoch: 253341.20ms\n",
            "Epoch: 10 | Train Loss: 0.8764 | Val Loss: 1.0564 | dt/epoch: 254003.40ms\n",
            "Epoch: 11 | Train Loss: 0.8460 | Val Loss: 1.0018 | dt/epoch: 253733.68ms\n",
            "Epoch: 12 | Train Loss: 0.8239 | Val Loss: 0.9474 | dt/epoch: 254026.07ms\n",
            "Epoch: 13 | Train Loss: 0.7993 | Val Loss: 0.9702 | dt/epoch: 253331.51ms\n",
            "Epoch: 14 | Train Loss: 0.7766 | Val Loss: 0.9101 | dt/epoch: 254111.13ms\n",
            "Epoch: 15 | Train Loss: 0.7562 | Val Loss: 0.9705 | dt/epoch: 253623.75ms\n",
            "Epoch: 16 | Train Loss: 0.7411 | Val Loss: 0.9624 | dt/epoch: 254004.13ms\n",
            "Epoch: 17 | Train Loss: 0.7186 | Val Loss: 0.9859 | dt/epoch: 253792.34ms\n",
            "Epoch: 18 | Train Loss: 0.7035 | Val Loss: 0.9636 | dt/epoch: 254041.15ms\n",
            "Epoch: 19 | Train Loss: 0.6336 | Val Loss: 0.7902 | dt/epoch: 253924.96ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "plot_losses(tr_loss, vl_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "a0bf19b0-7593-4ed9-8b19-24b32f9fa075",
        "id": "DVQN5L3qGtS8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_acc= evaluate_model(model, test_loader, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f112ca5-645b-4f73-c526-690d3d434e74",
        "id": "IajZcrYUGtS9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/@alejandro.itoaramendia/decoding-the-u-net-a-complete-guide-810b1c6d56d8\n",
        "# https://medium.com/@fernandopalominocobo/mastering-u-net-a-step-by-step-guide-to-segmentation-from-scratch-with-pytorch-6a17c5916114\n",
        "# https://medium.com/@AIchemizt/u-net-architecture-explained-a-simple-guide-with-pytorch-code-fc33619f2b75"
      ],
      "metadata": {
        "id": "IGkS40SjEr0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}