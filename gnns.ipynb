{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Networks\n",
        "\n",
        "From MLPs to GCNs and GATs."
      ],
      "metadata": {
        "id": "TnvueT1u39I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "E_N4RFLj4VBo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "t0MFHexDsf7m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new environment with Poetry\n",
        "#!pip install poetry\n",
        "!poetry init --no-interaction\n",
        "!poetry add torch torchvision torchaudio torch-geometric matplotlib scikit-learn"
      ],
      "metadata": {
        "id": "Uw22t8wM5TuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cora dataset is a benchmark dataset for graph neural networks. The dataset contains data about 2708 scientific publications. These publications are the nodes of the graph. An edge between nodes (publications) is created when a publication references the other one. The target is to predict the subject of each paper, there are seven classes in total."
      ],
      "metadata": {
        "id": "7ZKtmH6IAa_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset= Planetoid(root='.', name='Cora', force_reload=True)\n",
        "data= dataset[0]"
      ],
      "metadata": {
        "id": "CCfNS47i7Isc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_size= data.x.shape[0]\n",
        "dev_size= 500\n",
        "test_size= 500\n",
        "train_size= data_size - dev_size - test_size\n",
        "\n",
        "train_mask= torch.tensor([i< train_size for i in range(data_size)])\n",
        "dev_mask= torch.tensor([i>= train_size and i< (data_size - test_size) for i in range(data_size)])\n",
        "test_mask= torch.tensor([i>= (train_size + dev_size) for i in range(data_size)])\n",
        "\n",
        "data.train_mask= train_mask\n",
        "data.val_mask= dev_mask\n",
        "data.test_mask= test_mask"
      ],
      "metadata": {
        "id": "_efh5OV4OrJQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= data.to(device)\n",
        "\n",
        "Xtr, Ytr= data.x[data.train_mask], data.y[data.train_mask]\n",
        "Xdev, Ydev= data.x[data.val_mask], data.y[data.val_mask]\n",
        "Xte, Yte= data.x[data.test_mask], data.y[data.test_mask]\n",
        "\n",
        "edge_idx= data.edge_index\n",
        "\n",
        "num_inputs= data.x.shape[1]                # used for input_dim\n",
        "num_labels= len(set(data.y.cpu().numpy())) # used for output_dim"
      ],
      "metadata": {
        "id": "sCXwB8WLA2PV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network - MLP"
      ],
      "metadata": {
        "id": "IE0voRYS4PWK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hkgvp70V32ub"
      },
      "outputs": [],
      "source": [
        "class MLP_Hidden(nn.Module):\n",
        "    \"\"\"\n",
        "    Activation functions implemented: relu, tanh.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, layer_norm, activation, dropout=0.0) -> None:\n",
        "\n",
        "        super(MLP_Hidden, self).__init__()\n",
        "        self.fc_layer= nn.Linear(input_dim, output_dim)\n",
        "        self.norm= None\n",
        "        if layer_norm:\n",
        "            self.norm= nn.LayerNorm(output_dim)\n",
        "\n",
        "        if activation== 'tanh':\n",
        "            self.activ= nn.Tanh()\n",
        "        else:\n",
        "            self.activ= nn.ReLU(inplace=True)\n",
        "\n",
        "        self.dropout= None\n",
        "        if dropout> 0.0:\n",
        "            self.dropout= nn.Dropout(p=dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.fc_layer(x)\n",
        "        if self.norm is not None:\n",
        "            x= self.norm(x)\n",
        "        x= self.activ(x)\n",
        "        if self.dropout is not None:\n",
        "            x= self.dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a customizable MLP.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim=[16,], output_dim=1, layer_norm=False,\n",
        "                 activation='relu', dropout=0.0) -> None:\n",
        "        super(MLP, self).__init__()\n",
        "        if isinstance(hidden_dim, int):\n",
        "            hidden_dim= [hidden_dim]\n",
        "        n_hidden_layers= len(hidden_dim)\n",
        "\n",
        "        if n_hidden_layers== 0:\n",
        "            raise Exception('hidden_dim cannot be an empty list')\n",
        "\n",
        "        self.fc_in= MLP_Hidden(input_dim, hidden_dim[0], layer_norm, activation, dropout)\n",
        "\n",
        "        if n_hidden_layers> 1:\n",
        "            self.fc_hn= nn.Sequential(*[\n",
        "                MLP_Hidden(d, hidden_dim[i+1], layer_norm, activation, dropout)\n",
        "                for i, d in enumerate(hidden_dim[:-1])\n",
        "            ])\n",
        "        else: self.fc_hn= None\n",
        "\n",
        "        self.fc_out= nn.Linear(hidden_dim[-1], output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):  # no graph structure, only node features\n",
        "        x= self.fc_in(x)\n",
        "        if self.fc_hn is not None:\n",
        "            x= self.fc_hn(x)\n",
        "        x= self.fc_out(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= MLP(input_dim=num_inputs, hidden_dim=[32,], output_dim=num_labels,\n",
        "           layer_norm=True, dropout=0.1).to(device)\n",
        "\n",
        "total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSF9E-O5A2Sx",
        "outputId": "46dfcab4-0d4b-464d-b933-9550ed03021b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 46183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Convolutional Network - GCN\n",
        "\n",
        "There are three common types of prediction tasks in graphs:\n",
        "- You can predict on graph level. The input of the model is many different graphs, and every graph gets one classification. For example the class a molecule belongs to: every molecule is represented by one graph, and every molecule needs a prediction. Another example is image classification. Yes, images can also be represented as graphs!\n",
        "- Another way to use GNNs is by predicting on node level. The input of the GNN is one graph, and every node needs a prediction. This prediction is a characteristic of the node. Node regression is of course possible as well. Compared to classification, you only need to change the output layer activation function, the loss function, evaluation metric, and obviously the target.\n",
        "- Finally, we can predict on edge level. The value of an edge is predicted, or the likelihood of an edge that will appear soon. An example is recommended friends on social media (a.k.a. link prediction).\n",
        "\n",
        "For understanding one node, we need to look at its neighborhood and include that information in the GNN.\n",
        "\n",
        "There is one important step we should take before actually implementing a GNN, and that is normalization. Imagine, without normalization, nodes with more connections (e.g. one node having 10 neighbors vs. another with just 1) can dominate the learning process. The node with 10 neighbors would aggregate far more information than the one with 1, leading to imbalance and unstable learning. Normalization ensures that each node's contribution is appropriately scaled, so the network learns from the graph structure rather than being skewed by uneven data distribution.\n",
        "\n",
        "In GNNs it's common to use symmetric normalization. The idea is to normalize each node's aggregated features by the square root of its degree (the number of neighbors, including itself for self-loops). This helps to ensure that nodes with different degrees contribute equally during aggregation."
      ],
      "metadata": {
        "id": "Y5xEhMmpVsxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.nn as gnn\n",
        "\n",
        "class GCN_Hidden(nn.Module):\n",
        "    \"\"\"\n",
        "    Activation functions implemented: relu, tanh.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, activation, dropout=0.0) -> None:\n",
        "        super(GCN_Hidden, self).__init__()\n",
        "        self.gcn_layer= gnn.GCNConv(input_dim, output_dim)\n",
        "\n",
        "        if activation== 'tanh':\n",
        "            self.activ= nn.Tanh()\n",
        "        else:\n",
        "            self.activ= nn.ReLU(inplace=True)\n",
        "\n",
        "        self.dropout= None\n",
        "        if dropout> 0.0:\n",
        "            self.dropout= nn.Dropout(p=dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, edge_index= x[0], x[1] # unpack x and edge_index\n",
        "\n",
        "        x= self.gcn_layer(x, edge_index)\n",
        "        x= self.activ(x)\n",
        "        if self.dropout is not None:\n",
        "            x= self.dropout(x)\n",
        "\n",
        "        return [x, edge_index]\n",
        "\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementing a Graph Convolutional Network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim=[16,], output_dim=1, activation='relu',\n",
        "                 dropout=0.0) -> None:\n",
        "        super(GCN, self).__init__()\n",
        "        if isinstance(hidden_dim, int):\n",
        "            hidden_dim= [hidden_dim]\n",
        "        n_hidden_layers= len(hidden_dim)\n",
        "\n",
        "        if n_hidden_layers== 0:\n",
        "            raise Exception('hidden_dim cannot be an empty list')\n",
        "\n",
        "        self.gcn_in= GCN_Hidden(input_dim, hidden_dim[0], activation)\n",
        "\n",
        "        if n_hidden_layers> 1:\n",
        "            self.gcn_hn= nn.Sequential(*[\n",
        "                GCN_Hidden(d, hidden_dim[i+1], activation) for i, d in enumerate(hidden_dim[:-1])\n",
        "            ])\n",
        "        else:\n",
        "            self.gcn_hn= None\n",
        "\n",
        "        self.gcn_out= gnn.GCNConv(hidden_dim[-1], output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x= [x, edge_index] # pack x and edge_index into a single data element\n",
        "\n",
        "        x= self.gcn_in(x)\n",
        "        if self.gcn_hn is not None:\n",
        "            x= self.gcn_hn(x) # nn.Sequential forwards only one element\n",
        "        x= self.gcn_out(x[0], edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "FeDfgo0LNitv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= GCN(input_dim=num_inputs, hidden_dim=[32,], output_dim=num_labels,\n",
        "           dropout=0.1).to(device)\n",
        "\n",
        "total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR2gI40qgl0x",
        "outputId": "6d41b166-c463-4d2d-b0bf-c46f7f29d13e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 46119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional neural networks can be efficiently batched during training. For graph neural networks, it's harder to batch the data because nodes have different neighbors, resulting in potentially uneven mini-batches. Efficient sampling techniques (like GraphSAGE) or mini-batch training are necessary for scalability."
      ],
      "metadata": {
        "id": "rAu8nHaK_B_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "# training procedure - we train 10 times and calculate the average accuracy and standard deviation\n",
        "def supervised_training(model_config, learning_rate=1e-3, epochs=500, eval_interval=50,\n",
        "                        batches=True, batch_size=128, verbose=False):\n",
        "\n",
        "    model_class= model_config.model_class\n",
        "    input_dim= model_config.input_dim\n",
        "    hidden_dim= model_config.hidden_dim\n",
        "    output_dim= model_config.output_dim\n",
        "    dropout= model_config.dropout\n",
        "\n",
        "    if batches:\n",
        "        epoch_size= math.floor(Xtr.shape[0]/ batch_size)\n",
        "    else:\n",
        "        batch_size= Xtr.shape[0]\n",
        "        epoch_size= 1\n",
        "\n",
        "    results= []\n",
        "    best_test_acc= 0.0\n",
        "\n",
        "    for i in tqdm(range(10)):\n",
        "        if verbose: print(f'Training {model_class.__name__} iteration {i+1}')\n",
        "\n",
        "        # create a fresh model for training\n",
        "        if model_class== MLP:\n",
        "            model_tr= MLP(input_dim, hidden_dim, output_dim, layer_norm=model_config.layer_norm,\n",
        "                          dropout=dropout).to(device)\n",
        "        elif model_class== GCN:\n",
        "            model_tr= GCN(input_dim, hidden_dim, output_dim, dropout=dropout).to(device)\n",
        "        elif model_class== GAT:\n",
        "            model_tr= GAT(input_dim, hidden_dim, output_dim, heads=model_config.heads,\n",
        "                          dropout=dropout).to(device)\n",
        "\n",
        "        # create a PyTorch optimizer\n",
        "        optimizer= torch.optim.AdamW(model_tr.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "\n",
        "        # loss function\n",
        "        class_weights= torch.bincount(data.y) / len(data.y)\n",
        "        loss_fn= nn.CrossEntropyLoss(weight=1/class_weights).to(device)\n",
        "\n",
        "        # --- training loop ---\n",
        "        for epoch in range(epochs):\n",
        "            # iterating over all batches\n",
        "            for i in range(epoch_size):\n",
        "                # --- minibatch construction ---\n",
        "                Xb= Xtr[(i * batch_size):((i+1) * batch_size)]\n",
        "                Yb= Ytr[(i * batch_size):((i+1) * batch_size)]\n",
        "\n",
        "                # --- forward pass ---\n",
        "                if isinstance(model_tr, MLP):\n",
        "                    y_pred= model_tr(Xb)\n",
        "                else:\n",
        "                    y_pred= model_tr(data.x, data.edge_index)[data.train_mask]\n",
        "                tr_loss= loss_fn(y_pred, Yb)\n",
        "\n",
        "                # --- backward pass ---\n",
        "                model_tr.train(True)\n",
        "                optimizer.zero_grad()\n",
        "                tr_loss.backward()\n",
        "\n",
        "                # --- update ---\n",
        "                optimizer.step()\n",
        "\n",
        "            # --- track stats ---\n",
        "            if epoch% eval_interval== 0:\n",
        "                model_tr.eval()\n",
        "                with torch.no_grad():\n",
        "                    if isinstance(model_tr, MLP):\n",
        "                        y_pred= model_tr(Xdev)\n",
        "                    else:\n",
        "                        y_pred= model_tr(data.x, data.edge_index)[data.val_mask]\n",
        "\n",
        "                    val_loss= loss_fn(y_pred, Ydev)\n",
        "                    val_acc= (y_pred.argmax(dim=1)== Ydev).sum().item()/ Ydev.shape[0]\n",
        "                    if verbose:\n",
        "                        print(f'Epoch {epoch} | Training Loss: {tr_loss.item():.4f} | Validation Loss: {val_loss.item():.4f} | Validation Acc: {val_acc:>5.2f}')\n",
        "\n",
        "        # --- final evaluation on the test set ---\n",
        "        model_tr.eval()\n",
        "        with torch.no_grad():\n",
        "            if isinstance(model_tr, MLP):\n",
        "                y_pred= model_tr(Xte)\n",
        "            else:\n",
        "                y_pred= model_tr(data.x, data.edge_index)[data.test_mask]\n",
        "\n",
        "            test_loss= loss_fn(y_pred, Yte)\n",
        "            test_acc= (y_pred.argmax(dim=1)== Yte).sum().item()/ Yte.shape[0]\n",
        "            if best_test_acc< test_acc:\n",
        "                best_model= copy.deepcopy(model_tr)\n",
        "            del model_tr\n",
        "\n",
        "            if verbose: print(f'{model_class.__name__} Test Loss: {test_loss.item():.2f} | Test Acc: {test_acc:>5.2f}')\n",
        "            results.append([val_acc, test_acc])\n",
        "\n",
        "    return best_model, torch.tensor(results)\n"
      ],
      "metadata": {
        "id": "obq48nTaA2WR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print average on test set and standard deviation\n",
        "@dataclass\n",
        "class MLPConfig:\n",
        "    model_class= MLP\n",
        "    input_dim= num_inputs\n",
        "    hidden_dim= [32,]\n",
        "    output_dim= num_labels\n",
        "    layer_norm= True\n",
        "    dropout= 0.1\n",
        "\n",
        "model, results= supervised_training(MLPConfig, learning_rate=0.01, epochs=1000, eval_interval=100)\n",
        "print(f'{model.__class__.__name__} - Test Accuracy: {100*results[:,1].mean():.2f} ± {100*results[:,1].std():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDLirCnkXmgu",
        "outputId": "29bfcb35-c4df-4436-9550-0a26d66e4a4e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:21<00:00, 20.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP - Test Accuracy: 72.46 ± 1.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print average on test set and standard deviation\n",
        "@dataclass\n",
        "class GCNConfig:\n",
        "    model_class= GCN\n",
        "    input_dim= num_inputs\n",
        "    hidden_dim= [32,]\n",
        "    output_dim= num_labels\n",
        "    dropout= 0.1\n",
        "\n",
        "model, results= supervised_training(GCNConfig, learning_rate=0.01, epochs=1000, eval_interval=100,\n",
        "                                    batches=False)\n",
        "print(f'{model.__class__.__name__} - Test Accuracy: {100*results[:,1].mean():.2f} ± {100*results[:,1].std():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjNGb5qUXUcD",
        "outputId": "92c011a8-cfeb-4d0c-f176-4ae4b4ef5eec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:33<00:00,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN - Test Accuracy: 83.78 ± 0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph structure should really make a difference for the problem you are trying to solve. The structure should be meaningful for the prediction task at hand. Testing is important here. You can try to formulate the graph in different ways to see if one way of formulating works better than another one.\n",
        "\n",
        "Training a graph neural network takes more time than training a normal neural network. So if the results improve only a little bit and training time is important, the normal neural network can be the best choice. Also, the effectiveness among types of graph neural networks (GCN, GAT, GraphSAGE) can vary greatly based on the problem.\n",
        "\n",
        "Just like in standard neural networks, transfer learning (pre-training a GNN on a large dataset and fine-tuning on the target dataset) can be effective for GNNs. Checking for available pre-trained models for your task can be valuable.\n",
        "\n",
        "As we've seen, simply adding graph information to a basic neural network can dramatically boost performance, as was the case when we moved from a normal neural network to a GCN for the Cora dataset. By aggregating information from neighboring nodes, GCNs can provide a richer representation of the data, leading to more accurate predictions. But, it's crucial to remember that GNNs aren't a magic bullet for every problem. The graph structure must be truly meaningful to the prediction task, and the increase in training complexity might not always justify the performance boost, especially when training time is critical."
      ],
      "metadata": {
        "id": "d1BiiWAP_PfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/graph-neural-networks-part-1-graph-convolutional-networks-explained-9c6aaa8a406e"
      ],
      "metadata": {
        "id": "N6GhxIdHBFgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Attention Network - GAT\n",
        "\n",
        "GCNs treat all neighbors equally. For GATs, this is different. GATs allow the model to learn different importance (attention) scores for different neighbors. They aggregate neighbor information by using attention mechanisms (this might ring a bell because these mechanisms are also used in transformers).\n",
        "\n",
        "In the GCN, we only looked at the degree of the nodes. GATs on the other hand, also take the feature values into account to assign attention scores to different neighbors. So instead of treating all neighbors equally, an attention mechanism is introduced that assigns varying levels of importance to different neighbors. This allows the network to focus on the most relevant parts of the graph structure, essentially learning \"where to look\" when making predictions.\n",
        "\n",
        "**Computing Attention Scores:** For each node, we calculate an attention score for every neighboring node. This score is a measure of how important a specific neighbor's features are when updating the current node's features (https://arxiv.org/pdf/1710.10903). The score is learned during training, so the model decides which nodes matter most for each task (https://arxiv.org/abs/2105.14491), most of the time this method is more effective.\n",
        "\n",
        "Just like transformers, GATs often use multi-head attention to improve their performance. Multi-head attention refers to running several separate attention mechanisms, or heads, in parallel. Each of these heads independently computes attention scores for the neighbors of a node, learning to focus on different aspects of the graph structure or node features. After these heads process the graph, their outputs are either concatenated or averaged to form the final node representation. So one of the key reasons of using multiple heads instead of one is to learn diverse patterns, because each attention head has its own learnable parameters and can learn to focus on different parts of the neighborhood. Another reason is that it stabilizes the training process. You can compare it with an ensemble, other heads can compensate for a \"noisy head\"."
      ],
      "metadata": {
        "id": "-E2HQv76_pvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "class GAT_Hidden(nn.Module):\n",
        "    \"\"\"\n",
        "    Activation functions implemented: ELU only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, heads, concat=True, activation=True,\n",
        "                 dropout=0.0) -> None:\n",
        "        super(GAT_Hidden, self).__init__()\n",
        "        self.dropout= None\n",
        "        if dropout> 0.0:\n",
        "            self.dropout= nn.Dropout(p=dropout)\n",
        "\n",
        "        self.gat_layer= GATv2Conv(input_dim, output_dim, heads=heads, concat=concat)\n",
        "\n",
        "        self.activ= None\n",
        "        if activation:\n",
        "            self.activ= nn.ELU(inplace=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, edge_index= x[0], x[1] # unpack x and edge_index\n",
        "\n",
        "        if self.dropout is not None:\n",
        "            x= self.dropout(x)\n",
        "        x= self.gat_layer(x, edge_index)\n",
        "        if self.activ is not None:\n",
        "            x= self.activ(x)\n",
        "\n",
        "        return [x, edge_index]\n",
        "\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementing a Graph Attention Network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim=[16,], output_dim=1, heads=8, dropout=0.0) -> None:\n",
        "        super(GAT, self).__init__()\n",
        "        if isinstance(hidden_dim, int):\n",
        "            hidden_dim= [hidden_dim]\n",
        "        n_hidden_layers= len(hidden_dim)\n",
        "\n",
        "        if n_hidden_layers== 0:\n",
        "            raise Exception('hidden_dim cannot be an empty list')\n",
        "\n",
        "        self.gat_in = GAT_Hidden(input_dim, hidden_dim[0], heads, dropout=dropout)\n",
        "\n",
        "        if n_hidden_layers> 1:\n",
        "            self.gat_hn= nn.Sequential(*[\n",
        "                GAT_Hidden((d * heads), hidden_dim[i+1], heads, dropout=dropout)\n",
        "                for i, d in enumerate(hidden_dim[:-1])\n",
        "            ])\n",
        "        else:\n",
        "            self.gat_hn= None\n",
        "        # for the last GAT layer we use concat=False to average the outputs of the heads\n",
        "        self.gat_out= GAT_Hidden((hidden_dim[-1] * heads), output_dim, heads, concat=False,\n",
        "                                 activation=False, dropout=dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x= [x, edge_index] # pack x and edge_index into a single data element\n",
        "\n",
        "        x= self.gat_in(x)\n",
        "        if self.gat_hn is not None:\n",
        "            x= self.gat_hn(x) # nn.Sequential forwards only one element\n",
        "        x= self.gat_out(x)\n",
        "\n",
        "        return F.log_softmax(x[0], dim=1)\n"
      ],
      "metadata": {
        "id": "enthxQHiA2hx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each attention head computes its own set of attention scores and new node features independently. For $N$ heads, and a given node $i$, we'll end up with $N$ different sets of transformed features. Next up, all outputs are concatenated (stacked) or averaged. Concatenation is more common because it increases the model's expressiveness, but on the other hand the output dimension will be larger. Averaging helps to smooth out the differences between the heads. A general rule is to use concatenation when it's a hidden layer in the network and averaging when it's the last layer. When all attention heads are combined, we hope to get a comprehensive view of the graph, because the different heads have different perspectives on the relationships in the graph."
      ],
      "metadata": {
        "id": "DSlF1NcXt_Zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= GAT(input_dim=num_inputs, hidden_dim=[32,], output_dim=num_labels,\n",
        "           dropout=0.1).to(device)\n",
        "\n",
        "total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ibq8qiKmoPp",
        "outputId": "b70d6daf-4193-4969-f6cf-537873eaa90e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 763567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print average on test set and standard deviation\n",
        "@dataclass\n",
        "class GATConfig:\n",
        "    model_class= GAT\n",
        "    input_dim= num_inputs\n",
        "    hidden_dim= [32,]\n",
        "    output_dim= num_labels\n",
        "    heads= 8\n",
        "    dropout= 0.1\n",
        "\n",
        "model, results= supervised_training(GATConfig, learning_rate=0.01, epochs=1000, eval_interval=100,\n",
        "                                    batches=False)\n",
        "print(f'{model.__class__.__name__} - Test Accuracy: {100*results[:,1].mean():.2f} ± {100*results[:,1].std():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmZKFiKHmoU9",
        "outputId": "d5ce805c-5146-41ca-cebf-e74a606776d9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:17<00:00,  7.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT - Test Accuracy: 85.64 ± 0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GAT model takes a bit longer than the GCN... The attention mechanism in GATs adds additional complexity to the model, both in terms of computation and the number of parameters. This makes GATs more resource-intensive and slower to train than GCNs.\n",
        "\n",
        "Multi-head attention helps stabilize training, but there is still a risk of overfitting, especially when using many attention heads or deep GAT architectures. Using techniques like dropout and early stopping can help to mitigate this.\n",
        "\n",
        "Many steps in finetuning GNNs are similar to traditional neural networks: testing different values for the hyperparameters and preventing overfitting with early stopping. For example with GATs you need to tune the number of attention heads. Small changes to node and edge features can have an impact on GNN performance, so it might help to experiment with different feature combinations or to create new features. Augmenting data can improve generalization. You can do this by adding noise to edges, randomly dropping nodes, or by performing subgraph sampling."
      ],
      "metadata": {
        "id": "21nURmxJN04c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/graph-neural-networks-part-2-graph-attention-networks-vs-gcns-029efd7a1d92"
      ],
      "metadata": {
        "id": "5u0VqjtdA2mD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}