{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GoogLeNet from scratch in PyTorch\n",
        "\n",
        "Although designed in 2014, the Inception models (GoogLeNet) are still some of the most successful neural networks for image classification and detection. Their original article is a classic among machine learning research papers.\n",
        "\n",
        "https://arxiv.org/abs/1409.4842"
      ],
      "metadata": {
        "id": "vDE0bd3-3cSp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "725dlIKT3Z-a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "lO1EqkSq3esu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many trainable weights the model has\n",
        "def count_parameters(model) -> None:\n",
        "    total_params= sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Number of parameters: {total_params}')"
      ],
      "metadata": {
        "id": "XUavisSN3ewG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Implementation\n",
        "\n",
        "Starting by the fundamental building block of a CNN, represented by a convolutional layer. Notably, Batch Normalization was not introduced when GoogleNet (Inception) came out but modern implementations include it. Inception v2 (https://arxiv.org/abs/1502.03167) apply Batch Normalization after every convolution (including the 1x1 bottlenecks), which speeds convergence and stabilizes training."
      ],
      "metadata": {
        "id": "Uevxi4Vh3xLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements one customizable CNN layer.\n",
        "    GoogLeNet-style: Input -> Conv2d -> BatchNorm2d -> ReLU -> Output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False,\n",
        "                 norm=True, activation=None) -> None:\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.conv= nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "        # Batch Normalization to stabilize training\n",
        "        self.norm= nn.BatchNorm2d(out_channels) if norm else None\n",
        "        # Activation function -- ReLU is the default in GoogLeNet\n",
        "        self.activation= nn.ReLU(inplace=True) if activation is None else activation\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.conv(x)\n",
        "        if self.norm is not None:\n",
        "            x= self.norm(x)\n",
        "        x= self.activation(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RFjdwMj03ezq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Inception module forwards the input through four parallel branches of filters with different sizes: 1x1, 3x3, and 5x5. Note that even a modest number of 5x5 convolutions can be expensive. This drawback was solved by applying dimension reduction and projections whenever the computational requirements would increase. That is, 1x1 conv is applied before expensive 3x3 and 5x5 convolutions to keep the computational cost maintainable.\n",
        "\n",
        "The input tensor can be downsampled (through max-pooling) to reduce costs; however, we cannot perform downsampling too often; otherwise, information loss accumulates, which we want to avoid. 1x1 convolution solves this problem by pooling not inside a single channel but across the channels (keeps the image size stable while decreasing the number of channels).\n",
        "\n",
        "Therefore, Inception processes visual information at various scales and concatenate the resulting smaller tensors side by side so that the next stage can abstract features from different scales simultaneously."
      ],
      "metadata": {
        "id": "iHLZodTIkJ_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the Inception module with 4 parallel branches:\n",
        "    - 1x1 convolution\n",
        "    - 1x1 convolution followed by 3x3 convolution\n",
        "    - 1x1 convolution followed by 5x5 convolution\n",
        "    - 3x3 max pooling followed by 1x1 convolution\n",
        "    The output of this module concatenates feature maps from all 4 branches.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_ch1x1, in_ch3x3, out_ch3x3, in_ch5x5, out_ch5x5,\n",
        "                 out_1x1_pool_proj, activation) -> None:\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 convolution\n",
        "        self.branch1= ConvLayer(in_channels, out_ch1x1, kernel_size=1, activation=activation)\n",
        "        # 1x1 convolution followed by 3x3 convolution\n",
        "        self.branch2= nn.Sequential(\n",
        "            ConvLayer(in_channels, in_ch3x3, kernel_size=1, activation=activation),\n",
        "            ConvLayer(in_ch3x3, out_ch3x3, kernel_size=3, padding=1, activation=activation)\n",
        "        )\n",
        "        # 1x1 convolution followed by 5x5 convolution\n",
        "        self.branch3= nn.Sequential(\n",
        "            ConvLayer(in_channels, in_ch5x5, kernel_size=1, activation=activation),\n",
        "            ConvLayer(in_ch5x5, out_ch5x5, kernel_size=5, padding=2, activation=activation)\n",
        "        )\n",
        "        # 3x3 max pooling followed by 1x1 convolution\n",
        "        self.branch4= nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "            ConvLayer(in_channels, out_1x1_pool_proj, kernel_size=1, activation=activation)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1= self.branch1(x)\n",
        "        branch2= self.branch2(x)\n",
        "        branch3= self.branch3(x)\n",
        "        branch4= self.branch4(x)\n",
        "\n",
        "        return torch.cat([branch1, branch2, branch3, branch4], dim=1)\n"
      ],
      "metadata": {
        "id": "MLSXGdhG3e2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the relatively large depth of the network, the ability to propagate gradients back through all the layers is a concern. The authors solved this issue by adding auxiliary classifiers connected to some intermediate layers to encourage discrimination in the lower stages in the classifier, increase the gradient signal that gets propagated back, and provide additional regularization.\n",
        "\n",
        "These **auxiliary classifiers** are smaller convolutional networks put on top of the output of the **Inception 4a and 4d modules**. During training, their loss is added to the total loss of the network with a discount weight (the losses of auxiliary classifiers are weighted by 0.3). At inference time, the auxiliary classifiers are discarded."
      ],
      "metadata": {
        "id": "Ho9Qa5bcmLh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionAux(nn.Module):\n",
        "    \"\"\"\n",
        "    Auxiliary classifiers connected to intermediate layers (Inception 4a and 4d). During training,\n",
        "    their loss gets added to the total loss of the network to increase the gradient signal that\n",
        "    get propagated back and provide additional regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, num_classes, activation, dropout) -> None:\n",
        "        super(InceptionAux, self).__init__()\n",
        "        # Initial pooling\n",
        "        self.pool= nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.conv= ConvLayer(in_channels, 128, kernel_size=1, activation=activation)\n",
        "        self.fc1= nn.Linear(4 * 4 * 128, 1024)\n",
        "        self.activation= activation\n",
        "        self.dropout= nn.Dropout(p=dropout)\n",
        "        self.fc2= nn.Linear(1024, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.pool(x)\n",
        "        x= self.conv(x)\n",
        "        x= torch.flatten(x, 1)\n",
        "        x= self.fc1(x)\n",
        "        x= self.activation(x)\n",
        "        x= self.dropout(x)\n",
        "        x= self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "543omlIh3e5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the GoogLeNet network\n",
        "\n",
        "The network is 22 layers deep when counting only layers with parameters (or 27 layers if we also count pooling), but the code is organized into 5 convolutional stages (feature extractor) followed by a final classification head.\n",
        "\n",
        "**Inception v2** (https://arxiv.org/abs/1502.03167) reduces the complexity of branch3 by factorizing its 5x5 conv with two sequential 3x3 convs (same receptive field as one 5x5 but with fewer parameters) and ReLU in between, giving more nonlinearity.\n",
        "\n",
        "**Inception v3** (https://arxiv.org/abs/1512.00567) takes the v2 improvements further and adds new factorization ideas:\n",
        "\n",
        "- **Asymmetric Convolutions:** A 3x3 conv can be replaced by a 1x3 followed by a 3x1 (further reducing cost), without loss in expressivity (also 7x7 -> 1x7 + 7x1).\n",
        "- **Grid Size Reduction:** A pooling layer concatenated with a parallel 3x3 conv (both with stride 2).\n",
        "- Simplified side heads.\n",
        "- Label smoothing for training.\n",
        "\n",
        "But the core multi-branch CONCAT idea remains."
      ],
      "metadata": {
        "id": "Jqw_l8oW64c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the GoogLeNet architecture.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, num_classes=1000, aux_logits=True, activation=None, dropout=0.2,\n",
        "                 dropout_aux=0.7) -> None:\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        # Activation function -- ReLU is the default in GoogLeNet\n",
        "        activation= nn.ReLU(inplace=True) if activation is None else activation\n",
        "\n",
        "        # Feature extractor -- ConvLayers 1 and 2\n",
        "        self.conv1= ConvLayer(in_channels, 64, kernel_size=7, stride=2, padding=3, activation=activation)\n",
        "        self.pool1= nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n",
        "        self.conv2= nn.Sequential(\n",
        "            ConvLayer(64, 64, kernel_size=1, activation=activation),\n",
        "            ConvLayer(64, 192, kernel_size=3, padding=1, activation=activation),\n",
        "        )\n",
        "        self.pool2= nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n",
        "\n",
        "        # Inception modules 3, 4, and 5\n",
        "        # in_channels, out_ch1x1, in_ch3x3, out_ch3x3, in_ch5x5, out_ch5x5, out_1x1_pool_proj\n",
        "        self.inception3= nn.Sequential(\n",
        "            Inception(192,  64,  96, 128, 16, 32, 32, activation),\n",
        "            Inception(256, 128, 128, 192, 32, 96, 64, activation),\n",
        "        )\n",
        "        self.pool3= nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n",
        "\n",
        "        self.inception4a= Inception(480, 192,  96, 208, 16, 48, 64, activation)\n",
        "        self.inception4b= Inception(512, 160, 112, 224, 24, 64, 64, activation)\n",
        "        self.inception4c= Inception(512, 128, 128, 256, 24, 64, 64, activation)\n",
        "        self.inception4d= Inception(512, 112, 144, 288, 32, 64, 64, activation)\n",
        "        self.inception4e= Inception(528, 256, 160, 320, 32,128,128, activation)\n",
        "        self.pool4= nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n",
        "\n",
        "        # Auxiliar classifiers connected to Inception 4a and 4d (optional)\n",
        "        if aux_logits:\n",
        "            self.aux1= InceptionAux(512, num_classes, activation, dropout_aux)\n",
        "            self.aux2= InceptionAux(528, num_classes, activation, dropout_aux)\n",
        "        else:\n",
        "            self.aux1= None\n",
        "            self.aux2= None\n",
        "\n",
        "        self.inception5= nn.Sequential(\n",
        "            Inception(832, 256, 160, 320, 32, 128, 128, activation),\n",
        "            Inception(832, 384, 192, 384, 48, 128, 128, activation),\n",
        "        )\n",
        "\n",
        "        # Pooling and classification head to produce the final class logits\n",
        "        self.avgpool= nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.head= nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "        # Initialize parameters with Xavier initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.pool1(self.conv1(x))\n",
        "        x= self.pool2(self.conv2(x))\n",
        "        x= self.pool3(self.inception3(x))\n",
        "        x= self.inception4a(x)\n",
        "\n",
        "        if self.aux1 is not None and self.training:\n",
        "            aux1= self.aux1(x)\n",
        "        else:\n",
        "            aux1= None\n",
        "\n",
        "        x= self.inception4b(x)\n",
        "        x= self.inception4c(x)\n",
        "        x= self.inception4d(x)\n",
        "\n",
        "        if self.aux2 is not None and self.training:\n",
        "            aux2= self.aux2(x)\n",
        "        else:\n",
        "            aux2= None\n",
        "\n",
        "        x= self.pool4(self.inception4e(x))\n",
        "        x= self.avgpool(self.inception5(x))\n",
        "        x= torch.flatten(x, 1)\n",
        "        x= self.head(x)\n",
        "\n",
        "        return x, aux1, aux2\n"
      ],
      "metadata": {
        "id": "ozZ7R7Lz3e9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using **torchvision** GoogLeNet architecture to get the parameter count, we see that the total parameters comes out to be 6,624,904. It's important to note that this architecture replaces all 5x5 convolutions with 3x3 convolutions (a known bug), resulting in a different parameter count. Ideally, the parameter count should align with the one we created, which is a total of 7,005,832 parameter."
      ],
      "metadata": {
        "id": "A3RpLkLaf1uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchvision.models import GoogLeNet_Weights\n",
        "\n",
        "tvis_model= models.googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1).to(device)\n",
        "count_parameters(tvis_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmv36-P03fA9",
        "outputId": "5af9837d-1189-44d3-bf1c-fab901bb10ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 172MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 6624904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img= torch.randn(1, 3, 224, 224).to(device)  # a single image batch\n",
        "model= GoogLeNet(in_channels=3, aux_logits=False).to(device)\n",
        "count_parameters(model)\n",
        "out, _, _= model(img)\n",
        "print(out.shape)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "J1J_4ZLk3fGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9e5e6e-fedc-43db-8cdc-c2735ed326b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 7005832\n",
            "torch.Size([1, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): ConvLayer(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "  (conv2): Sequential(\n",
              "    (0): ConvLayer(\n",
              "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): ConvLayer(\n",
              "      (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "  (inception3): Sequential(\n",
              "    (0): Inception(\n",
              "      (branch1): ConvLayer(\n",
              "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch3): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch4): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Inception(\n",
              "      (branch1): ConvLayer(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch3): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch4): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): ConvLayer(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): ConvLayer(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): ConvLayer(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): ConvLayer(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): ConvLayer(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): ConvLayer(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "  (inception5): Sequential(\n",
              "    (0): Inception(\n",
              "      (branch1): ConvLayer(\n",
              "        (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch3): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch4): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Inception(\n",
              "      (branch1): ConvLayer(\n",
              "        (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch3): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (branch4): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "        (1): ConvLayer(\n",
              "          (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (head): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the GoogLeNet model from scratch"
      ],
      "metadata": {
        "id": "eLlzSe1K8UgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "aM-NHS8-8a7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation -- define transformations for the dataset\n",
        "transform= transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std= [0.2023, 0.1994, 0.2010]), # CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# load the CIFAR-10 dataset\n",
        "train_dataset= datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "train_size= int(0.9 * len(train_dataset))\n",
        "val_size  = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset= random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size= 128\n",
        "train_loader= DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "KdR9voQy3fJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4d7e57-ff11-4c7c-e953-47d87d51d5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 32.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(val_loader)"
      ],
      "metadata": {
        "id": "0jDRfQSa3fML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36ae225-dbf2-4f12-826f-48cb4b4cf174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Function\n",
        "\n",
        "In the original GoogleNet paper they compute:\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = \\mathcal{L}_{main} + \\alpha\\mathcal{L}_{aux_1} + \\alpha\\mathcal{L}_{aux_2}\n",
        "$$\n",
        "\n",
        "where each $\\mathcal{L}_{*}$ is the supervised classification loss (cross-entropy). The original paper used $\\alpha = 0.3$ on each aux head.\n",
        "\n",
        "TODO:\n",
        "\n",
        "- Play with different learning rate values.\n",
        "- More training epochs.\n",
        "- Improved LR schedulers, e.g., Cosine decay with warmup."
      ],
      "metadata": {
        "id": "-KCrxVnA8kf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs,\n",
        "            device, discount_loss=0.3, eval_interval=1, verbose=False):\n",
        "\n",
        "    tr_loss_hist= []\n",
        "    vl_loss_hist= []\n",
        "\n",
        "    # --- training loop ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_loss= []\n",
        "        start= time.time()\n",
        "\n",
        "        # --- training steps ---\n",
        "        # iterating over all batches\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # --- minibatch construction ---\n",
        "            images= images.to(device, non_blocking=True)\n",
        "            labels= labels.to(device, non_blocking=True)\n",
        "\n",
        "            # --- forward pass and get loss ---\n",
        "            logits, logits_aux1, logits_aux2= model(images)\n",
        "            loss= criterion(logits, labels)\n",
        "            if logits_aux1 is not None and logits_aux2 is not None:\n",
        "                loss += (discount_loss * criterion(logits_aux1, labels))\n",
        "                loss += (discount_loss * criterion(logits_aux2, labels))\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            # --- backward pass to calculate the gradients ---\n",
        "            loss.backward()\n",
        "\n",
        "            # --- update the parameters using the gradient ---\n",
        "            optimizer.step()\n",
        "\n",
        "        # --- evaluation and track stats ---\n",
        "        tr_loss_hist.append(np.mean(batch_loss))\n",
        "\n",
        "        if epoch% eval_interval== 0 or epoch== epochs-1:\n",
        "            model.eval()\n",
        "            val_loss= []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels= images.to(device), labels.to(device)\n",
        "                    logits, _, _= model(images)\n",
        "                    loss_v= criterion(logits, labels)\n",
        "                    val_loss.append(loss_v.item())\n",
        "\n",
        "            val_loss= np.mean(val_loss)\n",
        "            end= time.time()\n",
        "            dt= end - start\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch: {epoch} | Train Loss: {tr_loss_hist[-1]:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f} | dt/epoch: {dt*1000:.2f}ms\")\n",
        "\n",
        "            # for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        vl_loss_hist.append(val_loss)\n",
        "\n",
        "    return tr_loss_hist, vl_loss_hist\n"
      ],
      "metadata": {
        "id": "utXaRI803fP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device, verbose=False):\n",
        "    model.eval()\n",
        "    correct= 0\n",
        "    total= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels= images.to(device), labels.to(device)\n",
        "            logits, _, _= model(images)\n",
        "            y_pred= torch.argmax(logits, dim=1)\n",
        "            correct += (y_pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc= correct / total\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {(acc * 100):.2f}%\")\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "l2YXfTvJ3fTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(train_loss, valid_loss):\n",
        "    # plot training and validation losses\n",
        "    plt.plot(train_loss, label='Train Loss')\n",
        "    plt.plot(valid_loss, label='Validation Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "IMtV3Pp93fWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup using TF32, Fused AdamW, and Label Smoothing"
      ],
      "metadata": {
        "id": "KllBjAU78w7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_fused= False\n",
        "\n",
        "if device== 'cuda': # TF32 computationally more efficient (slightly the same precision of FP32)\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    # create AdamW optimizer and use the fused version of it is available\n",
        "    fused_available= 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "    # fused is a lot faster when it is available and when running on cuda\n",
        "    use_fused= fused_available\n",
        "\n",
        "\n",
        "# --- GoogLeNet ---\n",
        "in_channels= 3\n",
        "num_classes= 10\n",
        "dropout= 0.1\n",
        "dropout_aux= 0.5\n",
        "\n",
        "model= GoogLeNet(in_channels, num_classes, dropout=dropout, dropout_aux=dropout_aux).to(device)\n",
        "count_parameters(model)\n",
        "\n",
        "\n",
        "# train_loader has size 352, so 20 epochs have 7,040 steps\n",
        "epochs= 20\n",
        "learning_rate= 5e-4\n",
        "\n",
        "optimizer= torch.optim.AdamW(\n",
        "    model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-4,\n",
        "    fused=use_fused\n",
        ")\n",
        "print(f\"Using fused AdamW: {use_fused}\")\n",
        "criterion= nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "# for decreasing learning rate -- the ReduceLROnPlateau is designed to be used per epoch\n",
        "scheduler= ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n"
      ],
      "metadata": {
        "id": "us8zn2YY3fZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70712bd4-42c3-42d4-9d12-debef0ca703c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 10341566\n",
            "Using fused AdamW: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss, vl_loss= trainer(model, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                          epochs, device, discount_loss=0.3, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c532c678-24ac-420a-8197-556f660bfbef",
        "id": "ASgRKnSRHUF7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 2.4615 | Val Loss: 1.3832 | dt/epoch: 82703.98ms\n",
            "Epoch: 1 | Train Loss: 1.8515 | Val Loss: 1.1233 | dt/epoch: 81818.11ms\n",
            "Epoch: 2 | Train Loss: 1.6141 | Val Loss: 1.0083 | dt/epoch: 81571.56ms\n",
            "Epoch: 3 | Train Loss: 1.4769 | Val Loss: 0.9938 | dt/epoch: 82008.37ms\n",
            "Epoch: 4 | Train Loss: 1.3897 | Val Loss: 0.9280 | dt/epoch: 81658.56ms\n",
            "Epoch: 5 | Train Loss: 1.3178 | Val Loss: 0.8731 | dt/epoch: 81350.17ms\n",
            "Epoch: 6 | Train Loss: 1.2554 | Val Loss: 0.9882 | dt/epoch: 81932.09ms\n",
            "Epoch: 7 | Train Loss: 1.2034 | Val Loss: 0.8392 | dt/epoch: 81699.19ms\n",
            "Epoch: 8 | Train Loss: 1.1650 | Val Loss: 0.7646 | dt/epoch: 81260.35ms\n",
            "Epoch: 9 | Train Loss: 1.1322 | Val Loss: 0.7921 | dt/epoch: 81910.11ms\n",
            "Epoch: 10 | Train Loss: 1.0959 | Val Loss: 0.8557 | dt/epoch: 82125.29ms\n",
            "Epoch: 11 | Train Loss: 1.0727 | Val Loss: 0.8341 | dt/epoch: 81308.84ms\n",
            "Epoch: 12 | Train Loss: 1.0422 | Val Loss: 0.7846 | dt/epoch: 81329.18ms\n",
            "Epoch: 13 | Train Loss: 0.9477 | Val Loss: 0.6862 | dt/epoch: 81634.99ms\n",
            "Epoch: 14 | Train Loss: 0.9185 | Val Loss: 0.6953 | dt/epoch: 81704.80ms\n",
            "Epoch: 15 | Train Loss: 0.9096 | Val Loss: 0.6875 | dt/epoch: 81502.99ms\n",
            "Epoch: 16 | Train Loss: 0.8993 | Val Loss: 0.6891 | dt/epoch: 81554.73ms\n",
            "Epoch: 17 | Train Loss: 0.8931 | Val Loss: 0.6875 | dt/epoch: 81573.78ms\n",
            "Epoch: 18 | Train Loss: 0.8857 | Val Loss: 0.6859 | dt/epoch: 81448.44ms\n",
            "Epoch: 19 | Train Loss: 0.8840 | Val Loss: 0.6845 | dt/epoch: 81376.61ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "plot_losses(tr_loss, vl_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "f5f7b7b4-edb9-4da1-c1e8-b72e3cc3b3f8",
        "id": "nStvVHyuHUF9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetv1_acc= evaluate_model(model, test_loader, device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdecbc16-555a-40fd-edf1-9ca4cfcb0b67",
        "id": "ZTW5cQ95HUF-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/aiguys/going-deeper-with-convolutions-the-inception-paper-explained-841a0c661fd3\n",
        "# https://medium.com/@karuneshu21/implement-inception-v1-in-pytorch-66bdbb3d0005\n",
        "# https://sahiltinky94.medium.com/know-about-googlenet-and-implementation-using-pytorch-92f827d675db\n",
        "# https://medium.com/nerd-for-tech/know-about-inception-v2-and-v3-implementation-using-pytorch-b1d96b2c1aa5"
      ],
      "metadata": {
        "id": "sV_6ONHS9K0w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}